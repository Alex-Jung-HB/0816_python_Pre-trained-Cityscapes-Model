{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMvq5UY+viNHZ2Tmoe8CYYj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alex-Jung-HB/0816_python_Pre-trained-Cityscapes-Model/blob/main/0816_python_Pre_trained_Cityscapes_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-trained Cityscapes Model:"
      ],
      "metadata": {
        "id": "Z9yE7AzrkdLj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/segmentation_quality_check/results/user_image_original_20250816_020225.jpg": {
              "data": "",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "0"
                ]
              ],
              "status": 404,
              "status_text": ""
            },
            "http://localhost:8080/segmentation_quality_check/results/user_image_segmented_20250816_020225.jpg": {
              "data": "",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "0"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "naP31I4okK5l",
        "outputId": "c3faa7c1-31a0-441f-f97e-b28508c8821f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Google Colab environment detected\n",
            "üéØ SEGMENTATION QUALITY VALIDATION SYSTEM\n",
            "======================================================================\n",
            "This system helps you validate segmentation quality before video processing\n",
            "\n",
            "Options:\n",
            "1. üß™ Run complete validation with sample images\n",
            "2. üì§ Test your own image\n",
            "3. ‚ÑπÔ∏è  Show system information\n",
            "0. üö™ Exit\n",
            "\n",
            "üëâ Enter your choice (0-3): 2\n",
            "\n",
            "üì§ USER IMAGE QUALITY TEST\n",
            "============================================================\n",
            "üîÑ Loading Segformer model...\n",
            "============================================================\n",
            "‚úÖ Model loaded successfully!\n",
            "üì± Device: cpu\n",
            "üéØ Classes: 19\n",
            "üìÅ Please upload your traffic image:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ac17b889-ef22-4e02-aa63-ab8f33f2631f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ac17b889-ef22-4e02-aa63-ab8f33f2631f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving KakaoTalk_20250717_091440196_08.jpg to KakaoTalk_20250717_091440196_08 (1).jpg\n",
            "üîç Analyzing: KakaoTalk_20250717_091440196_08 (1).jpg\n",
            "\n",
            "üìä QUALITY ANALYSIS RESULTS\n",
            "============================================================\n",
            "üéØ Overall Quality Score: 0.79\n",
            "üéì Grade: B+\n",
            "üìà Status: ‚úÖ GOOD\n",
            "\n",
            "üìã Detailed Metrics:\n",
            "  ‚Ä¢ Road Coverage: 1.00 (Good)\n",
            "  ‚Ä¢ Fragmentation: 1.00 (Good)\n",
            "  ‚Ä¢ Traffic Detection: 1.00 (Good)\n",
            "  ‚Ä¢ Spatial Coherence: 0.15 (Poor)\n",
            "\n",
            "üé® Class Distribution:\n",
            "  ‚Ä¢ road: 25.6% (382,434 pixels)\n",
            "  ‚Ä¢ building: 8.9% (132,861 pixels)\n",
            "  ‚Ä¢ pole: 1.2% (17,321 pixels)\n",
            "  ‚Ä¢ vegetation: 12.4% (184,783 pixels)\n",
            "  ‚Ä¢ sky: 30.7% (457,928 pixels)\n",
            "  ‚Ä¢ car: 19.9% (297,204 pixels)\n",
            "\n",
            "‚úÖ RECOMMENDATION: This segmentation quality is suitable for video processing!\n",
            "\n",
            "üíæ Results saved to: ./segmentation_quality_check/results\n",
            "\n",
            "üñºÔ∏è Visual Results:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <div style=\"display: flex; gap: 10px;\">\n",
              "                <div>\n",
              "                    <h4>Original</h4>\n",
              "                    <img src=\"./segmentation_quality_check/results/user_image_original_20250816_020225.jpg\" style=\"max-width: 300px;\">\n",
              "                </div>\n",
              "                <div>\n",
              "                    <h4>Segmentation</h4>\n",
              "                    <img src=\"./segmentation_quality_check/results/user_image_segmented_20250816_020225.jpg\" style=\"max-width: 300px;\">\n",
              "                </div>\n",
              "            </div>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üëâ Enter your choice (0-3): 0\n",
            "üëã Quality check completed!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nüöÄ QUICK START GUIDE:\\n\\n1. RUN THE CODE:\\n   - Execute this entire cell/script\\n   - It will initialize the quality checking system\\n\\n2. CHOOSE OPTION 1 FOR COMPLETE VALIDATION:\\n   - Creates realistic traffic sample images\\n   - Tests segmentation quality on each sample\\n   - Provides detailed quality scores and grades\\n   - Gives clear recommendation (Ready/Not Ready for video)\\n\\n3. CHOOSE OPTION 2 TO TEST YOUR OWN IMAGE:\\n   - Upload your traffic image\\n   - Get detailed quality analysis\\n   - See if it's suitable for video processing\\n\\n4. INTERPRET RESULTS:\\n   - Quality Score 0.6+ = Good for video processing\\n   - Grade A/B = Excellent/Good quality\\n   - Grade C/D = Needs improvement\\n\\n5. WHAT TO EXPECT:\\n   ‚úÖ Good road surface detection\\n   ‚úÖ Clear traffic element recognition\\n   ‚úÖ Low fragmentation\\n   ‚úÖ Coherent object boundaries\\n\\nThis validation ensures your model will work well on videos before processing!\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# ===============================================================================\n",
        "# SEGFORMER QUALITY CHECK SYSTEM - STEP BY STEP VALIDATION\n",
        "# ===============================================================================\n",
        "# This enhanced version provides comprehensive quality checking before video processing\n",
        "# ===============================================================================\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from datetime import datetime\n",
        "import json\n",
        "import time\n",
        "\n",
        "# For Colab environment\n",
        "try:\n",
        "    from google.colab import files\n",
        "    from IPython.display import display, Image as IPImage, HTML\n",
        "    COLAB_ENV = True\n",
        "    print(\"‚úÖ Google Colab environment detected\")\n",
        "except ImportError:\n",
        "    COLAB_ENV = False\n",
        "    print(\"üì± Running in local environment\")\n",
        "\n",
        "# ===============================================================================\n",
        "# STEP 1: QUALITY CHECKER CLASS\n",
        "# ===============================================================================\n",
        "class SegmentationQualityChecker:\n",
        "    \"\"\"Comprehensive quality checking system for segmentation results\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.processor = None\n",
        "        self.model = None\n",
        "\n",
        "        # Cityscapes classes for evaluation\n",
        "        self.cityscapes_classes = {\n",
        "            0: 'road', 1: 'sidewalk', 2: 'building', 3: 'wall', 4: 'fence',\n",
        "            5: 'pole', 6: 'traffic_light', 7: 'traffic_sign', 8: 'vegetation',\n",
        "            9: 'terrain', 10: 'sky', 11: 'person', 12: 'rider', 13: 'car',\n",
        "            14: 'truck', 15: 'bus', 16: 'train', 17: 'motorcycle', 18: 'bicycle'\n",
        "        }\n",
        "\n",
        "        # Color mapping for clear visualization\n",
        "        self.color_map = {\n",
        "            0: [128, 64, 128],   # road - purple\n",
        "            1: [244, 35, 232],   # sidewalk - pink\n",
        "            2: [70, 70, 70],     # building - gray\n",
        "            5: [153, 153, 153],  # pole - light gray\n",
        "            6: [250, 170, 30],   # traffic_light - orange\n",
        "            7: [220, 220, 0],    # traffic_sign - yellow\n",
        "            8: [107, 142, 35],   # vegetation - olive\n",
        "            10: [70, 130, 180],  # sky - steel blue\n",
        "            11: [220, 20, 60],   # person - crimson\n",
        "            13: [0, 0, 142],     # car - dark blue\n",
        "            14: [0, 0, 70],      # truck - darker blue\n",
        "            15: [0, 60, 100],    # bus - navy\n",
        "            17: [0, 0, 230],     # motorcycle - blue\n",
        "            18: [119, 11, 32],   # bicycle - dark red\n",
        "        }\n",
        "\n",
        "        # Quality criteria for traffic scenes\n",
        "        self.quality_criteria = {\n",
        "            'road_coverage': {'min': 15, 'max': 70, 'weight': 0.3},          # 15-70% road coverage\n",
        "            'fragmentation': {'max_fragments': 50, 'weight': 0.25},          # Low fragmentation\n",
        "            'boundary_quality': {'min_coherence': 0.7, 'weight': 0.2},      # Smooth boundaries\n",
        "            'traffic_elements': {'min_detection': 1, 'weight': 0.15},       # Detect traffic elements\n",
        "            'background_ratio': {'min': 20, 'max': 80, 'weight': 0.1}       # Reasonable background\n",
        "        }\n",
        "\n",
        "        self.setup_directories()\n",
        "\n",
        "    def setup_directories(self):\n",
        "        \"\"\"Create output directories\"\"\"\n",
        "        self.output_dir = \"./segmentation_quality_check\"\n",
        "        self.sample_dir = os.path.join(self.output_dir, \"samples\")\n",
        "        self.results_dir = os.path.join(self.output_dir, \"results\")\n",
        "\n",
        "        for dir_path in [self.output_dir, self.sample_dir, self.results_dir]:\n",
        "            os.makedirs(dir_path, exist_ok=True)\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"Load pre-trained Segformer model\"\"\"\n",
        "        print(\"üîÑ Loading Segformer model...\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        try:\n",
        "            model_name = \"nvidia/segformer-b0-finetuned-cityscapes-1024-1024\"\n",
        "            self.processor = SegformerImageProcessor.from_pretrained(model_name)\n",
        "            self.model = SegformerForSemanticSegmentation.from_pretrained(model_name)\n",
        "            self.model.to(self.device)\n",
        "            self.model.eval()\n",
        "\n",
        "            print(\"‚úÖ Model loaded successfully!\")\n",
        "            print(f\"üì± Device: {self.device}\")\n",
        "            print(f\"üéØ Classes: {len(self.cityscapes_classes)}\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading model: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "# ===============================================================================\n",
        "# STEP 2: SAMPLE IMAGE GENERATOR\n",
        "# ===============================================================================\n",
        "    def create_traffic_sample_images(self):\n",
        "        \"\"\"Create realistic traffic scene sample images for testing\"\"\"\n",
        "        print(\"\\nüé® CREATING TRAFFIC SAMPLE IMAGES\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        samples = []\n",
        "\n",
        "        # Sample 1: Highway scene\n",
        "        highway_img = self._create_highway_scene()\n",
        "        highway_path = os.path.join(self.sample_dir, \"sample_highway.jpg\")\n",
        "        highway_img.save(highway_path)\n",
        "        samples.append((\"Highway Scene\", highway_path))\n",
        "\n",
        "        # Sample 2: City intersection\n",
        "        city_img = self._create_city_intersection()\n",
        "        city_path = os.path.join(self.sample_dir, \"sample_city.jpg\")\n",
        "        city_img.save(city_path)\n",
        "        samples.append((\"City Intersection\", city_path))\n",
        "\n",
        "        # Sample 3: Traffic with signs\n",
        "        traffic_img = self._create_traffic_signs_scene()\n",
        "        traffic_path = os.path.join(self.sample_dir, \"sample_traffic_signs.jpg\")\n",
        "        traffic_img.save(traffic_path)\n",
        "        samples.append((\"Traffic Signs Scene\", traffic_path))\n",
        "\n",
        "        print(f\"‚úÖ Created {len(samples)} sample images:\")\n",
        "        for name, path in samples:\n",
        "            print(f\"  ‚Ä¢ {name}: {path}\")\n",
        "\n",
        "        return samples\n",
        "\n",
        "    def _create_highway_scene(self):\n",
        "        \"\"\"Create a highway-like sample image\"\"\"\n",
        "        img = Image.new('RGB', (800, 600), color=(135, 206, 235))  # Sky blue background\n",
        "        draw = ImageDraw.Draw(img)\n",
        "\n",
        "        # Road surface (gray)\n",
        "        draw.rectangle([0, 400, 800, 600], fill=(70, 70, 70))\n",
        "\n",
        "        # Lane markings (white)\n",
        "        for x in range(50, 800, 100):\n",
        "            draw.rectangle([x, 480, x+40, 490], fill=(255, 255, 255))\n",
        "\n",
        "        # Side barriers (concrete)\n",
        "        draw.rectangle([0, 380, 800, 400], fill=(150, 150, 150))\n",
        "\n",
        "        # Vehicles (simplified rectangles)\n",
        "        # Car 1\n",
        "        draw.rectangle([200, 420, 280, 470], fill=(255, 0, 0))  # Red car\n",
        "        # Car 2\n",
        "        draw.rectangle([450, 430, 530, 480], fill=(0, 0, 255))  # Blue car\n",
        "\n",
        "        # Trees/vegetation on sides\n",
        "        for x in range(100, 800, 150):\n",
        "            draw.ellipse([x, 200, x+60, 280], fill=(34, 139, 34))  # Green circles\n",
        "\n",
        "        return img\n",
        "\n",
        "    def _create_city_intersection(self):\n",
        "        \"\"\"Create a city intersection sample\"\"\"\n",
        "        img = Image.new('RGB', (800, 600), color=(135, 206, 235))  # Sky\n",
        "        draw = ImageDraw.Draw(img)\n",
        "\n",
        "        # Buildings (gray/brown)\n",
        "        draw.rectangle([0, 0, 300, 350], fill=(139, 69, 19))      # Left building\n",
        "        draw.rectangle([500, 0, 800, 300], fill=(105, 105, 105))  # Right building\n",
        "\n",
        "        # Road intersection\n",
        "        draw.rectangle([300, 350, 500, 600], fill=(70, 70, 70))   # Vertical road\n",
        "        draw.rectangle([0, 450, 800, 550], fill=(70, 70, 70))     # Horizontal road\n",
        "\n",
        "        # Crosswalk (white stripes)\n",
        "        for y in range(460, 540, 8):\n",
        "            draw.rectangle([320, y, 480, y+4], fill=(255, 255, 255))\n",
        "\n",
        "        # Traffic light (simplified)\n",
        "        draw.rectangle([290, 330, 310, 380], fill=(128, 128, 128))  # Pole\n",
        "        draw.ellipse([285, 320, 315, 350], fill=(255, 255, 0))      # Yellow light\n",
        "\n",
        "        # Stop sign\n",
        "        draw.polygon([(480, 300), (520, 320), (520, 360), (480, 380),\n",
        "                     (440, 360), (440, 320)], fill=(255, 0, 0))\n",
        "\n",
        "        return img\n",
        "\n",
        "    def _create_traffic_signs_scene(self):\n",
        "        \"\"\"Create scene with various traffic elements\"\"\"\n",
        "        img = Image.new('RGB', (800, 600), color=(135, 206, 235))  # Sky\n",
        "        draw = ImageDraw.Draw(img)\n",
        "\n",
        "        # Road\n",
        "        draw.rectangle([0, 400, 800, 600], fill=(70, 70, 70))\n",
        "\n",
        "        # Sidewalk\n",
        "        draw.rectangle([0, 350, 800, 400], fill=(244, 164, 96))\n",
        "\n",
        "        # Various traffic signs\n",
        "        # Speed limit sign (rectangular)\n",
        "        draw.rectangle([100, 200, 180, 280], fill=(255, 255, 255))\n",
        "        draw.rectangle([105, 205, 175, 275], fill=(255, 0, 0))\n",
        "\n",
        "        # Warning sign (triangular)\n",
        "        draw.polygon([(300, 180), (250, 280), (350, 280)], fill=(255, 255, 0))\n",
        "\n",
        "        # Traffic light pole\n",
        "        draw.rectangle([450, 100, 470, 350], fill=(128, 128, 128))\n",
        "        draw.rectangle([430, 100, 490, 160], fill=(0, 0, 0))\n",
        "        draw.ellipse([435, 105, 455, 125], fill=(255, 0, 0))      # Red\n",
        "        draw.ellipse([435, 120, 455, 140], fill=(255, 255, 0))    # Yellow\n",
        "        draw.ellipse([435, 135, 455, 155], fill=(0, 255, 0))      # Green\n",
        "\n",
        "        # Vehicles\n",
        "        draw.rectangle([600, 420, 720, 480], fill=(0, 0, 139))    # Car\n",
        "\n",
        "        return img\n",
        "\n",
        "# ===============================================================================\n",
        "# STEP 3: QUALITY ASSESSMENT FUNCTIONS\n",
        "# ===============================================================================\n",
        "    def predict_and_analyze(self, image_path_or_pil):\n",
        "        \"\"\"Predict segmentation and perform detailed analysis\"\"\"\n",
        "        try:\n",
        "            # Load image\n",
        "            if isinstance(image_path_or_pil, str):\n",
        "                image = Image.open(image_path_or_pil).convert(\"RGB\")\n",
        "            else:\n",
        "                image = image_path_or_pil.convert(\"RGB\")\n",
        "\n",
        "            # Predict\n",
        "            inputs = self.processor(image, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(**inputs)\n",
        "                predictions = torch.nn.functional.interpolate(\n",
        "                    outputs.logits,\n",
        "                    size=image.size[::-1],\n",
        "                    mode=\"bilinear\",\n",
        "                    align_corners=False,\n",
        "                )\n",
        "                predicted_map = predictions.squeeze().cpu().numpy().argmax(axis=0)\n",
        "\n",
        "            return self._analyze_prediction_quality(predicted_map, image)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error during prediction: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def _analyze_prediction_quality(self, prediction, image):\n",
        "        \"\"\"Comprehensive quality analysis of prediction\"\"\"\n",
        "        h, w = prediction.shape\n",
        "        total_pixels = h * w\n",
        "\n",
        "        # Get class distribution\n",
        "        unique_classes, counts = np.unique(prediction, return_counts=True)\n",
        "        class_distribution = {}\n",
        "\n",
        "        for class_id, count in zip(unique_classes, counts):\n",
        "            percentage = (count / total_pixels) * 100\n",
        "            class_name = self.cityscapes_classes.get(class_id, f\"Unknown_{class_id}\")\n",
        "            class_distribution[class_name] = {\n",
        "                'pixels': int(count),\n",
        "                'percentage': round(percentage, 2),\n",
        "                'class_id': int(class_id)\n",
        "            }\n",
        "\n",
        "        # Quality metrics\n",
        "        quality_scores = self._calculate_quality_scores(prediction, class_distribution)\n",
        "\n",
        "        # Create visualizations\n",
        "        colored_mask = self._create_colored_mask(prediction)\n",
        "        blended = self._create_blended_image(image, colored_mask)\n",
        "\n",
        "        return {\n",
        "            'prediction': prediction,\n",
        "            'image': image,\n",
        "            'colored_mask': colored_mask,\n",
        "            'blended': blended,\n",
        "            'class_distribution': class_distribution,\n",
        "            'quality_scores': quality_scores,\n",
        "            'dimensions': (h, w),\n",
        "            'total_pixels': total_pixels\n",
        "        }\n",
        "\n",
        "    def _calculate_quality_scores(self, prediction, class_distribution):\n",
        "        \"\"\"Calculate quality scores based on criteria\"\"\"\n",
        "        scores = {}\n",
        "\n",
        "        # 1. Road coverage analysis\n",
        "        road_percentage = class_distribution.get('road', {}).get('percentage', 0)\n",
        "        road_score = self._score_in_range(road_percentage,\n",
        "                                        self.quality_criteria['road_coverage']['min'],\n",
        "                                        self.quality_criteria['road_coverage']['max'])\n",
        "        scores['road_coverage'] = {\n",
        "            'score': road_score,\n",
        "            'value': road_percentage,\n",
        "            'status': 'Good' if road_score > 0.7 else 'Poor'\n",
        "        }\n",
        "\n",
        "        # 2. Fragmentation analysis\n",
        "        fragmentation_score = self._analyze_fragmentation(prediction)\n",
        "        scores['fragmentation'] = {\n",
        "            'score': fragmentation_score,\n",
        "            'status': 'Good' if fragmentation_score > 0.7 else 'Poor'\n",
        "        }\n",
        "\n",
        "        # 3. Traffic elements detection\n",
        "        traffic_elements = ['traffic_light', 'traffic_sign', 'car', 'truck', 'bus']\n",
        "        detected_traffic = sum(1 for elem in traffic_elements if elem in class_distribution)\n",
        "        traffic_score = min(1.0, detected_traffic / 2)  # At least 2 traffic elements\n",
        "        scores['traffic_detection'] = {\n",
        "            'score': traffic_score,\n",
        "            'detected': detected_traffic,\n",
        "            'status': 'Good' if traffic_score > 0.5 else 'Poor'\n",
        "        }\n",
        "\n",
        "        # 4. Overall coherence\n",
        "        coherence_score = self._analyze_spatial_coherence(prediction)\n",
        "        scores['spatial_coherence'] = {\n",
        "            'score': coherence_score,\n",
        "            'status': 'Good' if coherence_score > 0.6 else 'Poor'\n",
        "        }\n",
        "\n",
        "        # Calculate overall quality score\n",
        "        weights = [0.3, 0.25, 0.2, 0.25]  # Road, fragmentation, traffic, coherence\n",
        "        overall_score = sum(s['score'] * w for s, w in zip(scores.values(), weights))\n",
        "\n",
        "        scores['overall'] = {\n",
        "            'score': overall_score,\n",
        "            'grade': self._get_quality_grade(overall_score),\n",
        "            'status': 'Good' if overall_score > 0.6 else 'Poor'\n",
        "        }\n",
        "\n",
        "        return scores\n",
        "\n",
        "    def _score_in_range(self, value, min_val, max_val):\n",
        "        \"\"\"Score value based on optimal range\"\"\"\n",
        "        if min_val <= value <= max_val:\n",
        "            return 1.0\n",
        "        elif value < min_val:\n",
        "            return max(0, value / min_val)\n",
        "        else:\n",
        "            return max(0, 1 - (value - max_val) / max_val)\n",
        "\n",
        "    def _analyze_fragmentation(self, prediction):\n",
        "        \"\"\"Analyze image fragmentation (lower is better)\"\"\"\n",
        "        # Count connected components for major classes\n",
        "        fragmentation_penalty = 0\n",
        "\n",
        "        for class_id in [0, 6, 7, 13]:  # road, traffic_light, traffic_sign, car\n",
        "            mask = (prediction == class_id).astype(np.uint8)\n",
        "            if np.sum(mask) > 100:  # Only analyze if significant presence\n",
        "                num_labels, _ = cv2.connectedComponents(mask)\n",
        "                if num_labels > 10:  # Too many fragments\n",
        "                    fragmentation_penalty += (num_labels - 10) / 50\n",
        "\n",
        "        return max(0, 1 - fragmentation_penalty)\n",
        "\n",
        "    def _analyze_spatial_coherence(self, prediction):\n",
        "        \"\"\"Analyze spatial coherence of segmentation\"\"\"\n",
        "        # Check for spatial coherence using edge consistency\n",
        "        edges = cv2.Canny(prediction.astype(np.uint8), 1, 3)\n",
        "        edge_ratio = np.sum(edges > 0) / prediction.size\n",
        "\n",
        "        # Good segmentation should have moderate edge ratio (not too fragmented)\n",
        "        if 0.05 <= edge_ratio <= 0.2:\n",
        "            return 1.0\n",
        "        elif edge_ratio < 0.05:\n",
        "            return edge_ratio / 0.05\n",
        "        else:\n",
        "            return max(0, 1 - (edge_ratio - 0.2) / 0.3)\n",
        "\n",
        "    def _get_quality_grade(self, score):\n",
        "        \"\"\"Convert score to letter grade\"\"\"\n",
        "        if score >= 0.9: return 'A+'\n",
        "        elif score >= 0.8: return 'A'\n",
        "        elif score >= 0.7: return 'B+'\n",
        "        elif score >= 0.6: return 'B'\n",
        "        elif score >= 0.5: return 'C'\n",
        "        else: return 'D'\n",
        "\n",
        "    def _create_colored_mask(self, prediction):\n",
        "        \"\"\"Create colored visualization mask\"\"\"\n",
        "        h, w = prediction.shape\n",
        "        colored_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
        "\n",
        "        for class_id, color in self.color_map.items():\n",
        "            mask = prediction == class_id\n",
        "            colored_mask[mask] = color\n",
        "\n",
        "        return colored_mask\n",
        "\n",
        "    def _create_blended_image(self, image, colored_mask, alpha=0.6):\n",
        "        \"\"\"Create blended image with segmentation overlay\"\"\"\n",
        "        image_np = np.array(image)\n",
        "        return cv2.addWeighted(image_np, alpha, colored_mask, 1-alpha, 0)\n",
        "\n",
        "# ===============================================================================\n",
        "# STEP 4: COMPREHENSIVE TESTING INTERFACE\n",
        "# ===============================================================================\n",
        "    def run_step_by_step_validation(self):\n",
        "        \"\"\"Run complete step-by-step validation process\"\"\"\n",
        "        print(\"\\nüéØ STEP-BY-STEP SEGMENTATION QUALITY VALIDATION\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # Step 1: Model loading\n",
        "        print(\"\\nüì• STEP 1: Loading Model\")\n",
        "        print(\"-\" * 40)\n",
        "        if not self.load_model():\n",
        "            return False\n",
        "\n",
        "        # Step 2: Create sample images\n",
        "        print(\"\\nüé® STEP 2: Creating Sample Images\")\n",
        "        print(\"-\" * 40)\n",
        "        samples = self.create_traffic_sample_images()\n",
        "\n",
        "        # Step 3: Test each sample\n",
        "        print(\"\\nüîç STEP 3: Testing Sample Images\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        all_results = []\n",
        "\n",
        "        for i, (name, sample_path) in enumerate(samples, 1):\n",
        "            print(f\"\\nüß™ Testing Sample {i}: {name}\")\n",
        "            print(\".\" * 30)\n",
        "\n",
        "            result = self.predict_and_analyze(sample_path)\n",
        "            if result:\n",
        "                # Save results\n",
        "                self._save_detailed_results(result, f\"sample_{i}_{name.lower().replace(' ', '_')}\")\n",
        "                all_results.append((name, result))\n",
        "\n",
        "                # Print quick summary\n",
        "                quality = result['quality_scores']['overall']\n",
        "                print(f\"   Quality Score: {quality['score']:.2f} (Grade: {quality['grade']})\")\n",
        "                print(f\"   Status: {'‚úÖ GOOD' if quality['status'] == 'Good' else '‚ö†Ô∏è NEEDS IMPROVEMENT'}\")\n",
        "\n",
        "        # Step 4: Overall assessment\n",
        "        print(\"\\nüìä STEP 4: Overall Assessment\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        average_score = np.mean([r[1]['quality_scores']['overall']['score'] for _, r in all_results])\n",
        "        overall_grade = self._get_quality_grade(average_score)\n",
        "\n",
        "        print(f\"üìà Average Quality Score: {average_score:.2f}\")\n",
        "        print(f\"üéì Overall Grade: {overall_grade}\")\n",
        "\n",
        "        # Decision recommendation\n",
        "        if average_score >= 0.6:\n",
        "            recommendation = \"‚úÖ READY FOR VIDEO PROCESSING\"\n",
        "            print(f\"\\nüöÄ {recommendation}\")\n",
        "            print(\"The model shows good segmentation quality. You can proceed with video processing.\")\n",
        "        else:\n",
        "            recommendation = \"‚ö†Ô∏è CONSIDER IMPROVEMENTS BEFORE VIDEO PROCESSING\"\n",
        "            print(f\"\\n‚ö†Ô∏è {recommendation}\")\n",
        "            print(\"The model quality may need improvement. Consider:\")\n",
        "            print(\"  ‚Ä¢ Using a different pre-trained model\")\n",
        "            print(\"  ‚Ä¢ Fine-tuning on your specific traffic data\")\n",
        "            print(\"  ‚Ä¢ Adjusting image preprocessing\")\n",
        "\n",
        "        # Generate summary report\n",
        "        self._generate_summary_report(all_results, average_score, overall_grade, recommendation)\n",
        "\n",
        "        return average_score >= 0.6\n",
        "\n",
        "    def _save_detailed_results(self, result, prefix):\n",
        "        \"\"\"Save detailed results for each test\"\"\"\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "        # Save images\n",
        "        image_path = os.path.join(self.results_dir, f\"{prefix}_original_{timestamp}.jpg\")\n",
        "        blended_path = os.path.join(self.results_dir, f\"{prefix}_segmented_{timestamp}.jpg\")\n",
        "        mask_path = os.path.join(self.results_dir, f\"{prefix}_mask_{timestamp}.jpg\")\n",
        "\n",
        "        # Convert and save\n",
        "        result['image'].save(image_path)\n",
        "        cv2.imwrite(blended_path, cv2.cvtColor(result['blended'], cv2.COLOR_RGB2BGR))\n",
        "        cv2.imwrite(mask_path, cv2.cvtColor(result['colored_mask'], cv2.COLOR_RGB2BGR))\n",
        "\n",
        "        # Save analysis JSON\n",
        "        analysis_path = os.path.join(self.results_dir, f\"{prefix}_analysis_{timestamp}.json\")\n",
        "        analysis_data = {\n",
        "            'quality_scores': result['quality_scores'],\n",
        "            'class_distribution': result['class_distribution'],\n",
        "            'dimensions': result['dimensions'],\n",
        "            'total_pixels': result['total_pixels'],\n",
        "            'timestamp': timestamp\n",
        "        }\n",
        "\n",
        "        with open(analysis_path, 'w') as f:\n",
        "            json.dump(analysis_data, f, indent=2)\n",
        "\n",
        "        return {\n",
        "            'image': image_path,\n",
        "            'segmented': blended_path,\n",
        "            'mask': mask_path,\n",
        "            'analysis': analysis_path\n",
        "        }\n",
        "\n",
        "    def _generate_summary_report(self, all_results, average_score, overall_grade, recommendation):\n",
        "        \"\"\"Generate comprehensive summary report\"\"\"\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        report_path = os.path.join(self.results_dir, f\"quality_validation_report_{timestamp}.html\")\n",
        "\n",
        "        html_content = f\"\"\"\n",
        "        <!DOCTYPE html>\n",
        "        <html>\n",
        "        <head>\n",
        "            <title>Segmentation Quality Validation Report</title>\n",
        "            <style>\n",
        "                body {{ font-family: Arial, sans-serif; margin: 20px; }}\n",
        "                .header {{ background-color: #f0f0f0; padding: 20px; border-radius: 5px; }}\n",
        "                .result {{ margin: 20px 0; padding: 15px; border: 1px solid #ddd; border-radius: 5px; }}\n",
        "                .good {{ background-color: #e8f5e8; }}\n",
        "                .poor {{ background-color: #ffe8e8; }}\n",
        "                .score {{ font-size: 1.2em; font-weight: bold; }}\n",
        "                table {{ border-collapse: collapse; width: 100%; }}\n",
        "                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}\n",
        "                th {{ background-color: #f2f2f2; }}\n",
        "            </style>\n",
        "        </head>\n",
        "        <body>\n",
        "            <div class=\"header\">\n",
        "                <h1>üéØ Segmentation Quality Validation Report</h1>\n",
        "                <p><strong>Generated:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
        "                <p><strong>Overall Score:</strong> <span class=\"score\">{average_score:.2f} (Grade: {overall_grade})</span></p>\n",
        "                <p><strong>Recommendation:</strong> {recommendation}</p>\n",
        "            </div>\n",
        "        \"\"\"\n",
        "\n",
        "        for name, result in all_results:\n",
        "            quality = result['quality_scores']['overall']\n",
        "            status_class = 'good' if quality['status'] == 'Good' else 'poor'\n",
        "\n",
        "            html_content += f\"\"\"\n",
        "            <div class=\"result {status_class}\">\n",
        "                <h2>üìä {name}</h2>\n",
        "                <p><strong>Quality Score:</strong> {quality['score']:.2f} (Grade: {quality['grade']})</p>\n",
        "\n",
        "                <h3>Detailed Scores:</h3>\n",
        "                <table>\n",
        "                    <tr><th>Metric</th><th>Score</th><th>Status</th><th>Details</th></tr>\n",
        "            \"\"\"\n",
        "\n",
        "            for metric, data in result['quality_scores'].items():\n",
        "                if metric != 'overall':\n",
        "                    details = str(data.get('value', data.get('detected', '')))\n",
        "                    html_content += f\"\"\"\n",
        "                    <tr>\n",
        "                        <td>{metric.replace('_', ' ').title()}</td>\n",
        "                        <td>{data['score']:.2f}</td>\n",
        "                        <td>{data['status']}</td>\n",
        "                        <td>{details}</td>\n",
        "                    </tr>\n",
        "                    \"\"\"\n",
        "\n",
        "            html_content += \"\"\"\n",
        "                </table>\n",
        "\n",
        "                <h3>Class Distribution:</h3>\n",
        "                <table>\n",
        "                    <tr><th>Class</th><th>Percentage</th><th>Pixels</th></tr>\n",
        "            \"\"\"\n",
        "\n",
        "            for class_name, stats in result['class_distribution'].items():\n",
        "                html_content += f\"\"\"\n",
        "                <tr>\n",
        "                    <td>{class_name}</td>\n",
        "                    <td>{stats['percentage']}%</td>\n",
        "                    <td>{stats['pixels']:,}</td>\n",
        "                </tr>\n",
        "                \"\"\"\n",
        "\n",
        "            html_content += \"</table></div>\"\n",
        "\n",
        "        html_content += \"\"\"\n",
        "        </body>\n",
        "        </html>\n",
        "        \"\"\"\n",
        "\n",
        "        with open(report_path, 'w') as f:\n",
        "            f.write(html_content)\n",
        "\n",
        "        print(f\"üìÑ Detailed report saved: {report_path}\")\n",
        "\n",
        "# ===============================================================================\n",
        "# STEP 5: USER TESTING INTERFACE\n",
        "# ===============================================================================\n",
        "def test_user_image():\n",
        "    \"\"\"Test user-uploaded image with quality checking\"\"\"\n",
        "    print(\"\\nüì§ USER IMAGE QUALITY TEST\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    checker = SegmentationQualityChecker()\n",
        "\n",
        "    # Load model\n",
        "    if not checker.load_model():\n",
        "        return\n",
        "\n",
        "    if COLAB_ENV:\n",
        "        print(\"üìÅ Please upload your traffic image:\")\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        if not uploaded:\n",
        "            print(\"‚ùå No file uploaded!\")\n",
        "            return\n",
        "\n",
        "        image_path = list(uploaded.keys())[0]\n",
        "    else:\n",
        "        image_path = input(\"üìÅ Enter path to your traffic image: \").strip()\n",
        "        if not os.path.exists(image_path):\n",
        "            print(f\"‚ùå File not found: {image_path}\")\n",
        "            return\n",
        "\n",
        "    print(f\"üîç Analyzing: {image_path}\")\n",
        "\n",
        "    # Analyze image\n",
        "    result = checker.predict_and_analyze(image_path)\n",
        "\n",
        "    if result:\n",
        "        # Save results\n",
        "        saved_files = checker._save_detailed_results(result, \"user_image\")\n",
        "\n",
        "        # Display analysis\n",
        "        print(\"\\nüìä QUALITY ANALYSIS RESULTS\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        quality = result['quality_scores']['overall']\n",
        "        print(f\"üéØ Overall Quality Score: {quality['score']:.2f}\")\n",
        "        print(f\"üéì Grade: {quality['grade']}\")\n",
        "        print(f\"üìà Status: {'‚úÖ GOOD' if quality['status'] == 'Good' else '‚ö†Ô∏è NEEDS IMPROVEMENT'}\")\n",
        "\n",
        "        print(\"\\nüìã Detailed Metrics:\")\n",
        "        for metric, data in result['quality_scores'].items():\n",
        "            if metric != 'overall':\n",
        "                print(f\"  ‚Ä¢ {metric.replace('_', ' ').title()}: {data['score']:.2f} ({data['status']})\")\n",
        "\n",
        "        print(\"\\nüé® Class Distribution:\")\n",
        "        for class_name, stats in result['class_distribution'].items():\n",
        "            if stats['percentage'] > 1.0:  # Only show classes with >1%\n",
        "                print(f\"  ‚Ä¢ {class_name}: {stats['percentage']:.1f}% ({stats['pixels']:,} pixels)\")\n",
        "\n",
        "        # Recommendation\n",
        "        if quality['score'] >= 0.6:\n",
        "            print(\"\\n‚úÖ RECOMMENDATION: This segmentation quality is suitable for video processing!\")\n",
        "        else:\n",
        "            print(\"\\n‚ö†Ô∏è RECOMMENDATION: Consider improving the model before video processing.\")\n",
        "            print(\"   Possible improvements:\")\n",
        "            print(\"   ‚Ä¢ Try different preprocessing\")\n",
        "            print(\"   ‚Ä¢ Use fine-tuned model on similar data\")\n",
        "            print(\"   ‚Ä¢ Check image quality and lighting\")\n",
        "\n",
        "        print(f\"\\nüíæ Results saved to: {checker.results_dir}\")\n",
        "\n",
        "        # Display images in Colab\n",
        "        if COLAB_ENV:\n",
        "            print(\"\\nüñºÔ∏è Visual Results:\")\n",
        "            display(HTML(f\"\"\"\n",
        "            <div style=\"display: flex; gap: 10px;\">\n",
        "                <div>\n",
        "                    <h4>Original</h4>\n",
        "                    <img src=\"{saved_files['image']}\" style=\"max-width: 300px;\">\n",
        "                </div>\n",
        "                <div>\n",
        "                    <h4>Segmentation</h4>\n",
        "                    <img src=\"{saved_files['segmented']}\" style=\"max-width: 300px;\">\n",
        "                </div>\n",
        "            </div>\n",
        "            \"\"\"))\n",
        "\n",
        "    return result\n",
        "\n",
        "# ===============================================================================\n",
        "# STEP 6: MAIN INTERFACE\n",
        "# ===============================================================================\n",
        "def main_quality_check():\n",
        "    \"\"\"Main interface for quality checking\"\"\"\n",
        "    print(\"üéØ SEGMENTATION QUALITY VALIDATION SYSTEM\")\n",
        "    print(\"=\" * 70)\n",
        "    print(\"This system helps you validate segmentation quality before video processing\")\n",
        "    print(\"\\nOptions:\")\n",
        "    print(\"1. üß™ Run complete validation with sample images\")\n",
        "    print(\"2. üì§ Test your own image\")\n",
        "    print(\"3. ‚ÑπÔ∏è  Show system information\")\n",
        "    print(\"0. üö™ Exit\")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            choice = input(\"\\nüëâ Enter your choice (0-3): \").strip()\n",
        "\n",
        "            if choice == '0':\n",
        "                print(\"üëã Quality check completed!\")\n",
        "                break\n",
        "            elif choice == '1':\n",
        "                checker = SegmentationQualityChecker()\n",
        "                success = checker.run_step_by_step_validation()\n",
        "                if success:\n",
        "                    print(\"\\nüéâ Validation passed! You can proceed with video processing.\")\n",
        "                else:\n",
        "                    print(\"\\n‚ö†Ô∏è Consider model improvements before video processing.\")\n",
        "            elif choice == '2':\n",
        "                test_user_image()\n",
        "            elif choice == '3':\n",
        "                print(f\"\\nüíª System Information:\")\n",
        "                print(f\"  ‚Ä¢ Device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\")\n",
        "                print(f\"  ‚Ä¢ CUDA Available: {torch.cuda.is_available()}\")\n",
        "                if torch.cuda.is_available():\n",
        "                    print(f\"  ‚Ä¢ GPU: {torch.cuda.get_device_name()}\")\n",
        "                print(f\"  ‚Ä¢ Environment: {'Google Colab' if COLAB_ENV else 'Local'}\")\n",
        "            else:\n",
        "                print(\"‚ùå Invalid choice. Please try again.\")\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n‚èπÔ∏è Interrupted by user\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error: {str(e)}\")\n",
        "\n",
        "# ===============================================================================\n",
        "# EXECUTION\n",
        "# ===============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    main_quality_check()\n",
        "\n",
        "# ===============================================================================\n",
        "# QUICK START INSTRUCTIONS\n",
        "# ===============================================================================\n",
        "\"\"\"\n",
        "üöÄ QUICK START GUIDE:\n",
        "\n",
        "1. RUN THE CODE:\n",
        "   - Execute this entire cell/script\n",
        "   - It will initialize the quality checking system\n",
        "\n",
        "2. CHOOSE OPTION 1 FOR COMPLETE VALIDATION:\n",
        "   - Creates realistic traffic sample images\n",
        "   - Tests segmentation quality on each sample\n",
        "   - Provides detailed quality scores and grades\n",
        "   - Gives clear recommendation (Ready/Not Ready for video)\n",
        "\n",
        "3. CHOOSE OPTION 2 TO TEST YOUR OWN IMAGE:\n",
        "   - Upload your traffic image\n",
        "   - Get detailed quality analysis\n",
        "   - See if it's suitable for video processing\n",
        "\n",
        "4. INTERPRET RESULTS:\n",
        "   - Quality Score 0.6+ = Good for video processing\n",
        "   - Grade A/B = Excellent/Good quality\n",
        "   - Grade C/D = Needs improvement\n",
        "\n",
        "5. WHAT TO EXPECT:\n",
        "   ‚úÖ Good road surface detection\n",
        "   ‚úÖ Clear traffic element recognition\n",
        "   ‚úÖ Low fragmentation\n",
        "   ‚úÖ Coherent object boundaries\n",
        "\n",
        "This validation ensures your model will work well on videos before processing!\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VIDEO PROCESSING"
      ],
      "metadata": {
        "id": "cmSsG0C_pVkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# VIDEO PROCESSING - READY TO GO!\n",
        "# ===============================================================================\n",
        "# Your quality check PASSED with score 0.79 (Grade B+)\n",
        "# Now let's process your video with the validated model!\n",
        "# ===============================================================================\n",
        "\n",
        "import torch\n",
        "from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# For file upload in Colab\n",
        "try:\n",
        "    from google.colab import files\n",
        "    COLAB_ENV = True\n",
        "    print(\"‚úÖ Google Colab environment detected\")\n",
        "except ImportError:\n",
        "    COLAB_ENV = False\n",
        "    print(\"üì± Local environment detected\")\n",
        "\n",
        "class VideoSegmentationProcessor:\n",
        "    \"\"\"Ready-to-use video segmentation processor\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.processor = None\n",
        "        self.model = None\n",
        "        self.output_dir = \"./video_segmentation_output\"\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "\n",
        "        # Color mapping (same as quality check)\n",
        "        self.color_map = {\n",
        "            0: [128, 64, 128],   # road - purple\n",
        "            1: [244, 35, 232],   # sidewalk - pink\n",
        "            2: [70, 70, 70],     # building - gray\n",
        "            5: [153, 153, 153],  # pole - light gray\n",
        "            6: [250, 170, 30],   # traffic_light - orange\n",
        "            7: [220, 220, 0],    # traffic_sign - yellow\n",
        "            8: [107, 142, 35],   # vegetation - olive\n",
        "            10: [70, 130, 180],  # sky - steel blue\n",
        "            11: [220, 20, 60],   # person - crimson\n",
        "            13: [0, 0, 142],     # car - dark blue\n",
        "            14: [0, 0, 70],      # truck - darker blue\n",
        "            15: [0, 60, 100],    # bus - navy\n",
        "            17: [0, 0, 230],     # motorcycle - blue\n",
        "            18: [119, 11, 32],   # bicycle - dark red\n",
        "        }\n",
        "\n",
        "    def load_validated_model(self):\n",
        "        \"\"\"Load the same model that passed quality validation\"\"\"\n",
        "        print(\"üöÄ LOADING VALIDATED MODEL\")\n",
        "        print(\"=\" * 50)\n",
        "        print(\"Loading the same Cityscapes model that passed your quality check...\")\n",
        "\n",
        "        try:\n",
        "            model_name = \"nvidia/segformer-b0-finetuned-cityscapes-1024-1024\"\n",
        "            self.processor = SegformerImageProcessor.from_pretrained(model_name)\n",
        "            self.model = SegformerForSemanticSegmentation.from_pretrained(model_name)\n",
        "            self.model.to(self.device)\n",
        "            self.model.eval()\n",
        "\n",
        "            print(\"‚úÖ Model loaded successfully!\")\n",
        "            print(f\"üì± Device: {self.device}\")\n",
        "            print(\"üéØ Quality validated: Score 0.79 (Grade B+)\")\n",
        "            print(\"‚úÖ Ready for video processing!\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading model: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def predict_frame(self, frame_rgb):\n",
        "        \"\"\"Predict segmentation for a single frame\"\"\"\n",
        "        # Convert to PIL Image\n",
        "        image_pil = Image.fromarray(frame_rgb)\n",
        "\n",
        "        # Process\n",
        "        inputs = self.processor(image_pil, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "        # Predict\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "            predictions = torch.nn.functional.interpolate(\n",
        "                outputs.logits,\n",
        "                size=image_pil.size[::-1],\n",
        "                mode=\"bilinear\",\n",
        "                align_corners=False,\n",
        "            )\n",
        "            predicted_map = predictions.squeeze().cpu().numpy().argmax(axis=0)\n",
        "\n",
        "        return predicted_map\n",
        "\n",
        "    def create_colored_overlay(self, prediction, alpha=0.6):\n",
        "        \"\"\"Create colored segmentation overlay\"\"\"\n",
        "        h, w = prediction.shape\n",
        "        colored_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
        "\n",
        "        # Apply colors\n",
        "        for class_id, color in self.color_map.items():\n",
        "            mask = prediction == class_id\n",
        "            colored_mask[mask] = color\n",
        "\n",
        "        return colored_mask\n",
        "\n",
        "    def upload_video(self):\n",
        "        \"\"\"Upload video file (Colab version)\"\"\"\n",
        "        print(\"üì§ VIDEO UPLOAD\")\n",
        "        print(\"=\" * 30)\n",
        "\n",
        "        if not COLAB_ENV:\n",
        "            video_path = input(\"üìÅ Enter path to your video file: \").strip()\n",
        "            if not os.path.exists(video_path):\n",
        "                print(f\"‚ùå Video file not found: {video_path}\")\n",
        "                return None\n",
        "            return video_path\n",
        "\n",
        "        print(\"üìÅ Please select your traffic video to upload:\")\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        if not uploaded:\n",
        "            print(\"‚ùå No video uploaded!\")\n",
        "            return None\n",
        "\n",
        "        video_filename = list(uploaded.keys())[0]\n",
        "        print(f\"‚úÖ Uploaded: {video_filename}\")\n",
        "        return video_filename\n",
        "\n",
        "    def process_video(self, video_path, max_frames=None, blend_alpha=0.6):\n",
        "        \"\"\"Process video with validated segmentation model\"\"\"\n",
        "        print(f\"\\nüé¨ PROCESSING VIDEO: {video_path}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Open video\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        if not cap.isOpened():\n",
        "            print(f\"‚ùå Error opening video: {video_path}\")\n",
        "            return None\n",
        "\n",
        "        # Get video properties\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        if max_frames:\n",
        "            total_frames = min(total_frames, max_frames)\n",
        "\n",
        "        print(f\"üìπ Video Properties:\")\n",
        "        print(f\"  ‚Ä¢ Resolution: {width}x{height}\")\n",
        "        print(f\"  ‚Ä¢ FPS: {fps}\")\n",
        "        print(f\"  ‚Ä¢ Frames to process: {total_frames:,}\")\n",
        "        print(f\"  ‚Ä¢ Duration: {total_frames/fps:.1f} seconds\")\n",
        "\n",
        "        # Setup output video\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        output_filename = f\"segmented_traffic_video_{timestamp}.mp4\"\n",
        "        output_path = os.path.join(self.output_dir, output_filename)\n",
        "\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "        print(f\"üíæ Output: {output_path}\")\n",
        "        print(f\"üé® Blend alpha: {blend_alpha} (0=mask only, 1=original only)\")\n",
        "\n",
        "        # Process frames\n",
        "        print(\"\\n‚è≥ Processing frames...\")\n",
        "        frame_count = 0\n",
        "        start_time = time.time()\n",
        "\n",
        "        with tqdm(total=total_frames, desc=\"üé¨ Segmenting\", unit=\"frames\") as pbar:\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret or (max_frames and frame_count >= max_frames):\n",
        "                    break\n",
        "\n",
        "                # Convert BGR to RGB\n",
        "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                # Predict segmentation\n",
        "                prediction = self.predict_frame(frame_rgb)\n",
        "\n",
        "                # Create colored overlay\n",
        "                colored_mask = self.create_colored_overlay(prediction)\n",
        "\n",
        "                # Blend with original frame\n",
        "                blended = cv2.addWeighted(frame_rgb, blend_alpha, colored_mask, 1-blend_alpha, 0)\n",
        "\n",
        "                # Convert back to BGR and write\n",
        "                blended_bgr = cv2.cvtColor(blended, cv2.COLOR_RGB2BGR)\n",
        "                out.write(blended_bgr)\n",
        "\n",
        "                frame_count += 1\n",
        "                pbar.update(1)\n",
        "\n",
        "                # Update stats every 50 frames\n",
        "                if frame_count % 50 == 0:\n",
        "                    elapsed = time.time() - start_time\n",
        "                    current_fps = frame_count / elapsed\n",
        "                    remaining_frames = total_frames - frame_count\n",
        "                    eta_seconds = remaining_frames / current_fps if current_fps > 0 else 0\n",
        "\n",
        "                    pbar.set_postfix({\n",
        "                        'FPS': f'{current_fps:.1f}',\n",
        "                        'ETA': f'{eta_seconds/60:.1f}m'\n",
        "                    })\n",
        "\n",
        "        # Cleanup\n",
        "        cap.release()\n",
        "        out.release()\n",
        "\n",
        "        # Final statistics\n",
        "        total_time = time.time() - start_time\n",
        "        avg_fps = frame_count / total_time\n",
        "\n",
        "        print(f\"\\n‚úÖ VIDEO PROCESSING COMPLETED!\")\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"üìä Processing Statistics:\")\n",
        "        print(f\"  ‚Ä¢ Frames processed: {frame_count:,}\")\n",
        "        print(f\"  ‚Ä¢ Total time: {total_time/60:.1f} minutes\")\n",
        "        print(f\"  ‚Ä¢ Average FPS: {avg_fps:.1f}\")\n",
        "        print(f\"  ‚Ä¢ Output saved: {output_path}\")\n",
        "        print(f\"  ‚Ä¢ File size: {os.path.getsize(output_path)/1024/1024:.1f} MB\")\n",
        "\n",
        "        return output_path\n",
        "\n",
        "# ===============================================================================\n",
        "# MAIN VIDEO PROCESSING INTERFACE\n",
        "# ===============================================================================\n",
        "def main_video_processing():\n",
        "    \"\"\"Main interface for video processing\"\"\"\n",
        "    print(\"üé¨ VIDEO SEGMENTATION - QUALITY VALIDATED!\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"‚úÖ Your model passed quality check with score 0.79 (Grade B+)\")\n",
        "    print(\"üöÄ Ready to process your traffic video!\")\n",
        "\n",
        "    # Initialize processor\n",
        "    processor = VideoSegmentationProcessor()\n",
        "\n",
        "    # Load model\n",
        "    if not processor.load_validated_model():\n",
        "        print(\"‚ùå Failed to load model!\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nüéØ PROCESSING OPTIONS:\")\n",
        "    print(\"=\" * 30)\n",
        "    print(\"1. üì§ Upload and process video (full)\")\n",
        "    print(\"2. üìπ Process video from path\")\n",
        "    print(\"3. üß™ Process video (first 100 frames only - for testing)\")\n",
        "    print(\"4. ‚öôÔ∏è  Custom processing options\")\n",
        "    print(\"0. üö™ Exit\")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            choice = input(\"\\nüëâ Enter your choice (0-4): \").strip()\n",
        "\n",
        "            if choice == '0':\n",
        "                print(\"üëã Video processing session ended!\")\n",
        "                break\n",
        "\n",
        "            elif choice == '1':\n",
        "                # Upload and process full video\n",
        "                video_path = processor.upload_video()\n",
        "                if video_path:\n",
        "                    output_path = processor.process_video(video_path)\n",
        "                    if output_path:\n",
        "                        print(f\"\\nüéâ SUCCESS! Your segmented video is ready!\")\n",
        "                        print(f\"üìÅ Location: {output_path}\")\n",
        "\n",
        "            elif choice == '2':\n",
        "                # Process from path\n",
        "                video_path = input(\"üìÅ Enter video file path: \").strip()\n",
        "                if video_path and os.path.exists(video_path):\n",
        "                    output_path = processor.process_video(video_path)\n",
        "                    if output_path:\n",
        "                        print(f\"\\nüéâ SUCCESS! Your segmented video is ready!\")\n",
        "                        print(f\"üìÅ Location: {output_path}\")\n",
        "                else:\n",
        "                    print(\"‚ùå Video file not found!\")\n",
        "\n",
        "            elif choice == '3':\n",
        "                # Test with first 100 frames\n",
        "                video_path = processor.upload_video() if COLAB_ENV else input(\"üìÅ Enter video path: \").strip()\n",
        "                if video_path:\n",
        "                    print(\"üß™ Processing first 100 frames for testing...\")\n",
        "                    output_path = processor.process_video(video_path, max_frames=100)\n",
        "                    if output_path:\n",
        "                        print(f\"\\nüéâ TEST COMPLETE! Sample video created!\")\n",
        "                        print(f\"üìÅ Location: {output_path}\")\n",
        "\n",
        "            elif choice == '4':\n",
        "                # Custom options\n",
        "                video_path = input(\"üìÅ Enter video path: \").strip()\n",
        "                if not os.path.exists(video_path):\n",
        "                    print(\"‚ùå Video file not found!\")\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    max_frames = input(\"üé¨ Max frames (or press Enter for all): \").strip()\n",
        "                    max_frames = int(max_frames) if max_frames else None\n",
        "\n",
        "                    blend_alpha = input(\"üé® Blend ratio 0.0-1.0 (0.6 default): \").strip()\n",
        "                    blend_alpha = float(blend_alpha) if blend_alpha else 0.6\n",
        "\n",
        "                    output_path = processor.process_video(video_path, max_frames, blend_alpha)\n",
        "                    if output_path:\n",
        "                        print(f\"\\nüéâ SUCCESS! Custom processed video ready!\")\n",
        "                        print(f\"üìÅ Location: {output_path}\")\n",
        "\n",
        "                except ValueError:\n",
        "                    print(\"‚ùå Invalid input values!\")\n",
        "\n",
        "            else:\n",
        "                print(\"‚ùå Invalid choice. Please try again.\")\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n‚èπÔ∏è Operation cancelled by user\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error: {str(e)}\")\n",
        "\n",
        "# ===============================================================================\n",
        "# QUICK START EXECUTION\n",
        "# ===============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"üéâ CONGRATULATIONS!\")\n",
        "    print(\"Your segmentation model passed quality validation!\")\n",
        "    print(\"Score: 0.79 (Grade B+) ‚úÖ\")\n",
        "    print(\"\\nStarting video processing...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    main_video_processing()\n",
        "\n",
        "# ===============================================================================\n",
        "# USAGE SUMMARY\n",
        "# ===============================================================================\n",
        "\"\"\"\n",
        "üéØ SUMMARY - YOU'RE READY!\n",
        "\n",
        "‚úÖ QUALITY CHECK PASSED: Score 0.79 (Grade B+)\n",
        "‚úÖ MODEL VALIDATED: Much better than your previous YOLO approach\n",
        "‚úÖ READY FOR VIDEO: No more fragmented, noisy results\n",
        "\n",
        "RECOMMENDED WORKFLOW:\n",
        "1. Choose option 3 first (test with 100 frames)\n",
        "2. Check the sample output quality\n",
        "3. If satisfied, process your full video with option 1 or 2\n",
        "\n",
        "EXPECTED IMPROVEMENTS:\n",
        "‚úÖ Clean road surface detection (no more blue noise)\n",
        "‚úÖ Proper traffic light/sign recognition\n",
        "‚úÖ Coherent vehicle boundaries\n",
        "‚úÖ Realistic background segmentation\n",
        "\n",
        "Your video processing should now give you the clean,\n",
        "professional results you were looking for! üöÄ\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "A3B3vdZxpQgQ",
        "outputId": "2940f635-9218-41f5-b207-69dcc11e3ae5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Google Colab environment detected\n",
            "üéâ CONGRATULATIONS!\n",
            "Your segmentation model passed quality validation!\n",
            "Score: 0.79 (Grade B+) ‚úÖ\n",
            "\n",
            "Starting video processing...\n",
            "============================================================\n",
            "üé¨ VIDEO SEGMENTATION - QUALITY VALIDATED!\n",
            "============================================================\n",
            "‚úÖ Your model passed quality check with score 0.79 (Grade B+)\n",
            "üöÄ Ready to process your traffic video!\n",
            "üöÄ LOADING VALIDATED MODEL\n",
            "==================================================\n",
            "Loading the same Cityscapes model that passed your quality check...\n",
            "‚úÖ Model loaded successfully!\n",
            "üì± Device: cpu\n",
            "üéØ Quality validated: Score 0.79 (Grade B+)\n",
            "‚úÖ Ready for video processing!\n",
            "\n",
            "üéØ PROCESSING OPTIONS:\n",
            "==============================\n",
            "1. üì§ Upload and process video (full)\n",
            "2. üìπ Process video from path\n",
            "3. üß™ Process video (first 100 frames only - for testing)\n",
            "4. ‚öôÔ∏è  Custom processing options\n",
            "0. üö™ Exit\n",
            "\n",
            "üëâ Enter your choice (0-4): 1\n",
            "üì§ VIDEO UPLOAD\n",
            "==============================\n",
            "üìÅ Please select your traffic video to upload:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-376a78ee-3c36-4a5b-88a3-2ba28886ac59\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-376a78ee-3c36-4a5b-88a3-2ba28886ac59\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Sunny day.mp4 to Sunny day.mp4\n",
            "‚úÖ Uploaded: Sunny day.mp4\n",
            "\n",
            "üé¨ PROCESSING VIDEO: Sunny day.mp4\n",
            "============================================================\n",
            "üìπ Video Properties:\n",
            "  ‚Ä¢ Resolution: 1600x720\n",
            "  ‚Ä¢ FPS: 24\n",
            "  ‚Ä¢ Frames to process: 2,226\n",
            "  ‚Ä¢ Duration: 92.8 seconds\n",
            "üíæ Output: ./video_segmentation_output/segmented_traffic_video_20250816_021323.mp4\n",
            "üé® Blend alpha: 0.6 (0=mask only, 1=original only)\n",
            "\n",
            "‚è≥ Processing frames...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üé¨ Segmenting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2226/2226 [46:27<00:00,  1.25s/frames, FPS=0.8, ETA=0.5m]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ VIDEO PROCESSING COMPLETED!\n",
            "==================================================\n",
            "üìä Processing Statistics:\n",
            "  ‚Ä¢ Frames processed: 2,226\n",
            "  ‚Ä¢ Total time: 46.5 minutes\n",
            "  ‚Ä¢ Average FPS: 0.8\n",
            "  ‚Ä¢ Output saved: ./video_segmentation_output/segmented_traffic_video_20250816_021323.mp4\n",
            "  ‚Ä¢ File size: 99.8 MB\n",
            "\n",
            "üéâ SUCCESS! Your segmented video is ready!\n",
            "üìÅ Location: ./video_segmentation_output/segmented_traffic_video_20250816_021323.mp4\n",
            "\n",
            "üëâ Enter your choice (0-4): 0\n",
            "üëã Video processing session ended!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nüéØ SUMMARY - YOU'RE READY!\\n\\n‚úÖ QUALITY CHECK PASSED: Score 0.79 (Grade B+)\\n‚úÖ MODEL VALIDATED: Much better than your previous YOLO approach\\n‚úÖ READY FOR VIDEO: No more fragmented, noisy results\\n\\nRECOMMENDED WORKFLOW:\\n1. Choose option 3 first (test with 100 frames)\\n2. Check the sample output quality\\n3. If satisfied, process your full video with option 1 or 2\\n\\nEXPECTED IMPROVEMENTS:\\n‚úÖ Clean road surface detection (no more blue noise)\\n‚úÖ Proper traffic light/sign recognition\\n‚úÖ Coherent vehicle boundaries  \\n‚úÖ Realistic background segmentation\\n\\nYour video processing should now give you the clean, \\nprofessional results you were looking for! üöÄ\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Traing with labeling Data"
      ],
      "metadata": {
        "id": "HXcowBvr32AE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "YOLO Training Tool - Multi-Version Support with Fixed Dataset and File Handling\n",
        "\n",
        "Supports YOLOv8, YOLOv9, YOLOv10, and YOLO11 with automatic version detection.\n",
        "\n",
        "For Jupyter/Colab users, use the simple function:\n",
        "    model_path = train_yolo_simple(\"/path/to/data.zip\", classes=\"all\", epochs=100)\n",
        "    model_path = train_yolo_simple(\"/path/to/data.zip\", classes=\"0,2,5\", epochs=50, model=\"yolov8n.pt\")\n",
        "    model_path = train_yolo_simple(\"/path/to/data.zip\", model=\"yolov10m.pt\", yolo_version=\"yolov10\")\n",
        "\n",
        "For command line usage:\n",
        "    python yolo11_trainer.py --cli\n",
        "    python yolo11_trainer.py --zip data.zip --classes all --epochs 100 --model yolov8s.pt\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import zipfile\n",
        "import json\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "import threading\n",
        "import shutil\n",
        "import argparse\n",
        "import subprocess\n",
        "import random\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "# Suppress common warnings that clutter the output\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.*\")\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"torch.*\")\n",
        "\n",
        "# These will be imported after checking if they're available\n",
        "# import torch\n",
        "# from ultralytics import YOLO\n",
        "\n",
        "# Try to import tkinter, handle if no display available\n",
        "GUI_AVAILABLE = True\n",
        "try:\n",
        "    import tkinter as tk\n",
        "    from tkinter import ttk, filedialog, messagebox, scrolledtext\n",
        "    # Test if display is available\n",
        "    root_test = tk.Tk()\n",
        "    root_test.withdraw()\n",
        "    root_test.destroy()\n",
        "except (ImportError, tk.TclError) as e:\n",
        "    GUI_AVAILABLE = False\n",
        "    print(\"=\" * 60)\n",
        "    print(\"YOLO11 Training Tool\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"GUI not available: {e}\")\n",
        "    print(\"Running in command-line mode...\")\n",
        "    print(\"\\nTo enable GUI:\")\n",
        "    print(\"- On Linux/WSL: Install X server (Xming, VcXsrv, or X11)\")\n",
        "    print(\"- On SSH: Use 'ssh -X' for X11 forwarding\")\n",
        "    print(\"- On headless servers: Use CLI mode with --cli flag\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "def check_and_install_packages():\n",
        "    \"\"\"Check and install required packages with better error handling\"\"\"\n",
        "    missing_packages = []\n",
        "    installation_commands = []\n",
        "\n",
        "    print(\"üîç Checking required packages...\")\n",
        "\n",
        "    # Check PyTorch\n",
        "    try:\n",
        "        import torch\n",
        "        print(f\"‚úÖ PyTorch {torch.__version__} is available\")\n",
        "\n",
        "        # Check CUDA availability with better error handling\n",
        "        if torch.cuda.is_available():\n",
        "            gpu_count = torch.cuda.device_count()\n",
        "            print(f\"‚úÖ CUDA available with {gpu_count} GPU(s)\")\n",
        "            for i in range(gpu_count):\n",
        "                try:\n",
        "                    gpu_name = torch.cuda.get_device_name(i)\n",
        "                    print(f\"   GPU {i}: {gpu_name}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"   GPU {i}: Unknown (error: {e})\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è  CUDA not available - will use CPU\")\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"‚ùå PyTorch not found\")\n",
        "        missing_packages.append(\"torch\")\n",
        "        installation_commands.append(\"pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\")\n",
        "\n",
        "    # Check Ultralytics\n",
        "    try:\n",
        "        import ultralytics\n",
        "        print(f\"‚úÖ Ultralytics {ultralytics.__version__} is available\")\n",
        "    except ImportError:\n",
        "        print(\"‚ùå Ultralytics not found\")\n",
        "        missing_packages.append(\"ultralytics\")\n",
        "        installation_commands.append(\"pip install ultralytics\")\n",
        "\n",
        "    # Install missing packages\n",
        "    if missing_packages:\n",
        "        print(f\"\\nüì¶ Installing {len(missing_packages)} missing package(s)...\")\n",
        "\n",
        "        for i, cmd in enumerate(installation_commands):\n",
        "            package_name = missing_packages[i]\n",
        "            print(f\"\\n‚è≥ Installing {package_name}...\")\n",
        "\n",
        "            try:\n",
        "                # Use subprocess with better error handling\n",
        "                result = subprocess.run(\n",
        "                    cmd.split(),\n",
        "                    capture_output=True,\n",
        "                    text=True,\n",
        "                    timeout=300  # 5 minute timeout\n",
        "                )\n",
        "\n",
        "                if result.returncode == 0:\n",
        "                    print(f\"‚úÖ {package_name} installed successfully\")\n",
        "                else:\n",
        "                    print(f\"‚ùå Failed to install {package_name}\")\n",
        "                    print(f\"Error: {result.stderr}\")\n",
        "                    return False\n",
        "\n",
        "            except subprocess.TimeoutExpired:\n",
        "                print(f\"‚ùå Installation of {package_name} timed out\")\n",
        "                return False\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error installing {package_name}: {e}\")\n",
        "                return False\n",
        "\n",
        "        print(\"\\nüîÑ Reloading modules...\")\n",
        "        # Try to import again after installation\n",
        "        try:\n",
        "            import torch\n",
        "            from ultralytics import YOLO\n",
        "            print(\"‚úÖ All packages loaded successfully\")\n",
        "        except ImportError as e:\n",
        "            print(f\"‚ùå Still missing packages after installation: {e}\")\n",
        "            return False\n",
        "\n",
        "    return True\n",
        "\n",
        "class FileHandler:\n",
        "    \"\"\"Handles file operations with improved error handling\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def normalize_path(file_path):\n",
        "        \"\"\"Normalize and clean file path\"\"\"\n",
        "        if not file_path:\n",
        "            return \"\"\n",
        "\n",
        "        # Remove quotes and whitespace\n",
        "        file_path = file_path.strip().strip('\"\\'')\n",
        "\n",
        "        # Handle different path formats\n",
        "        if file_path.startswith('\\\\\\\\'):\n",
        "            # UNC path\n",
        "            return file_path\n",
        "\n",
        "        # Normalize path separators\n",
        "        file_path = os.path.normpath(file_path)\n",
        "\n",
        "        # Convert to absolute path if relative\n",
        "        if not os.path.isabs(file_path):\n",
        "            file_path = os.path.abspath(file_path)\n",
        "\n",
        "        return file_path\n",
        "\n",
        "    @staticmethod\n",
        "    def check_file_access(file_path):\n",
        "        \"\"\"Check if file exists and is accessible\"\"\"\n",
        "        try:\n",
        "            # Check existence\n",
        "            if not os.path.exists(file_path):\n",
        "                return False, f\"File does not exist: {file_path}\"\n",
        "\n",
        "            # Check if it's a file (not directory)\n",
        "            if not os.path.isfile(file_path):\n",
        "                return False, f\"Path is not a file: {file_path}\"\n",
        "\n",
        "            # Check read permissions\n",
        "            if not os.access(file_path, os.R_OK):\n",
        "                return False, f\"No read permission for file: {file_path}\"\n",
        "\n",
        "            # Check file size\n",
        "            file_size = os.path.getsize(file_path)\n",
        "            if file_size == 0:\n",
        "                return False, f\"File is empty: {file_path}\"\n",
        "\n",
        "            return True, f\"File accessible, size: {file_size:,} bytes\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return False, f\"Error checking file: {str(e)}\"\n",
        "\n",
        "    @staticmethod\n",
        "    def is_valid_zip_detailed(file_path):\n",
        "        \"\"\"Check if file is a valid ZIP archive with detailed reporting\"\"\"\n",
        "        try:\n",
        "            # Basic file checks first\n",
        "            accessible, msg = FileHandler.check_file_access(file_path)\n",
        "            if not accessible:\n",
        "                return False, msg\n",
        "\n",
        "            print(f\"üìÅ Checking ZIP file: {os.path.basename(file_path)}\")\n",
        "            print(f\"   Path: {file_path}\")\n",
        "            print(f\"   {msg}\")\n",
        "\n",
        "            # Try to read as ZIP\n",
        "            try:\n",
        "                with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "                    # Get file list\n",
        "                    file_list = zip_ref.namelist()\n",
        "                    if not file_list:\n",
        "                        return False, \"ZIP file is empty\"\n",
        "\n",
        "                    print(f\"   üìã Contains {len(file_list)} files/folders\")\n",
        "\n",
        "                    # Test ZIP integrity\n",
        "                    print(\"   üîç Testing ZIP integrity...\")\n",
        "                    bad_file = zip_ref.testzip()\n",
        "                    if bad_file:\n",
        "                        return False, f\"ZIP contains corrupted file: {bad_file}\"\n",
        "\n",
        "                    # Count relevant files\n",
        "                    image_files = []\n",
        "                    label_files = []\n",
        "                    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.webp'}\n",
        "\n",
        "                    for filename in file_list:\n",
        "                        if filename.lower().endswith(tuple(image_extensions)):\n",
        "                            image_files.append(filename)\n",
        "                        elif filename.lower().endswith('.txt') and not filename.lower().endswith('classes.txt'):\n",
        "                            label_files.append(filename)\n",
        "\n",
        "                    print(f\"   üñºÔ∏è  Found {len(image_files)} image files\")\n",
        "                    print(f\"   üè∑Ô∏è  Found {len(label_files)} label files\")\n",
        "\n",
        "                    if len(image_files) == 0:\n",
        "                        return False, \"No image files found in ZIP\"\n",
        "\n",
        "                    return True, f\"Valid ZIP with {len(image_files)} images and {len(label_files)} labels\"\n",
        "\n",
        "            except zipfile.BadZipFile:\n",
        "                return False, \"File is not a valid ZIP archive\"\n",
        "            except Exception as e:\n",
        "                return False, f\"Error reading ZIP file: {str(e)}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return False, f\"Unexpected error: {str(e)}\"\n",
        "\n",
        "    @staticmethod\n",
        "    def find_files_interactive():\n",
        "        \"\"\"Interactive file finder with suggestions\"\"\"\n",
        "        print(\"\\nüîç File Path Helper\")\n",
        "        print(\"Let's find your ZIP file step by step...\")\n",
        "\n",
        "        # Check current directory\n",
        "        current_dir = os.getcwd()\n",
        "        print(f\"\\nüìÅ Current directory: {current_dir}\")\n",
        "\n",
        "        # Look for ZIP files in current directory\n",
        "        zip_files = []\n",
        "        try:\n",
        "            for file in os.listdir(current_dir):\n",
        "                if file.lower().endswith('.zip'):\n",
        "                    zip_files.append(file)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        if zip_files:\n",
        "            print(f\"üéØ Found {len(zip_files)} ZIP file(s) in current directory:\")\n",
        "            for i, file in enumerate(zip_files):\n",
        "                file_path = os.path.join(current_dir, file)\n",
        "                size = os.path.getsize(file_path)\n",
        "                print(f\"   {i+1}. {file} ({size:,} bytes)\")\n",
        "\n",
        "            try:\n",
        "                choice = input(f\"\\nEnter number (1-{len(zip_files)}) to select, or 'c' to continue with custom path: \").strip()\n",
        "                if choice.isdigit() and 1 <= int(choice) <= len(zip_files):\n",
        "                    selected_file = os.path.join(current_dir, zip_files[int(choice)-1])\n",
        "                    print(f\"‚úÖ Selected: {selected_file}\")\n",
        "                    return selected_file\n",
        "            except KeyboardInterrupt:\n",
        "                raise\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        # Check common directories\n",
        "        common_dirs = []\n",
        "        home_dir = os.path.expanduser(\"~\")\n",
        "        if os.path.exists(home_dir):\n",
        "            common_dirs.append((\"Home\", home_dir))\n",
        "\n",
        "            # Check Downloads folder\n",
        "            downloads_dir = os.path.join(home_dir, \"Downloads\")\n",
        "            if os.path.exists(downloads_dir):\n",
        "                common_dirs.append((\"Downloads\", downloads_dir))\n",
        "\n",
        "            # Check Desktop\n",
        "            desktop_dir = os.path.join(home_dir, \"Desktop\")\n",
        "            if os.path.exists(desktop_dir):\n",
        "                common_dirs.append((\"Desktop\", desktop_dir))\n",
        "\n",
        "            # Check OneDrive Desktop (Windows)\n",
        "            onedrive_desktop = os.path.join(home_dir, \"OneDrive\", \"Î∞îÌÉï ÌôîÎ©¥\")\n",
        "            if os.path.exists(onedrive_desktop):\n",
        "                common_dirs.append((\"OneDrive Desktop\", onedrive_desktop))\n",
        "\n",
        "        # Check for ZIP files in common directories\n",
        "        for dir_name, dir_path in common_dirs:\n",
        "            try:\n",
        "                zip_files_in_dir = [f for f in os.listdir(dir_path) if f.lower().endswith('.zip')]\n",
        "                if zip_files_in_dir:\n",
        "                    print(f\"\\nüìÇ Found ZIP files in {dir_name} ({dir_path}):\")\n",
        "                    for file in zip_files_in_dir[:5]:  # Show first 5\n",
        "                        file_path = os.path.join(dir_path, file)\n",
        "                        try:\n",
        "                            size = os.path.getsize(file_path)\n",
        "                            print(f\"   ‚Ä¢ {file} ({size:,} bytes)\")\n",
        "                        except Exception:\n",
        "                            print(f\"   ‚Ä¢ {file}\")\n",
        "                    if len(zip_files_in_dir) > 5:\n",
        "                        print(f\"   ... and {len(zip_files_in_dir) - 5} more\")\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "        print(f\"\\nüí° Tips for entering file path:\")\n",
        "        print(f\"   ‚Ä¢ Use forward slashes (/) or double backslashes (\\\\\\\\)\")\n",
        "        print(f\"   ‚Ä¢ Drag and drop the file into terminal (if supported)\")\n",
        "        print(f\"   ‚Ä¢ Use quotes if path contains spaces\")\n",
        "        print(f\"   ‚Ä¢ Use Tab for auto-completion (if supported)\")\n",
        "\n",
        "        return None\n",
        "\n",
        "class DatasetManager:\n",
        "    \"\"\"Handles all dataset operations with robust error handling\"\"\"\n",
        "\n",
        "    def __init__(self, log_func=print):\n",
        "        self.log = log_func\n",
        "        self.image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.webp'}\n",
        "\n",
        "    def analyze_dataset_structure(self, extract_path):\n",
        "        \"\"\"Analyze and report dataset structure with detailed logging\"\"\"\n",
        "        self.log(\"üîç Analyzing dataset structure...\")\n",
        "\n",
        "        structure_info = {\n",
        "            'images': [],\n",
        "            'labels': [],\n",
        "            'image_dirs': {},\n",
        "            'label_dirs': {},\n",
        "            'total_images': 0,\n",
        "            'total_labels': 0,\n",
        "            'class_ids': set()\n",
        "        }\n",
        "\n",
        "        # Walk through all directories\n",
        "        for root, dirs, files in os.walk(extract_path):\n",
        "            rel_root = os.path.relpath(root, extract_path)\n",
        "            if rel_root == '.':\n",
        "                rel_root = 'root'\n",
        "\n",
        "            # Count images and labels in this directory\n",
        "            images_in_dir = []\n",
        "            labels_in_dir = []\n",
        "\n",
        "            for file in files:\n",
        "                file_lower = file.lower()\n",
        "                if any(file_lower.endswith(ext) for ext in self.image_extensions):\n",
        "                    images_in_dir.append(file)\n",
        "                    structure_info['images'].append(os.path.join(root, file))\n",
        "                elif file_lower.endswith('.txt') and file_lower not in ['classes.txt', 'readme.txt']:\n",
        "                    labels_in_dir.append(file)\n",
        "                    structure_info['labels'].append(os.path.join(root, file))\n",
        "\n",
        "                    # Extract class IDs from this label file\n",
        "                    try:\n",
        "                        with open(os.path.join(root, file), 'r') as f:\n",
        "                            for line in f:\n",
        "                                if line.strip():\n",
        "                                    parts = line.split()\n",
        "                                    if len(parts) >= 5:\n",
        "                                        try:\n",
        "                                            class_id = int(parts[0])\n",
        "                                            structure_info['class_ids'].add(class_id)\n",
        "                                        except ValueError:\n",
        "                                            continue\n",
        "                    except Exception:\n",
        "                        pass\n",
        "\n",
        "            if images_in_dir:\n",
        "                structure_info['image_dirs'][rel_root] = len(images_in_dir)\n",
        "                structure_info['total_images'] += len(images_in_dir)\n",
        "\n",
        "            if labels_in_dir:\n",
        "                structure_info['label_dirs'][rel_root] = len(labels_in_dir)\n",
        "                structure_info['total_labels'] += len(labels_in_dir)\n",
        "\n",
        "        # Report findings\n",
        "        self.log(f\"üìä Dataset Analysis Complete:\")\n",
        "        self.log(f\"   üñºÔ∏è  Total images: {structure_info['total_images']}\")\n",
        "        self.log(f\"   üè∑Ô∏è  Total labels: {structure_info['total_labels']}\")\n",
        "        self.log(f\"   üéØ Unique classes: {len(structure_info['class_ids'])}\")\n",
        "\n",
        "        if structure_info['image_dirs']:\n",
        "            self.log(f\"   üìÅ Image directories:\")\n",
        "            for dir_name, count in structure_info['image_dirs'].items():\n",
        "                self.log(f\"      {dir_name}: {count} images\")\n",
        "\n",
        "        if structure_info['label_dirs']:\n",
        "            self.log(f\"   üìÇ Label directories:\")\n",
        "            for dir_name, count in structure_info['label_dirs'].items():\n",
        "                self.log(f\"      {dir_name}: {count} labels\")\n",
        "\n",
        "        return structure_info\n",
        "\n",
        "    def create_yolo_structure(self, base_path):\n",
        "        \"\"\"Create YOLO directory structure\"\"\"\n",
        "        yolo_dirs = {\n",
        "            'train_images': os.path.join(base_path, 'train', 'images'),\n",
        "            'train_labels': os.path.join(base_path, 'train', 'labels'),\n",
        "            'val_images': os.path.join(base_path, 'val', 'images'),\n",
        "            'val_labels': os.path.join(base_path, 'val', 'labels'),\n",
        "            'test_images': os.path.join(base_path, 'test', 'images'),\n",
        "            'test_labels': os.path.join(base_path, 'test', 'labels')\n",
        "        }\n",
        "\n",
        "        # Create all directories\n",
        "        for dir_name, dir_path in yolo_dirs.items():\n",
        "            os.makedirs(dir_path, exist_ok=True)\n",
        "            self.log(f\"   üìÅ Created: {os.path.relpath(dir_path, base_path)}\")\n",
        "\n",
        "        return yolo_dirs\n",
        "\n",
        "    def find_image_label_pairs(self, structure_info):\n",
        "        \"\"\"Find matching image-label pairs\"\"\"\n",
        "        self.log(\"üîç Finding image-label pairs...\")\n",
        "\n",
        "        image_label_pairs = []\n",
        "        unmatched_images = []\n",
        "\n",
        "        for img_path in structure_info['images']:\n",
        "            img_name = os.path.basename(img_path)\n",
        "            img_name_no_ext = os.path.splitext(img_name)[0]\n",
        "\n",
        "            # Look for corresponding label file\n",
        "            label_path = None\n",
        "            for lbl_path in structure_info['labels']:\n",
        "                lbl_name = os.path.basename(lbl_path)\n",
        "                lbl_name_no_ext = os.path.splitext(lbl_name)[0]\n",
        "\n",
        "                if img_name_no_ext == lbl_name_no_ext:\n",
        "                    label_path = lbl_path\n",
        "                    break\n",
        "\n",
        "            if label_path and os.path.exists(label_path):\n",
        "                image_label_pairs.append((img_path, label_path, img_name))\n",
        "            else:\n",
        "                unmatched_images.append(img_name)\n",
        "\n",
        "        self.log(f\"‚úÖ Found {len(image_label_pairs)} valid image-label pairs\")\n",
        "        if unmatched_images:\n",
        "            self.log(f\"‚ö†Ô∏è  {len(unmatched_images)} images without labels\")\n",
        "            if len(unmatched_images) <= 10:\n",
        "                for img in unmatched_images[:10]:\n",
        "                    self.log(f\"      {img}\")\n",
        "            else:\n",
        "                for img in unmatched_images[:5]:\n",
        "                    self.log(f\"      {img}\")\n",
        "                self.log(f\"      ... and {len(unmatched_images) - 5} more\")\n",
        "\n",
        "        return image_label_pairs\n",
        "\n",
        "    def split_dataset(self, image_label_pairs, train_ratio=0.7, val_ratio=0.2):\n",
        "        \"\"\"Split dataset into train/val/test with minimum validation guarantee\"\"\"\n",
        "        if len(image_label_pairs) == 0:\n",
        "            return {'train': [], 'val': [], 'test': []}\n",
        "\n",
        "        # Shuffle for random split\n",
        "        random.shuffle(image_label_pairs)\n",
        "        total_pairs = len(image_label_pairs)\n",
        "\n",
        "        # Ensure minimum validation set size\n",
        "        min_val_size = max(1, min(10, total_pairs // 10))  # At least 1, max 10, or 10% of dataset\n",
        "\n",
        "        if total_pairs < 3:\n",
        "            # Very small dataset - put most in training, at least 1 in validation\n",
        "            if total_pairs == 1:\n",
        "                splits = {'train': image_label_pairs, 'val': [], 'test': []}\n",
        "            elif total_pairs == 2:\n",
        "                splits = {'train': image_label_pairs[:1], 'val': image_label_pairs[1:], 'test': []}\n",
        "            else:  # total_pairs == 3\n",
        "                splits = {'train': image_label_pairs[:2], 'val': image_label_pairs[2:], 'test': []}\n",
        "        else:\n",
        "            # Calculate split points\n",
        "            val_size = max(min_val_size, int(total_pairs * val_ratio))\n",
        "            test_size = max(1, int(total_pairs * (1 - train_ratio - val_ratio)))\n",
        "            train_size = total_pairs - val_size - test_size\n",
        "\n",
        "            # Ensure train_size is positive\n",
        "            if train_size < 1:\n",
        "                train_size = total_pairs - val_size\n",
        "                test_size = 0\n",
        "\n",
        "            train_end = train_size\n",
        "            val_end = train_size + val_size\n",
        "\n",
        "            splits = {\n",
        "                'train': image_label_pairs[:train_end],\n",
        "                'val': image_label_pairs[train_end:val_end],\n",
        "                'test': image_label_pairs[val_end:] if test_size > 0 else []\n",
        "            }\n",
        "\n",
        "        self.log(f\"üìä Dataset split:\")\n",
        "        self.log(f\"   üèãÔ∏è  Training: {len(splits['train'])} samples ({len(splits['train'])/total_pairs*100:.1f}%)\")\n",
        "        self.log(f\"   ‚úÖ Validation: {len(splits['val'])} samples ({len(splits['val'])/total_pairs*100:.1f}%)\")\n",
        "        if splits['test']:\n",
        "            self.log(f\"   üß™ Test: {len(splits['test'])} samples ({len(splits['test'])/total_pairs*100:.1f}%)\")\n",
        "\n",
        "        return splits\n",
        "\n",
        "    def copy_files_to_splits(self, splits, yolo_dirs):\n",
        "        \"\"\"Copy files to train/val/test directories\"\"\"\n",
        "        self.log(\"üìã Copying files to YOLO structure...\")\n",
        "\n",
        "        total_copied = 0\n",
        "\n",
        "        for split_name, pairs in splits.items():\n",
        "            if len(pairs) == 0:\n",
        "                continue\n",
        "\n",
        "            img_dir = yolo_dirs[f'{split_name}_images']\n",
        "            lbl_dir = yolo_dirs[f'{split_name}_labels']\n",
        "\n",
        "            split_copied = 0\n",
        "\n",
        "            for img_path, lbl_path, img_name in pairs:\n",
        "                try:\n",
        "                    # Copy image\n",
        "                    if os.path.exists(img_path):\n",
        "                        shutil.copy2(img_path, img_dir)\n",
        "                        split_copied += 1\n",
        "                        total_copied += 1\n",
        "                    else:\n",
        "                        self.log(f\"‚ö†Ô∏è  Image not found: {img_path}\")\n",
        "                        continue\n",
        "\n",
        "                    # Copy label\n",
        "                    if lbl_path and os.path.exists(lbl_path):\n",
        "                        shutil.copy2(lbl_path, lbl_dir)\n",
        "                    else:\n",
        "                        self.log(f\"‚ö†Ô∏è  Label not found for: {img_name}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    self.log(f\"‚ùå Error copying {img_name}: {e}\")\n",
        "                    continue\n",
        "\n",
        "            self.log(f\"   {split_name}: {split_copied} files copied\")\n",
        "\n",
        "        return total_copied > 0\n",
        "\n",
        "    def reorganize_dataset(self, extract_path, structure_info):\n",
        "        \"\"\"Complete dataset reorganization with robust error handling\"\"\"\n",
        "        self.log(\"üîÑ Reorganizing dataset to YOLO format...\")\n",
        "\n",
        "        # Create YOLO directory structure\n",
        "        yolo_dirs = self.create_yolo_structure(extract_path)\n",
        "\n",
        "        # Find image-label pairs\n",
        "        image_label_pairs = self.find_image_label_pairs(structure_info)\n",
        "\n",
        "        if len(image_label_pairs) == 0:\n",
        "            self.log(\"‚ùå No valid image-label pairs found!\")\n",
        "            return False\n",
        "\n",
        "        # Check if dataset already has splits\n",
        "        has_existing_splits = self.check_existing_splits(structure_info)\n",
        "\n",
        "        if has_existing_splits:\n",
        "            self.log(\"‚úÖ Preserving existing train/val splits\")\n",
        "            success = self.preserve_existing_splits(structure_info, yolo_dirs)\n",
        "        else:\n",
        "            self.log(\"üîÄ Creating new train/val/test splits\")\n",
        "            splits = self.split_dataset(image_label_pairs)\n",
        "            success = self.copy_files_to_splits(splits, yolo_dirs)\n",
        "\n",
        "        if not success:\n",
        "            return False\n",
        "\n",
        "        # Verify the reorganization\n",
        "        return self.verify_dataset_structure(yolo_dirs)\n",
        "\n",
        "    def check_existing_splits(self, structure_info):\n",
        "        \"\"\"Check if dataset already has train/val directory structure\"\"\"\n",
        "        has_train = any('train' in dir_name.lower() for dir_name in structure_info['image_dirs'].keys())\n",
        "        has_val = any('val' in dir_name.lower() or 'valid' in dir_name.lower() for dir_name in structure_info['image_dirs'].keys())\n",
        "        return has_train and has_val\n",
        "\n",
        "    def preserve_existing_splits(self, structure_info, yolo_dirs):\n",
        "        \"\"\"Preserve existing train/val/test splits\"\"\"\n",
        "        files_copied = 0\n",
        "\n",
        "        for img_path in structure_info['images']:\n",
        "            img_name = os.path.basename(img_path)\n",
        "            img_name_no_ext = os.path.splitext(img_name)[0]\n",
        "\n",
        "            if not os.path.exists(img_path):\n",
        "                continue\n",
        "\n",
        "            # Determine split based on directory path\n",
        "            dir_path = os.path.dirname(img_path).lower()\n",
        "\n",
        "            if 'train' in dir_path:\n",
        "                dest_img_dir = yolo_dirs['train_images']\n",
        "                dest_lbl_dir = yolo_dirs['train_labels']\n",
        "            elif 'val' in dir_path or 'valid' in dir_path:\n",
        "                dest_img_dir = yolo_dirs['val_images']\n",
        "                dest_lbl_dir = yolo_dirs['val_labels']\n",
        "            elif 'test' in dir_path:\n",
        "                dest_img_dir = yolo_dirs['test_images']\n",
        "                dest_lbl_dir = yolo_dirs['test_labels']\n",
        "            else:\n",
        "                # Default to train if unclear\n",
        "                dest_img_dir = yolo_dirs['train_images']\n",
        "                dest_lbl_dir = yolo_dirs['train_labels']\n",
        "\n",
        "            try:\n",
        "                # Copy image\n",
        "                shutil.copy2(img_path, dest_img_dir)\n",
        "                files_copied += 1\n",
        "\n",
        "                # Find and copy corresponding label\n",
        "                for lbl_path in structure_info['labels']:\n",
        "                    lbl_name = os.path.basename(lbl_path)\n",
        "                    lbl_name_no_ext = os.path.splitext(lbl_name)[0]\n",
        "\n",
        "                    if img_name_no_ext == lbl_name_no_ext:\n",
        "                        if os.path.exists(lbl_path):\n",
        "                            shutil.copy2(lbl_path, dest_lbl_dir)\n",
        "                        break\n",
        "\n",
        "            except Exception as e:\n",
        "                self.log(f\"‚ùå Error copying {img_name}: {e}\")\n",
        "                continue\n",
        "\n",
        "        self.log(f\"‚úÖ Copied {files_copied} files preserving splits\")\n",
        "        return files_copied > 0\n",
        "\n",
        "    def verify_dataset_structure(self, yolo_dirs):\n",
        "        \"\"\"Verify that the dataset structure is correct\"\"\"\n",
        "        self.log(\"üîç Verifying dataset structure...\")\n",
        "\n",
        "        required_dirs = ['train_images', 'train_labels', 'val_images', 'val_labels']\n",
        "\n",
        "        for dir_name in required_dirs:\n",
        "            dir_path = yolo_dirs[dir_name]\n",
        "\n",
        "            if not os.path.exists(dir_path):\n",
        "                self.log(f\"‚ùå Missing directory: {dir_path}\")\n",
        "                return False\n",
        "\n",
        "            # Count files\n",
        "            if 'images' in dir_name:\n",
        "                files = [f for f in os.listdir(dir_path) if f.lower().endswith(tuple(self.image_extensions))]\n",
        "            else:\n",
        "                files = [f for f in os.listdir(dir_path) if f.endswith('.txt')]\n",
        "\n",
        "            file_count = len(files)\n",
        "            self.log(f\"   ‚úÖ {dir_name}: {file_count} files\")\n",
        "\n",
        "            # Check for empty critical directories\n",
        "            if file_count == 0:\n",
        "                if dir_name in ['train_images', 'train_labels']:\n",
        "                    self.log(f\"‚ùå Critical directory is empty: {dir_name}\")\n",
        "                    return False\n",
        "                elif dir_name in ['val_images', 'val_labels']:\n",
        "                    self.log(f\"‚ö†Ô∏è  Validation directory is empty: {dir_name}\")\n",
        "                    # Try to create validation set from training data\n",
        "                    return self.create_validation_from_training(yolo_dirs)\n",
        "\n",
        "        self.log(\"‚úÖ Dataset structure verification passed\")\n",
        "        return True\n",
        "\n",
        "    def create_validation_from_training(self, yolo_dirs):\n",
        "        \"\"\"Create validation set from training data when validation is empty\"\"\"\n",
        "        self.log(\"üîÑ Creating validation set from training data...\")\n",
        "\n",
        "        train_images_dir = yolo_dirs['train_images']\n",
        "        train_labels_dir = yolo_dirs['train_labels']\n",
        "        val_images_dir = yolo_dirs['val_images']\n",
        "        val_labels_dir = yolo_dirs['val_labels']\n",
        "\n",
        "        # Get all training images\n",
        "        train_images = [f for f in os.listdir(train_images_dir) if f.lower().endswith(tuple(self.image_extensions))]\n",
        "\n",
        "        if len(train_images) < 2:\n",
        "            self.log(\"‚ùå Not enough training images to create validation set\")\n",
        "            return False\n",
        "\n",
        "        # Move 20% of training to validation (minimum 1, maximum 20)\n",
        "        val_count = max(1, min(20, len(train_images) // 5))\n",
        "\n",
        "        # Randomly select images for validation\n",
        "        random.shuffle(train_images)\n",
        "        val_images = train_images[:val_count]\n",
        "\n",
        "        self.log(f\"üì¶ Moving {len(val_images)} samples to validation...\")\n",
        "\n",
        "        moved_count = 0\n",
        "        for img_file in val_images:\n",
        "            img_name_no_ext = os.path.splitext(img_file)[0]\n",
        "\n",
        "            # Move image\n",
        "            src_img = os.path.join(train_images_dir, img_file)\n",
        "            dst_img = os.path.join(val_images_dir, img_file)\n",
        "\n",
        "            if os.path.exists(src_img):\n",
        "                shutil.move(src_img, dst_img)\n",
        "                moved_count += 1\n",
        "\n",
        "                # Move corresponding label if exists\n",
        "                label_file = img_name_no_ext + '.txt'\n",
        "                src_label = os.path.join(train_labels_dir, label_file)\n",
        "                dst_label = os.path.join(val_labels_dir, label_file)\n",
        "\n",
        "                if os.path.exists(src_label):\n",
        "                    shutil.move(src_label, dst_label)\n",
        "\n",
        "        self.log(f\"‚úÖ Created validation set with {moved_count} samples\")\n",
        "        return moved_count > 0\n",
        "\n",
        "class YOLO11TrainerCLI:\n",
        "    \"\"\"Command-line interface for YOLO11 training with improved file handling\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.all_classes = []\n",
        "        self.data_path = \"\"\n",
        "        self.dataset_manager = DatasetManager(print)\n",
        "        self.file_handler = FileHandler()\n",
        "        self.check_gpu()\n",
        "\n",
        "    def check_gpu(self):\n",
        "        \"\"\"Check for available GPUs with better error handling\"\"\"\n",
        "        try:\n",
        "            import torch\n",
        "        except ImportError:\n",
        "            print(\"‚ö†Ô∏è PyTorch not available, cannot check GPU status\")\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            if torch.cuda.is_available():\n",
        "                gpu_count = torch.cuda.device_count()\n",
        "                gpu_names = []\n",
        "                for i in range(gpu_count):\n",
        "                    try:\n",
        "                        gpu_names.append(torch.cuda.get_device_name(i))\n",
        "                    except Exception:\n",
        "                        gpu_names.append(f\"GPU {i}\")\n",
        "\n",
        "                print(f\"‚úÖ {gpu_count} GPU(s) available: {', '.join(gpu_names)}\")\n",
        "                os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(map(str, range(gpu_count)))\n",
        "            else:\n",
        "                print(\"‚ö†Ô∏è No GPU available, will use CPU\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è GPU check failed: {e}\")\n",
        "\n",
        "    def get_zip_file_interactive(self):\n",
        "        \"\"\"Interactive ZIP file selection with better error handling\"\"\"\n",
        "        max_attempts = 5\n",
        "        attempt = 0\n",
        "\n",
        "        while attempt < max_attempts:\n",
        "            attempt += 1\n",
        "            print(f\"\\nüìÅ Training Data (Attempt {attempt}/{max_attempts}):\")\n",
        "\n",
        "            if attempt == 1:\n",
        "                # First attempt - just ask for path\n",
        "                zip_path = input(\"Enter path to ZIP file: \").strip()\n",
        "            elif attempt == 2:\n",
        "                # Second attempt - provide help\n",
        "                print(\"üí° Let me help you find the file...\")\n",
        "                suggested_file = self.file_handler.find_files_interactive()\n",
        "                if suggested_file:\n",
        "                    zip_path = suggested_file\n",
        "                else:\n",
        "                    zip_path = input(\"\\nEnter full path to ZIP file: \").strip()\n",
        "            else:\n",
        "                # Subsequent attempts - more guidance\n",
        "                print(\"üîß Troubleshooting mode:\")\n",
        "                print(\"1. Make sure the file exists\")\n",
        "                print(\"2. Check the file is actually a ZIP file\")\n",
        "                print(\"3. Use the full path to the file\")\n",
        "                print(\"4. Make sure you have read permissions\")\n",
        "                zip_path = input(\"\\nTry again with full path: \").strip()\n",
        "\n",
        "            if not zip_path:\n",
        "                print(\"‚ùå No path provided\")\n",
        "                continue\n",
        "\n",
        "            # Normalize the path\n",
        "            zip_path = self.file_handler.normalize_path(zip_path)\n",
        "            print(f\"üîç Checking: {zip_path}\")\n",
        "\n",
        "            # Check if file is valid ZIP\n",
        "            is_valid, message = self.file_handler.is_valid_zip_detailed(zip_path)\n",
        "\n",
        "            if is_valid:\n",
        "                print(f\"‚úÖ {message}\")\n",
        "                return zip_path\n",
        "            else:\n",
        "                print(f\"‚ùå {message}\")\n",
        "\n",
        "                if \"does not exist\" in message.lower():\n",
        "                    print(\"üîç File not found. Please check:\")\n",
        "                    print(f\"   ‚Ä¢ Path spelling: {zip_path}\")\n",
        "                    print(f\"   ‚Ä¢ File location\")\n",
        "                    print(f\"   ‚Ä¢ File permissions\")\n",
        "                elif \"not a valid zip\" in message.lower():\n",
        "                    print(\"üîç File format issue. Please check:\")\n",
        "                    print(f\"   ‚Ä¢ File is actually a ZIP file\")\n",
        "                    print(f\"   ‚Ä¢ File is not corrupted\")\n",
        "                    print(f\"   ‚Ä¢ File downloaded completely\")\n",
        "\n",
        "                # On last attempt, give option to continue with CLI help\n",
        "                if attempt == max_attempts:\n",
        "                    print(f\"\\nüÜò Unable to load ZIP file after {max_attempts} attempts\")\n",
        "                    print(\"Would you like to:\")\n",
        "                    print(\"1. Try manual file selection\")\n",
        "                    print(\"2. Exit and fix the file issue\")\n",
        "\n",
        "                    choice = input(\"Enter choice (1/2): \").strip()\n",
        "                    if choice == \"1\":\n",
        "                        # Reset attempts for one more try\n",
        "                        attempt = 0\n",
        "                        max_attempts = 2\n",
        "                        continue\n",
        "                    else:\n",
        "                        return None\n",
        "\n",
        "        return None\n",
        "\n",
        "    def load_data(self, zip_path):\n",
        "        \"\"\"Load and analyze the ZIP file with comprehensive error handling\"\"\"\n",
        "        self.data_path = zip_path\n",
        "\n",
        "        # Validate ZIP file first\n",
        "        is_valid, message = self.file_handler.is_valid_zip_detailed(zip_path)\n",
        "        if not is_valid:\n",
        "            print(f\"‚ùå {message}\")\n",
        "            return False\n",
        "\n",
        "        print(f\"‚úÖ {message}\")\n",
        "\n",
        "        try:\n",
        "            print(\"üöÄ Starting data loading process...\")\n",
        "\n",
        "            # Extract ZIP file\n",
        "            extract_path = \"./temp_data\"\n",
        "            if os.path.exists(extract_path):\n",
        "                print(\"üßπ Cleaning up previous data...\")\n",
        "                shutil.rmtree(extract_path)\n",
        "            os.makedirs(extract_path)\n",
        "\n",
        "            print(\"üì¶ Extracting ZIP file...\")\n",
        "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "                zip_ref.extractall(extract_path)\n",
        "\n",
        "            print(\"‚úÖ ZIP file extracted successfully\")\n",
        "\n",
        "            # Analyze dataset structure\n",
        "            structure_info = self.dataset_manager.analyze_dataset_structure(extract_path)\n",
        "\n",
        "            if structure_info['total_images'] == 0:\n",
        "                print(\"‚ùå No image files found in dataset\")\n",
        "                print(\"üí° Make sure your ZIP contains image files (.jpg, .png, etc.)\")\n",
        "                return False\n",
        "\n",
        "            if structure_info['total_labels'] == 0:\n",
        "                print(\"‚ùå No label files found in dataset\")\n",
        "                print(\"üí° Make sure your ZIP contains YOLO format label files (.txt)\")\n",
        "                return False\n",
        "\n",
        "            # Reorganize dataset\n",
        "            if not self.dataset_manager.reorganize_dataset(extract_path, structure_info):\n",
        "                print(\"‚ùå Failed to reorganize dataset\")\n",
        "                return False\n",
        "\n",
        "            # Extract class information\n",
        "            all_class_ids = sorted(list(structure_info['class_ids']))\n",
        "            if not all_class_ids:\n",
        "                print(\"‚ùå No valid class labels found\")\n",
        "                return False\n",
        "\n",
        "            # Load class names\n",
        "            self.all_classes = self.load_class_names(extract_path, all_class_ids)\n",
        "\n",
        "            print(f\"‚úÖ Successfully loaded dataset with {len(self.all_classes)} classes:\")\n",
        "            for i, class_name in enumerate(self.all_classes):\n",
        "                print(f\"   {all_class_ids[i]:2d}: {class_name}\")\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed to load data: {str(e)}\")\n",
        "            print(\"\\nüîß Troubleshooting tips:\")\n",
        "            print(\"‚Ä¢ Make sure the ZIP file is not corrupted\")\n",
        "            print(\"‚Ä¢ Check available disk space\")\n",
        "            print(\"‚Ä¢ Verify file permissions\")\n",
        "            print(\"‚Ä¢ Try extracting the ZIP manually first\")\n",
        "            return False\n",
        "\n",
        "    def load_class_names(self, extract_path, all_class_ids):\n",
        "        \"\"\"Load class names from various sources\"\"\"\n",
        "        class_names = [f\"Class_{i}\" for i in all_class_ids]\n",
        "\n",
        "        for root, dirs, files in os.walk(extract_path):\n",
        "            if 'classes.txt' in files:\n",
        "                try:\n",
        "                    with open(os.path.join(root, 'classes.txt'), 'r') as f:\n",
        "                        names = [line.strip() for line in f if line.strip()]\n",
        "                        if len(names) >= max(all_class_ids) + 1:\n",
        "                            class_names = [names[i] for i in all_class_ids]\n",
        "                            print(\"üìù Loaded class names from classes.txt\")\n",
        "                            return class_names\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è Error reading classes.txt: {e}\")\n",
        "\n",
        "            for file in files:\n",
        "                if file.endswith(('.yaml', '.yml')):\n",
        "                    try:\n",
        "                        with open(os.path.join(root, file), 'r') as f:\n",
        "                            data = yaml.safe_load(f)\n",
        "                            if 'names' in data:\n",
        "                                names = data['names']\n",
        "                                if isinstance(names, list) and len(names) >= max(all_class_ids) + 1:\n",
        "                                    class_names = [names[i] for i in all_class_ids]\n",
        "                                    print(f\"üìù Loaded class names from {file}\")\n",
        "                                    return class_names\n",
        "                                elif isinstance(names, dict):\n",
        "                                    class_names = [names.get(i, f\"Class_{i}\") for i in all_class_ids]\n",
        "                                    print(f\"üìù Loaded class names from {file}\")\n",
        "                                    return class_names\n",
        "                    except Exception as e:\n",
        "                        print(f\"‚ö†Ô∏è Error reading {file}: {e}\")\n",
        "\n",
        "        print(\"üìù Using default class names\")\n",
        "        return class_names\n",
        "\n",
        "    def select_classes_interactive(self):\n",
        "        \"\"\"Interactive class selection with better UX\"\"\"\n",
        "        print(f\"\\nüìã Available Classes ({len(self.all_classes)} total):\")\n",
        "\n",
        "        for i, class_name in enumerate(self.all_classes):\n",
        "            print(f\"   {i:2d}: {class_name}\")\n",
        "\n",
        "        print(f\"\\nüéØ Select classes to train:\")\n",
        "        print(\"   ‚Ä¢ Type 'all' for all classes\")\n",
        "        print(\"   ‚Ä¢ Type numbers separated by commas (e.g., 0,2,5)\")\n",
        "        print(\"   ‚Ä¢ Type ranges with dashes (e.g., 0-5,8,10-12)\")\n",
        "        print(\"   ‚Ä¢ Press Ctrl+C to cancel\")\n",
        "\n",
        "        while True:\n",
        "            try:\n",
        "                selection = input(\"\\n‚û§ Enter your selection: \").strip()\n",
        "\n",
        "                if selection.lower() == 'all':\n",
        "                    selected_indices = list(range(len(self.all_classes)))\n",
        "                    break\n",
        "\n",
        "                selected_indices = self.parse_selection(selection)\n",
        "\n",
        "                if selected_indices:\n",
        "                    break\n",
        "                else:\n",
        "                    print(\"‚ùå No valid classes selected. Please try again.\")\n",
        "\n",
        "            except KeyboardInterrupt:\n",
        "                print(\"\\nüö´ Selection cancelled by user.\")\n",
        "                sys.exit(0)\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error: {e}. Please try again.\")\n",
        "\n",
        "        print(f\"\\n‚úÖ Selected {len(selected_indices)} classes:\")\n",
        "        for i in selected_indices:\n",
        "            print(f\"   {i:2d}: {self.all_classes[i]}\")\n",
        "\n",
        "        return selected_indices\n",
        "\n",
        "    def parse_selection(self, selection):\n",
        "        \"\"\"Parse user selection string\"\"\"\n",
        "        selected_indices = []\n",
        "        parts = selection.split(',')\n",
        "\n",
        "        for part in parts:\n",
        "            part = part.strip()\n",
        "            if '-' in part:\n",
        "                try:\n",
        "                    start, end = map(int, part.split('-'))\n",
        "                    selected_indices.extend(range(start, end + 1))\n",
        "                except ValueError:\n",
        "                    print(f\"‚ùå Invalid range format: {part}\")\n",
        "                    continue\n",
        "            else:\n",
        "                try:\n",
        "                    selected_indices.append(int(part))\n",
        "                except ValueError:\n",
        "                    print(f\"‚ùå Invalid number: {part}\")\n",
        "                    continue\n",
        "\n",
        "        # Remove duplicates and validate\n",
        "        selected_indices = list(set(selected_indices))\n",
        "        valid_indices = [i for i in selected_indices if 0 <= i < len(self.all_classes)]\n",
        "\n",
        "        if len(valid_indices) != len(selected_indices):\n",
        "            invalid = [i for i in selected_indices if i not in valid_indices]\n",
        "            print(f\"‚ö†Ô∏è Invalid indices ignored: {invalid}\")\n",
        "\n",
        "        return sorted(valid_indices)\n",
        "\n",
        "    def get_training_parameters(self):\n",
        "        \"\"\"Get training parameters from user\"\"\"\n",
        "        print(f\"\\n‚öôÔ∏è Training Configuration:\")\n",
        "        print(\"Press Enter to use default values shown in parentheses\")\n",
        "\n",
        "        params = {}\n",
        "\n",
        "        try:\n",
        "            # YOLO Version Selection\n",
        "            print(f\"\\nü§ñ Select YOLO Version:\")\n",
        "            yolo_versions = {\n",
        "                0: (\"YOLOv8\", [\"yolov8n.pt\", \"yolov8s.pt\", \"yolov8m.pt\", \"yolov8l.pt\", \"yolov8x.pt\"]),\n",
        "                1: (\"YOLOv9\", [\"yolov9t.pt\", \"yolov9s.pt\", \"yolov9m.pt\", \"yolov9c.pt\", \"yolov9e.pt\"]),\n",
        "                2: (\"YOLOv10\", [\"yolov10n.pt\", \"yolov10s.pt\", \"yolov10m.pt\", \"yolov10b.pt\", \"yolov10l.pt\", \"yolov10x.pt\"]),\n",
        "                3: (\"YOLO11\", [\"yolo11n.pt\", \"yolo11s.pt\", \"yolo11m.pt\", \"yolo11l.pt\", \"yolo11x.pt\"])\n",
        "            }\n",
        "\n",
        "            for i, (version_name, models) in yolo_versions.items():\n",
        "                print(f\"   {i}: {version_name} ({len(models)} models)\")\n",
        "\n",
        "            version_input = input(\"Select YOLO version (3 for YOLO11): \").strip()\n",
        "            version_idx = int(version_input) if version_input else 3\n",
        "\n",
        "            if version_idx not in yolo_versions:\n",
        "                version_idx = 3\n",
        "                print(\"‚ö†Ô∏è Invalid version, using YOLO11\")\n",
        "\n",
        "            selected_version, available_models = yolo_versions[version_idx]\n",
        "            params['yolo_version'] = selected_version\n",
        "\n",
        "            print(f\"\\nüì¶ Selected: {selected_version}\")\n",
        "            print(f\"Available {selected_version} models:\")\n",
        "            for i, model in enumerate(available_models):\n",
        "                model_size = model.split('.')[0][-1]  # Get the size letter (n, s, m, l, x, etc.)\n",
        "                size_names = {\n",
        "                    'n': 'Nano (fastest, least accurate)',\n",
        "                    't': 'Tiny (very fast, low accuracy)',\n",
        "                    's': 'Small (fast, good accuracy)',\n",
        "                    'm': 'Medium (balanced speed/accuracy)',\n",
        "                    'c': 'Classic (good accuracy)',\n",
        "                    'b': 'Balanced (optimized)',\n",
        "                    'l': 'Large (slow, high accuracy)',\n",
        "                    'x': 'Extra Large (slowest, highest accuracy)',\n",
        "                    'e': 'Efficient (optimized for deployment)'\n",
        "                }\n",
        "                description = size_names.get(model_size, 'Standard model')\n",
        "                print(f\"   {i}: {model} - {description}\")\n",
        "\n",
        "            model_input = input(f\"Select model (0 for {available_models[0]}): \").strip()\n",
        "            model_idx = int(model_input) if model_input else 0\n",
        "            params['model'] = available_models[model_idx] if 0 <= model_idx < len(available_models) else available_models[0]\n",
        "\n",
        "            epochs_input = input(\"\\nEpochs (100): \").strip()\n",
        "            params['epochs'] = int(epochs_input) if epochs_input else 100\n",
        "\n",
        "            imgsz_input = input(\"Image size (640): \").strip()\n",
        "            params['imgsz'] = int(imgsz_input) if imgsz_input else 640\n",
        "\n",
        "            batch_input = input(\"Batch size (16): \").strip()\n",
        "            params['batch'] = int(batch_input) if batch_input else 16\n",
        "\n",
        "        except ValueError:\n",
        "            print(\"‚ö†Ô∏è Invalid input detected. Using default parameters...\")\n",
        "            params = {\n",
        "                'epochs': 100,\n",
        "                'imgsz': 640,\n",
        "                'batch': 16,\n",
        "                'model': 'yolo11n.pt',\n",
        "                'yolo_version': 'YOLO11'\n",
        "            }\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\nüö´ Configuration cancelled by user.\")\n",
        "            sys.exit(0)\n",
        "\n",
        "        return params\n",
        "\n",
        "    def train_model(self, selected_indices, params):\n",
        "        \"\"\"Train YOLO model with comprehensive error handling and return model path\"\"\"\n",
        "        try:\n",
        "            import torch\n",
        "            from ultralytics import YOLO\n",
        "        except ImportError as e:\n",
        "            print(f\"‚ùå Required packages not available: {e}\")\n",
        "            return False, None\n",
        "\n",
        "        try:\n",
        "            yolo_version = params.get('yolo_version', 'YOLO11')\n",
        "            print(f\"üöÄ Starting {yolo_version} training with {len(selected_indices)} classes...\")\n",
        "\n",
        "            # Create dataset configuration\n",
        "            class_mapping = self.create_dataset_yaml(selected_indices)\n",
        "\n",
        "            # Filter labels\n",
        "            self.filter_labels(class_mapping)\n",
        "\n",
        "            # Final verification\n",
        "            if not self.final_dataset_check():\n",
        "                print(\"‚ùå Dataset verification failed\")\n",
        "                return False, None\n",
        "\n",
        "            # Initialize model\n",
        "            print(f\"ü§ñ Loading {params['model']} model...\")\n",
        "            model = YOLO(params['model'])\n",
        "\n",
        "            # Adjust batch size for GPU memory if needed\n",
        "            if torch.cuda.is_available():\n",
        "                try:\n",
        "                    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "                    if gpu_memory < 8 and params['batch'] > 8:\n",
        "                        params['batch'] = 8\n",
        "                        print(f\"üìâ Reduced batch size to {params['batch']} for GPU memory\")\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "            print(\"üèÉ Training started...\")\n",
        "            print(f\"Parameters: {yolo_version} {params['model']}, epochs={params['epochs']}, imgsz={params['imgsz']}, batch={params['batch']}\")\n",
        "\n",
        "            yaml_path = os.path.abspath('./dataset.yaml')\n",
        "            print(f\"üìÑ Using dataset config: {yaml_path}\")\n",
        "\n",
        "            # Create custom run name with YOLO version\n",
        "            run_name = f\"{yolo_version.lower()}_custom\"\n",
        "\n",
        "            # Start training\n",
        "            results = model.train(\n",
        "                data=yaml_path,\n",
        "                epochs=params['epochs'],\n",
        "                imgsz=params['imgsz'],\n",
        "                batch=params['batch'],\n",
        "                device='0' if torch.cuda.is_available() else 'cpu',\n",
        "                project='./runs/train',\n",
        "                name=run_name,\n",
        "                exist_ok=True,\n",
        "                verbose=True,\n",
        "                patience=20,\n",
        "                save_period=max(10, params['epochs'] // 10)\n",
        "            )\n",
        "\n",
        "            # Get the trained model path\n",
        "            model_dir = results.save_dir\n",
        "            best_model_path = os.path.join(model_dir, 'weights', 'best.pt')\n",
        "            last_model_path = os.path.join(model_dir, 'weights', 'last.pt')\n",
        "\n",
        "            # Check which model files exist and prefer 'best.pt'\n",
        "            if os.path.exists(best_model_path):\n",
        "                trained_model_path = best_model_path\n",
        "                model_type = \"best\"\n",
        "            elif os.path.exists(last_model_path):\n",
        "                trained_model_path = last_model_path\n",
        "                model_type = \"last\"\n",
        "            else:\n",
        "                # Fallback to save_dir if weights folder structure is different\n",
        "                trained_model_path = str(model_dir)\n",
        "                model_type = \"directory\"\n",
        "\n",
        "            print(\"üéâ Training completed successfully!\")\n",
        "            print(f\"üìÅ Training results saved to: {model_dir}\")\n",
        "            print(f\"üèÜ Trained model ({model_type}): {trained_model_path}\")\n",
        "\n",
        "            return True, trained_model_path\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Training failed: {str(e)}\")\n",
        "            print(\"\\nüîß Troubleshooting tips:\")\n",
        "            print(\"‚Ä¢ Check dataset paths and file permissions\")\n",
        "            print(\"‚Ä¢ Try reducing batch size or image size\")\n",
        "            print(\"‚Ä¢ Verify all images and labels are valid\")\n",
        "            print(\"‚Ä¢ Check available disk space\")\n",
        "            return False, None\n",
        "\n",
        "    def create_dataset_yaml(self, selected_indices):\n",
        "        \"\"\"Create dataset.yaml configuration\"\"\"\n",
        "        class_mapping = {old_idx: new_idx for new_idx, old_idx in enumerate(selected_indices)}\n",
        "        selected_names = [self.all_classes[i] for i in selected_indices]\n",
        "\n",
        "        dataset_config = {\n",
        "            'path': os.path.abspath('./temp_data'),\n",
        "            'train': 'train/images',\n",
        "            'val': 'val/images',\n",
        "            'test': 'test/images',\n",
        "            'nc': len(selected_indices),\n",
        "            'names': selected_names\n",
        "        }\n",
        "\n",
        "        with open('./dataset.yaml', 'w') as f:\n",
        "            yaml.dump(dataset_config, f, default_flow_style=False)\n",
        "\n",
        "        print(f\"üìÑ Created dataset.yaml with {len(selected_indices)} classes\")\n",
        "        return class_mapping\n",
        "\n",
        "    def filter_labels(self, class_mapping):\n",
        "        \"\"\"Filter label files for selected classes\"\"\"\n",
        "        print(\"üîÑ Filtering labels...\")\n",
        "\n",
        "        for root, dirs, files in os.walk('./temp_data'):\n",
        "            if 'labels' in root:\n",
        "                for file in files:\n",
        "                    if file.endswith('.txt'):\n",
        "                        self.filter_label_file(os.path.join(root, file), class_mapping)\n",
        "\n",
        "    def filter_label_file(self, label_path, class_mapping):\n",
        "        \"\"\"Filter individual label file\"\"\"\n",
        "        try:\n",
        "            with open(label_path, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "\n",
        "            filtered_lines = []\n",
        "            for line in lines:\n",
        "                if line.strip():\n",
        "                    parts = line.strip().split()\n",
        "                    if len(parts) >= 5:\n",
        "                        try:\n",
        "                            class_id = int(parts[0])\n",
        "                            if class_id in class_mapping:\n",
        "                                parts[0] = str(class_mapping[class_id])\n",
        "                                filtered_lines.append(' '.join(parts) + '\\n')\n",
        "                        except ValueError:\n",
        "                            continue\n",
        "\n",
        "            with open(label_path, 'w') as f:\n",
        "                f.writelines(filtered_lines)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error filtering {label_path}: {e}\")\n",
        "\n",
        "    def final_dataset_check(self):\n",
        "        \"\"\"Final comprehensive check before training\"\"\"\n",
        "        print(\"üîç Final dataset verification...\")\n",
        "\n",
        "        # Check required paths\n",
        "        required_paths = [\n",
        "            './temp_data/train/images',\n",
        "            './temp_data/train/labels',\n",
        "            './temp_data/val/images',\n",
        "            './temp_data/val/labels',\n",
        "            './dataset.yaml'\n",
        "        ]\n",
        "\n",
        "        for path in required_paths:\n",
        "            if not os.path.exists(path):\n",
        "                print(f\"‚ùå Missing: {path}\")\n",
        "                return False\n",
        "\n",
        "        # Count files and verify content\n",
        "        train_images = len([f for f in os.listdir('./temp_data/train/images')\n",
        "                           if f.lower().endswith(tuple(self.dataset_manager.image_extensions))])\n",
        "        train_labels = len([f for f in os.listdir('./temp_data/train/labels') if f.endswith('.txt')])\n",
        "        val_images = len([f for f in os.listdir('./temp_data/val/images')\n",
        "                         if f.lower().endswith(tuple(self.dataset_manager.image_extensions))])\n",
        "        val_labels = len([f for f in os.listdir('./temp_data/val/labels') if f.endswith('.txt')])\n",
        "\n",
        "        print(f\"üìä Dataset summary:\")\n",
        "        print(f\"   üèãÔ∏è Training: {train_images} images, {train_labels} labels\")\n",
        "        print(f\"   ‚úÖ Validation: {val_images} images, {val_labels} labels\")\n",
        "\n",
        "        if train_images == 0:\n",
        "            print(\"‚ùå No training images found\")\n",
        "            return False\n",
        "\n",
        "        if val_images == 0:\n",
        "            print(\"‚ùå No validation images found\")\n",
        "            return False\n",
        "\n",
        "        # Verify dataset.yaml content\n",
        "        try:\n",
        "            with open('./dataset.yaml', 'r') as f:\n",
        "                config = yaml.safe_load(f)\n",
        "                required_keys = ['path', 'train', 'val', 'nc', 'names']\n",
        "                for key in required_keys:\n",
        "                    if key not in config:\n",
        "                        print(f\"‚ùå Missing key in dataset.yaml: {key}\")\n",
        "                        return False\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error reading dataset.yaml: {e}\")\n",
        "            return False\n",
        "\n",
        "        print(\"‚úÖ Final verification passed - ready for training!\")\n",
        "        return True\n",
        "\n",
        "    def run_interactive(self):\n",
        "        \"\"\"Run interactive CLI training with improved file handling\"\"\"\n",
        "        print(\"\\nüöÄ YOLO11 Training Tool (Interactive Mode)\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        # Get ZIP file with better error handling\n",
        "        zip_path = self.get_zip_file_interactive()\n",
        "        if not zip_path:\n",
        "            print(\"‚ùå Unable to load ZIP file. Exiting.\")\n",
        "            return\n",
        "\n",
        "        # Load data\n",
        "        if not self.load_data(zip_path):\n",
        "            print(\"‚ùå Failed to load data. Exiting.\")\n",
        "            return\n",
        "\n",
        "        # Select classes\n",
        "        selected_indices = self.select_classes_interactive()\n",
        "\n",
        "        # Get training parameters\n",
        "        params = self.get_training_parameters()\n",
        "\n",
        "        # Show summary\n",
        "        print(f\"\\nüìã Training Summary:\")\n",
        "        print(f\"   üìä Dataset: {os.path.basename(zip_path)}\")\n",
        "        print(f\"   üéØ Classes: {len(selected_indices)} selected\")\n",
        "        print(f\"   ü§ñ YOLO Version: {params.get('yolo_version', 'YOLO11')}\")\n",
        "        print(f\"   üì¶ Model: {params['model']}\")\n",
        "        print(f\"   üìà Epochs: {params['epochs']}\")\n",
        "        print(f\"   üñºÔ∏è Image size: {params['imgsz']}\")\n",
        "        print(f\"   üì¶ Batch size: {params['batch']}\")\n",
        "\n",
        "        # Confirm training\n",
        "        print(f\"\\n‚ö° Ready to start training!\")\n",
        "        try:\n",
        "            confirm = input(\"Continue? (y/N): \").strip().lower()\n",
        "            if confirm in ['y', 'yes']:\n",
        "                success, model_path = self.train_model(selected_indices, params)\n",
        "                if success and model_path:\n",
        "                    print(\"\\nüéâ Training completed successfully!\")\n",
        "                    print(f\"üìÅ Check './runs/train/{params.get('yolo_version', 'yolo11').lower()}_custom' for all results\")\n",
        "                    print(f\"üèÜ Trained model: {model_path}\")\n",
        "                    return model_path\n",
        "                else:\n",
        "                    print(\"\\n‚ùå Training failed.\")\n",
        "                    return None\n",
        "            else:\n",
        "                print(\"üö´ Training cancelled.\")\n",
        "                return None\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\nüö´ Training cancelled by user.\")\n",
        "            return None\n",
        "\n",
        "\n",
        "def train_yolo_simple(zip_path=None, classes=\"all\", epochs=100, imgsz=640, batch=16, model=\"yolo11n.pt\", yolo_version=\"auto\"):\n",
        "    \"\"\"\n",
        "    Simple function for Jupyter/Colab environments with robust file handling and YOLO version selection\n",
        "\n",
        "    Parameters:\n",
        "    - zip_path: Path to the training data ZIP file\n",
        "    - classes: \"all\" or list of class indices like \"0,1,2\" or [0,1,2]\n",
        "    - epochs: Number of training epochs (default: 100)\n",
        "    - imgsz: Image size for training (default: 640)\n",
        "    - batch: Batch size (default: 16)\n",
        "    - model: Model name (default: \"yolo11n.pt\")\n",
        "    - yolo_version: YOLO version - \"auto\", \"yolov8\", \"yolov9\", \"yolov10\", \"yolo11\" (default: \"auto\")\n",
        "\n",
        "    Returns:\n",
        "    - Path to the trained model if successful, None if failed\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"üöÄ YOLO Simple Training\")\n",
        "    print(\"=\" * 30)\n",
        "\n",
        "    # Check packages first\n",
        "    if not check_and_install_packages():\n",
        "        print(\"‚ùå Failed to install required packages\")\n",
        "        return None\n",
        "\n",
        "    cli = YOLO11TrainerCLI()\n",
        "\n",
        "    if zip_path is None:\n",
        "        print(\"Interactive mode - please provide input when prompted\")\n",
        "        return cli.run_interactive()\n",
        "\n",
        "    # Normalize path\n",
        "    zip_path = FileHandler.normalize_path(zip_path)\n",
        "\n",
        "    # Validate ZIP file\n",
        "    is_valid, message = FileHandler.is_valid_zip_detailed(zip_path)\n",
        "    if not is_valid:\n",
        "        print(f\"‚ùå {message}\")\n",
        "        return None\n",
        "\n",
        "    print(f\"‚úÖ {message}\")\n",
        "\n",
        "    # Load data\n",
        "    if not cli.load_data(zip_path):\n",
        "        print(\"‚ùå Failed to load data\")\n",
        "        return None\n",
        "\n",
        "    # Parse classes\n",
        "    if isinstance(classes, str):\n",
        "        if classes.lower() == \"all\":\n",
        "            selected_indices = list(range(len(cli.all_classes)))\n",
        "        else:\n",
        "            try:\n",
        "                selected_indices = [int(x.strip()) for x in classes.split(',')]\n",
        "            except ValueError:\n",
        "                print(\"‚ùå Invalid class format. Use 'all' or '0,1,2'\")\n",
        "                return None\n",
        "    elif isinstance(classes, list):\n",
        "        selected_indices = classes\n",
        "    else:\n",
        "        print(\"‚ùå Classes must be 'all', '0,1,2', or [0,1,2]\")\n",
        "        return None\n",
        "\n",
        "    # Validate indices\n",
        "    valid_indices = [i for i in selected_indices if 0 <= i < len(cli.all_classes)]\n",
        "    if len(valid_indices) != len(selected_indices):\n",
        "        print(\"‚ö†Ô∏è Some class indices were invalid and ignored\")\n",
        "\n",
        "    if not valid_indices:\n",
        "        print(\"‚ùå No valid class indices provided\")\n",
        "        return None\n",
        "\n",
        "    print(f\"‚úÖ Selected classes: {[cli.all_classes[i] for i in valid_indices]}\")\n",
        "\n",
        "    # Handle YOLO version and model selection\n",
        "    yolo_models = {\n",
        "        \"yolov8\": [\"yolov8n.pt\", \"yolov8s.pt\", \"yolov8m.pt\", \"yolov8l.pt\", \"yolov8x.pt\"],\n",
        "        \"yolov9\": [\"yolov9t.pt\", \"yolov9s.pt\", \"yolov9m.pt\", \"yolov9c.pt\", \"yolov9e.pt\"],\n",
        "        \"yolov10\": [\"yolov10n.pt\", \"yolov10s.pt\", \"yolov10m.pt\", \"yolov10b.pt\", \"yolov10l.pt\", \"yolov10x.pt\"],\n",
        "        \"yolo11\": [\"yolo11n.pt\", \"yolo11s.pt\", \"yolo11m.pt\", \"yolo11l.pt\", \"yolo11x.pt\"]\n",
        "    }\n",
        "\n",
        "    # Auto-detect YOLO version from model name if version is \"auto\"\n",
        "    detected_version = yolo_version\n",
        "    if yolo_version.lower() == \"auto\":\n",
        "        for version, models in yolo_models.items():\n",
        "            if model in models:\n",
        "                detected_version = version\n",
        "                break\n",
        "        else:\n",
        "            detected_version = \"yolo11\"  # Default fallback\n",
        "            print(f\"‚ö†Ô∏è Could not detect YOLO version from model '{model}', using YOLO11\")\n",
        "\n",
        "    # Validate model exists for the version\n",
        "    if detected_version.lower() in yolo_models:\n",
        "        available_models = yolo_models[detected_version.lower()]\n",
        "        if model not in available_models:\n",
        "            print(f\"‚ö†Ô∏è Model '{model}' not available for {detected_version.upper()}\")\n",
        "            print(f\"Available models: {available_models}\")\n",
        "            model = available_models[0]  # Use first model as fallback\n",
        "            print(f\"Using fallback model: {model}\")\n",
        "\n",
        "    # Train model\n",
        "    params = {\n",
        "        'epochs': epochs,\n",
        "        'imgsz': imgsz,\n",
        "        'batch': batch,\n",
        "        'model': model,\n",
        "        'yolo_version': detected_version.upper()\n",
        "    }\n",
        "\n",
        "    print(f\"\\nüöÄ Starting {detected_version.upper()} training with {model}\")\n",
        "    print(f\"üìä Parameters: epochs={epochs}, imgsz={imgsz}, batch={batch}\")\n",
        "\n",
        "    success, model_path = cli.train_model(valid_indices, params)\n",
        "\n",
        "    if success and model_path:\n",
        "        print(\"\\nüéâ Training completed successfully!\")\n",
        "        print(f\"üìÅ Check './runs/train/{detected_version.lower()}_custom' for all results\")\n",
        "        print(f\"üèÜ Trained model: {model_path}\")\n",
        "        return model_path\n",
        "    else:\n",
        "        print(\"\\n‚ùå Training failed. Check error messages above.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def is_jupyter_environment():\n",
        "    \"\"\"Check if running in Jupyter/Colab environment\"\"\"\n",
        "    try:\n",
        "        from IPython import get_ipython\n",
        "        return get_ipython() is not None\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main entry point with improved error handling\"\"\"\n",
        "    print(\"üöÄ YOLO Training Tool (Multi-Version) - Initializing...\")\n",
        "\n",
        "    # Check and install packages first\n",
        "    if not check_and_install_packages():\n",
        "        print(\"‚ùå Failed to set up required packages. Exiting.\")\n",
        "        return\n",
        "\n",
        "    # Check environment\n",
        "    if is_jupyter_environment():\n",
        "        print(\"üî¨ Detected Jupyter/Colab environment\")\n",
        "        print(\"üí° Use train_yolo_simple() function for easy training:\")\n",
        "        print(\"   model_path = train_yolo_simple('/path/to/data.zip', classes='all', epochs=100)\")\n",
        "        print(\"   model_path = train_yolo_simple('/path/to/data.zip', model='yolov8n.pt')\")\n",
        "        print(\"\\nüìã Starting interactive CLI mode...\")\n",
        "        cli = YOLO11TrainerCLI()\n",
        "        return cli.run_interactive()\n",
        "\n",
        "    # Parse command line arguments\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description='YOLO Training Tool - Multi-version support with fixed dataset and file handling',\n",
        "        epilog='''\n",
        "Examples:\n",
        "  python yolo11_trainer.py --cli\n",
        "  python yolo11_trainer.py --zip data.zip --classes all --epochs 50\n",
        "  python yolo11_trainer.py --zip data.zip --classes 0,2,5 --epochs 100 --model yolov8n.pt\n",
        "\n",
        "Supported YOLO versions:\n",
        "  ‚Ä¢ YOLOv8: yolov8n.pt, yolov8s.pt, yolov8m.pt, yolov8l.pt, yolov8x.pt\n",
        "  ‚Ä¢ YOLOv9: yolov9t.pt, yolov9s.pt, yolov9m.pt, yolov9c.pt, yolov9e.pt\n",
        "  ‚Ä¢ YOLOv10: yolov10n.pt, yolov10s.pt, yolov10m.pt, yolov10b.pt, yolov10l.pt, yolov10x.pt\n",
        "  ‚Ä¢ YOLO11: yolo11n.pt, yolo11s.pt, yolo11m.pt, yolo11l.pt, yolo11x.pt\n",
        "        ''',\n",
        "        formatter_class=argparse.RawDescriptionHelpFormatter\n",
        "    )\n",
        "\n",
        "    parser.add_argument('--gui', action='store_true', help='Force GUI mode')\n",
        "    parser.add_argument('--cli', action='store_true', help='Force CLI mode')\n",
        "    parser.add_argument('--zip', type=str, help='Path to training data ZIP file')\n",
        "    parser.add_argument('--classes', type=str, help='Class indices (\"all\" or \"0,1,2\")')\n",
        "    parser.add_argument('--epochs', type=int, default=100, help='Training epochs')\n",
        "    parser.add_argument('--imgsz', type=int, default=640, help='Image size')\n",
        "    parser.add_argument('--batch', type=int, default=16, help='Batch size')\n",
        "    parser.add_argument('--model', type=str, default='yolo11n.pt', help='YOLO model')\n",
        "\n",
        "    try:\n",
        "        args = parser.parse_args()\n",
        "    except SystemExit:\n",
        "        print(\"Starting interactive CLI mode...\")\n",
        "        cli = YOLO11TrainerCLI()\n",
        "        cli.run_interactive()\n",
        "        return\n",
        "\n",
        "    # Determine interface mode\n",
        "    if args.cli or (not GUI_AVAILABLE and not args.gui):\n",
        "        # CLI mode\n",
        "        cli = YOLO11TrainerCLI()\n",
        "\n",
        "        if args.zip and args.classes:\n",
        "            # Non-interactive mode\n",
        "            # Normalize ZIP path\n",
        "            zip_path = FileHandler.normalize_path(args.zip)\n",
        "\n",
        "            # Validate ZIP file\n",
        "            is_valid, message = FileHandler.is_valid_zip_detailed(zip_path)\n",
        "            if not is_valid:\n",
        "                print(f\"‚ùå {message}\")\n",
        "                return\n",
        "\n",
        "            if cli.load_data(zip_path):\n",
        "                if args.classes.lower() == 'all':\n",
        "                    selected_indices = list(range(len(cli.all_classes)))\n",
        "                else:\n",
        "                    selected_indices = cli.parse_selection(args.classes)\n",
        "\n",
        "                if selected_indices:\n",
        "                    params = {\n",
        "                        'epochs': args.epochs,\n",
        "                        'imgsz': args.imgsz,\n",
        "                        'batch': args.batch,\n",
        "                        'model': args.model,\n",
        "                        'yolo_version': 'YOLO11'  # Default for CLI\n",
        "                    }\n",
        "                    success, model_path = cli.train_model(selected_indices, params)\n",
        "                    if success and model_path:\n",
        "                        print(f\"\\nüèÜ Training completed! Model saved at: {model_path}\")\n",
        "                    else:\n",
        "                        print(\"\\n‚ùå Training failed.\")\n",
        "                else:\n",
        "                    print(\"‚ùå No valid class indices provided\")\n",
        "        else:\n",
        "            # Interactive mode\n",
        "            cli.run_interactive()\n",
        "\n",
        "    elif args.gui or GUI_AVAILABLE:\n",
        "        # GUI mode (would need to be implemented with the new FileHandler and YOLO version support)\n",
        "        if not GUI_AVAILABLE:\n",
        "            print(\"‚ùå GUI not available. Use --cli flag.\")\n",
        "            return\n",
        "\n",
        "        print(\"üöÄ GUI mode would be launched here with multi-YOLO support...\")\n",
        "        print(\"üí° For now, using CLI mode...\")\n",
        "        cli = YOLO11TrainerCLI()\n",
        "        return cli.run_interactive()\n",
        "\n",
        "    else:\n",
        "        print(\"‚ùå No interface available. Use --cli flag.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "else:\n",
        "    # When imported as module\n",
        "    if is_jupyter_environment():\n",
        "        print(\"üî¨ YOLO Training Tool loaded in Jupyter/Colab\")\n",
        "        print(\"üí° Quick start:\")\n",
        "        print(\"   train_yolo_simple('/path/to/data.zip', classes='all', epochs=100)\")\n",
        "        print(\"   train_yolo_simple('/path/to/data.zip', classes='0,2,5', epochs=50)\")\n",
        "        print(\"   train_yolo_simple('/path/to/data.zip', model='yolov8n.pt', yolo_version='yolov8')\")\n",
        "        print(\"   train_yolo_simple('/path/to/data.zip', model='yolov10m.pt')  # Auto-detects version\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwOXHRJi9Aa7",
        "outputId": "1c7fdba1-d759-4f6c-caf8-d853206c4869"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "YOLO11 Training Tool\n",
            "============================================================\n",
            "GUI not available: no display name and no $DISPLAY environment variable\n",
            "Running in command-line mode...\n",
            "\n",
            "To enable GUI:\n",
            "- On Linux/WSL: Install X server (Xming, VcXsrv, or X11)\n",
            "- On SSH: Use 'ssh -X' for X11 forwarding\n",
            "- On headless servers: Use CLI mode with --cli flag\n",
            "============================================================\n",
            "üöÄ YOLO Training Tool (Multi-Version) - Initializing...\n",
            "üîç Checking required packages...\n",
            "‚úÖ PyTorch 2.6.0+cu124 is available\n",
            "‚úÖ CUDA available with 1 GPU(s)\n",
            "   GPU 0: Tesla T4\n",
            "‚ùå Ultralytics not found\n",
            "\n",
            "üì¶ Installing 1 missing package(s)...\n",
            "\n",
            "‚è≥ Installing ultralytics...\n",
            "‚úÖ ultralytics installed successfully\n",
            "\n",
            "üîÑ Reloading modules...\n",
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "‚úÖ All packages loaded successfully\n",
            "üî¨ Detected Jupyter/Colab environment\n",
            "üí° Use train_yolo_simple() function for easy training:\n",
            "   model_path = train_yolo_simple('/path/to/data.zip', classes='all', epochs=100)\n",
            "   model_path = train_yolo_simple('/path/to/data.zip', model='yolov8n.pt')\n",
            "\n",
            "üìã Starting interactive CLI mode...\n",
            "‚úÖ 1 GPU(s) available: Tesla T4\n",
            "\n",
            "üöÄ YOLO11 Training Tool (Interactive Mode)\n",
            "==================================================\n",
            "\n",
            "üìÅ Training Data (Attempt 1/5):\n",
            "Enter path to ZIP file: /content/Auto Driving.v1i.yolov8.zip\n",
            "üîç Checking: /content/Auto Driving.v1i.yolov8.zip\n",
            "üìÅ Checking ZIP file: Auto Driving.v1i.yolov8.zip\n",
            "   Path: /content/Auto Driving.v1i.yolov8.zip\n",
            "   File accessible, size: 10,485,760 bytes\n",
            "‚ùå File is not a valid ZIP archive\n",
            "üîç File format issue. Please check:\n",
            "   ‚Ä¢ File is actually a ZIP file\n",
            "   ‚Ä¢ File is not corrupted\n",
            "   ‚Ä¢ File downloaded completely\n",
            "\n",
            "üìÅ Training Data (Attempt 2/5):\n",
            "üí° Let me help you find the file...\n",
            "\n",
            "üîç File Path Helper\n",
            "Let's find your ZIP file step by step...\n",
            "\n",
            "üìÅ Current directory: /content\n",
            "üéØ Found 1 ZIP file(s) in current directory:\n",
            "   1. Auto Driving.v1i.yolov8.zip (10,485,760 bytes)\n",
            "\n",
            "Enter number (1-1) to select, or 'c' to continue with custom path: /content/Auto Driving.v1i.yolov8.zip\n",
            "\n",
            "üí° Tips for entering file path:\n",
            "   ‚Ä¢ Use forward slashes (/) or double backslashes (\\\\)\n",
            "   ‚Ä¢ Drag and drop the file into terminal (if supported)\n",
            "   ‚Ä¢ Use quotes if path contains spaces\n",
            "   ‚Ä¢ Use Tab for auto-completion (if supported)\n",
            "\n",
            "Enter full path to ZIP file: /content/Auto Driving.v1i.yolov8.zip\n",
            "üîç Checking: /content/Auto Driving.v1i.yolov8.zip\n",
            "üìÅ Checking ZIP file: Auto Driving.v1i.yolov8.zip\n",
            "   Path: /content/Auto Driving.v1i.yolov8.zip\n",
            "   File accessible, size: 21,585,322 bytes\n",
            "   üìã Contains 1134 files/folders\n",
            "   üîç Testing ZIP integrity...\n",
            "   üñºÔ∏è  Found 564 image files\n",
            "   üè∑Ô∏è  Found 566 label files\n",
            "‚úÖ Valid ZIP with 564 images and 566 labels\n",
            "üìÅ Checking ZIP file: Auto Driving.v1i.yolov8.zip\n",
            "   Path: /content/Auto Driving.v1i.yolov8.zip\n",
            "   File accessible, size: 21,585,322 bytes\n",
            "   üìã Contains 1134 files/folders\n",
            "   üîç Testing ZIP integrity...\n",
            "   üñºÔ∏è  Found 564 image files\n",
            "   üè∑Ô∏è  Found 566 label files\n",
            "‚úÖ Valid ZIP with 564 images and 566 labels\n",
            "üöÄ Starting data loading process...\n",
            "üì¶ Extracting ZIP file...\n",
            "‚úÖ ZIP file extracted successfully\n",
            "üîç Analyzing dataset structure...\n",
            "üìä Dataset Analysis Complete:\n",
            "   üñºÔ∏è  Total images: 564\n",
            "   üè∑Ô∏è  Total labels: 566\n",
            "   üéØ Unique classes: 16\n",
            "   üìÅ Image directories:\n",
            "      train/images: 564 images\n",
            "   üìÇ Label directories:\n",
            "      root: 2 labels\n",
            "      train/labels: 564 labels\n",
            "üîÑ Reorganizing dataset to YOLO format...\n",
            "   üìÅ Created: train/images\n",
            "   üìÅ Created: train/labels\n",
            "   üìÅ Created: val/images\n",
            "   üìÅ Created: val/labels\n",
            "   üìÅ Created: test/images\n",
            "   üìÅ Created: test/labels\n",
            "üîç Finding image-label pairs...\n",
            "‚úÖ Found 564 valid image-label pairs\n",
            "üîÄ Creating new train/val/test splits\n",
            "üìä Dataset split:\n",
            "   üèãÔ∏è  Training: 396 samples (70.2%)\n",
            "   ‚úÖ Validation: 112 samples (19.9%)\n",
            "   üß™ Test: 56 samples (9.9%)\n",
            "üìã Copying files to YOLO structure...\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0103_jpg.rf.63462a855d94b43c59321f09cc266ebd.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0103_jpg.rf.63462a855d94b43c59321f09cc266ebd.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0103_jpg.rf.63462a855d94b43c59321f09cc266ebd.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0145_jpg.rf.733c992187ad4f7c111846c19e654957.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0145_jpg.rf.733c992187ad4f7c111846c19e654957.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0145_jpg.rf.733c992187ad4f7c111846c19e654957.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0462_jpg.rf.04f8789bd9dd3a6dccabbcdfa48be3ea.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0462_jpg.rf.04f8789bd9dd3a6dccabbcdfa48be3ea.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0462_jpg.rf.04f8789bd9dd3a6dccabbcdfa48be3ea.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0518_jpg.rf.be061b4877218eab1b75f140f257c883.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0518_jpg.rf.be061b4877218eab1b75f140f257c883.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0518_jpg.rf.be061b4877218eab1b75f140f257c883.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0352_jpg.rf.64f458fea699ac7d3f1c8996728eb347.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0352_jpg.rf.64f458fea699ac7d3f1c8996728eb347.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0352_jpg.rf.64f458fea699ac7d3f1c8996728eb347.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0247_jpg.rf.e2d5610a66cac88a665a112bbda10ef2.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0247_jpg.rf.e2d5610a66cac88a665a112bbda10ef2.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0247_jpg.rf.e2d5610a66cac88a665a112bbda10ef2.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0212_jpg.rf.c3c0d858ef046fd5f96ddecd3e245f46.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0212_jpg.rf.c3c0d858ef046fd5f96ddecd3e245f46.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0212_jpg.rf.c3c0d858ef046fd5f96ddecd3e245f46.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0467_jpg.rf.e77e1166915cc78cd6cf4253197a9ea7.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0467_jpg.rf.e77e1166915cc78cd6cf4253197a9ea7.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0467_jpg.rf.e77e1166915cc78cd6cf4253197a9ea7.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0173_jpg.rf.38cd90cba476f34711f114e45462e3eb.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0173_jpg.rf.38cd90cba476f34711f114e45462e3eb.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0173_jpg.rf.38cd90cba476f34711f114e45462e3eb.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0437_jpg.rf.7f7f02f4ebd6b3d043ab50b04d14b407.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0437_jpg.rf.7f7f02f4ebd6b3d043ab50b04d14b407.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0437_jpg.rf.7f7f02f4ebd6b3d043ab50b04d14b407.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0479_jpg.rf.4aca10f453bc7cf429104383f3d54016.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0479_jpg.rf.4aca10f453bc7cf429104383f3d54016.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0479_jpg.rf.4aca10f453bc7cf429104383f3d54016.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0061_jpg.rf.b9579181a857a8daa9b449b66b769e7e.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0061_jpg.rf.b9579181a857a8daa9b449b66b769e7e.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0061_jpg.rf.b9579181a857a8daa9b449b66b769e7e.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0269_jpg.rf.7e8fee88ab2c70fa0f8c3f43e5881e8c.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0269_jpg.rf.7e8fee88ab2c70fa0f8c3f43e5881e8c.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0269_jpg.rf.7e8fee88ab2c70fa0f8c3f43e5881e8c.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0300_jpg.rf.7db72fc3e68365317d46b3dfa10043bb.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0300_jpg.rf.7db72fc3e68365317d46b3dfa10043bb.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0300_jpg.rf.7db72fc3e68365317d46b3dfa10043bb.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0067_jpg.rf.b5810f026f1d7536c06f4b0ebc6f7670.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0067_jpg.rf.b5810f026f1d7536c06f4b0ebc6f7670.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0067_jpg.rf.b5810f026f1d7536c06f4b0ebc6f7670.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0523_jpg.rf.721c115d4b6d3c339e5840bc3080967f.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0523_jpg.rf.721c115d4b6d3c339e5840bc3080967f.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0523_jpg.rf.721c115d4b6d3c339e5840bc3080967f.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0542_jpg.rf.27add01b0c8baac139445c1f3360e36b.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0542_jpg.rf.27add01b0c8baac139445c1f3360e36b.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0542_jpg.rf.27add01b0c8baac139445c1f3360e36b.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0155_jpg.rf.7cc2aed104b9780e78597a426704120e.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0155_jpg.rf.7cc2aed104b9780e78597a426704120e.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0155_jpg.rf.7cc2aed104b9780e78597a426704120e.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0395_jpg.rf.99af2be4899a28797e81e8920b61acf0.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0395_jpg.rf.99af2be4899a28797e81e8920b61acf0.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0395_jpg.rf.99af2be4899a28797e81e8920b61acf0.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0524_jpg.rf.474103a60ac45ac931e44e79709cb093.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0524_jpg.rf.474103a60ac45ac931e44e79709cb093.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0524_jpg.rf.474103a60ac45ac931e44e79709cb093.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0399_jpg.rf.3bca9189597879cfe5ae07f517212b2a.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0399_jpg.rf.3bca9189597879cfe5ae07f517212b2a.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0399_jpg.rf.3bca9189597879cfe5ae07f517212b2a.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0415_jpg.rf.1934e2fd29a30498231bdf5faab2a62c.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0415_jpg.rf.1934e2fd29a30498231bdf5faab2a62c.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0415_jpg.rf.1934e2fd29a30498231bdf5faab2a62c.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0349_jpg.rf.a46b5560d6b006ee27cfa394d4ea6014.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0349_jpg.rf.a46b5560d6b006ee27cfa394d4ea6014.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0349_jpg.rf.a46b5560d6b006ee27cfa394d4ea6014.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0094_jpg.rf.72a4be60358359125fed06cffe24a8e3.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0094_jpg.rf.72a4be60358359125fed06cffe24a8e3.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0094_jpg.rf.72a4be60358359125fed06cffe24a8e3.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0000_jpg.rf.e47c0bd6f660f4a26698e5d95d839a76.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0000_jpg.rf.e47c0bd6f660f4a26698e5d95d839a76.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0000_jpg.rf.e47c0bd6f660f4a26698e5d95d839a76.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0433_jpg.rf.518786927703c77ffd5d24df866cad93.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0433_jpg.rf.518786927703c77ffd5d24df866cad93.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0433_jpg.rf.518786927703c77ffd5d24df866cad93.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0050_jpg.rf.d18831aa8e6859f793179e018af12093.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0050_jpg.rf.d18831aa8e6859f793179e018af12093.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0050_jpg.rf.d18831aa8e6859f793179e018af12093.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0519_jpg.rf.9ad977330944317859285e9e4d81c190.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0519_jpg.rf.9ad977330944317859285e9e4d81c190.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0519_jpg.rf.9ad977330944317859285e9e4d81c190.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0281_jpg.rf.0320323eb668cc2026fc5fe6991d0c92.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0281_jpg.rf.0320323eb668cc2026fc5fe6991d0c92.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0281_jpg.rf.0320323eb668cc2026fc5fe6991d0c92.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0375_jpg.rf.081a173721c3a444ed134cedd46f44b0.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0375_jpg.rf.081a173721c3a444ed134cedd46f44b0.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0375_jpg.rf.081a173721c3a444ed134cedd46f44b0.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0253_jpg.rf.9d37adfbc0602d6a838bf0cdfb98b077.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0253_jpg.rf.9d37adfbc0602d6a838bf0cdfb98b077.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0253_jpg.rf.9d37adfbc0602d6a838bf0cdfb98b077.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0124_jpg.rf.85d590a76fd0f0de29ebe3bff1c81d8d.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0124_jpg.rf.85d590a76fd0f0de29ebe3bff1c81d8d.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0124_jpg.rf.85d590a76fd0f0de29ebe3bff1c81d8d.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0470_jpg.rf.171ee799d51ae775a27c791eb3526cb0.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0470_jpg.rf.171ee799d51ae775a27c791eb3526cb0.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0470_jpg.rf.171ee799d51ae775a27c791eb3526cb0.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0207_jpg.rf.dbd5b5cee5d716b4358ed7b20b21b9de.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0207_jpg.rf.dbd5b5cee5d716b4358ed7b20b21b9de.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0207_jpg.rf.dbd5b5cee5d716b4358ed7b20b21b9de.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0475_jpg.rf.062838c0e61919d0f0db62116e802c05.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0475_jpg.rf.062838c0e61919d0f0db62116e802c05.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0475_jpg.rf.062838c0e61919d0f0db62116e802c05.jpg' are the same file\n",
            "‚ùå Error copying KakaoTalk_20250717_091440196_06_jpg.rf.f36ffecaf990c4bc523f61d2e8d04896.jpg: './temp_data/train/images/KakaoTalk_20250717_091440196_06_jpg.rf.f36ffecaf990c4bc523f61d2e8d04896.jpg' and './temp_data/train/images/KakaoTalk_20250717_091440196_06_jpg.rf.f36ffecaf990c4bc523f61d2e8d04896.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0005_jpg.rf.03ba3b373b02b054edde48823ece9cb3.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0005_jpg.rf.03ba3b373b02b054edde48823ece9cb3.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0005_jpg.rf.03ba3b373b02b054edde48823ece9cb3.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0204_jpg.rf.12c2cea7edffb7165e00b66c5f542a18.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0204_jpg.rf.12c2cea7edffb7165e00b66c5f542a18.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0204_jpg.rf.12c2cea7edffb7165e00b66c5f542a18.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0346_jpg.rf.fba49cec95bbc95b58b272ac949383e8.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0346_jpg.rf.fba49cec95bbc95b58b272ac949383e8.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0346_jpg.rf.fba49cec95bbc95b58b272ac949383e8.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0092_jpg.rf.d3971974559527ba1c0e6ccf8f5da90b.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0092_jpg.rf.d3971974559527ba1c0e6ccf8f5da90b.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0092_jpg.rf.d3971974559527ba1c0e6ccf8f5da90b.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0297_jpg.rf.28a7e67e796e31944ea57fb0316c8308.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0297_jpg.rf.28a7e67e796e31944ea57fb0316c8308.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0297_jpg.rf.28a7e67e796e31944ea57fb0316c8308.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0013_jpg.rf.07977ad3e9f275ad6eb6809f259ab1df.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0013_jpg.rf.07977ad3e9f275ad6eb6809f259ab1df.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0013_jpg.rf.07977ad3e9f275ad6eb6809f259ab1df.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0534_jpg.rf.17780ff1b477562e93143c8b4b2c9879.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0534_jpg.rf.17780ff1b477562e93143c8b4b2c9879.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0534_jpg.rf.17780ff1b477562e93143c8b4b2c9879.jpg' are the same file\n",
            "‚ùå Error copying KakaoTalk_20250717_091440196_04_jpg.rf.3e9e3dcc22b5d5f428570b297284b093.jpg: './temp_data/train/images/KakaoTalk_20250717_091440196_04_jpg.rf.3e9e3dcc22b5d5f428570b297284b093.jpg' and './temp_data/train/images/KakaoTalk_20250717_091440196_04_jpg.rf.3e9e3dcc22b5d5f428570b297284b093.jpg' are the same file\n",
            "‚ùå Error copying KakaoTalk_20250704_210829744_09_jpg.rf.ade8f658656f89dae8faa28739fd8362.jpg: './temp_data/train/images/KakaoTalk_20250704_210829744_09_jpg.rf.ade8f658656f89dae8faa28739fd8362.jpg' and './temp_data/train/images/KakaoTalk_20250704_210829744_09_jpg.rf.ade8f658656f89dae8faa28739fd8362.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0213_jpg.rf.c4f026c16d6cb31332b8ffed2b0c9f17.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0213_jpg.rf.c4f026c16d6cb31332b8ffed2b0c9f17.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0213_jpg.rf.c4f026c16d6cb31332b8ffed2b0c9f17.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0159_jpg.rf.47c87396f6c63818583c27db52a33801.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0159_jpg.rf.47c87396f6c63818583c27db52a33801.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0159_jpg.rf.47c87396f6c63818583c27db52a33801.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0129_jpg.rf.1f052061ef13f5c799533f9ccdb6066d.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0129_jpg.rf.1f052061ef13f5c799533f9ccdb6066d.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0129_jpg.rf.1f052061ef13f5c799533f9ccdb6066d.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0249_jpg.rf.57e400523ba9ae4607b2bb705c998ca0.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0249_jpg.rf.57e400523ba9ae4607b2bb705c998ca0.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0249_jpg.rf.57e400523ba9ae4607b2bb705c998ca0.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0336_jpg.rf.0670e4e6c7787efee99d84da47833865.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0336_jpg.rf.0670e4e6c7787efee99d84da47833865.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0336_jpg.rf.0670e4e6c7787efee99d84da47833865.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0309_jpg.rf.d86f958d8e4fb9f03eda776260f13445.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0309_jpg.rf.d86f958d8e4fb9f03eda776260f13445.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0309_jpg.rf.d86f958d8e4fb9f03eda776260f13445.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0368_jpg.rf.e9a04f2215f6bdfd2a01ab09b7c2f936.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0368_jpg.rf.e9a04f2215f6bdfd2a01ab09b7c2f936.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0368_jpg.rf.e9a04f2215f6bdfd2a01ab09b7c2f936.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0088_jpg.rf.c5a21cec89be11154f7d7851f46928ff.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0088_jpg.rf.c5a21cec89be11154f7d7851f46928ff.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0088_jpg.rf.c5a21cec89be11154f7d7851f46928ff.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0112_jpg.rf.4aba1f241f5e383fd8de3e1ae6b75414.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0112_jpg.rf.4aba1f241f5e383fd8de3e1ae6b75414.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0112_jpg.rf.4aba1f241f5e383fd8de3e1ae6b75414.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0333_jpg.rf.943c1df0fd96a6519386984e74c30bba.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0333_jpg.rf.943c1df0fd96a6519386984e74c30bba.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0333_jpg.rf.943c1df0fd96a6519386984e74c30bba.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0273_jpg.rf.8ef8385dfe52a47516bc926720f543eb.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0273_jpg.rf.8ef8385dfe52a47516bc926720f543eb.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0273_jpg.rf.8ef8385dfe52a47516bc926720f543eb.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0120_jpg.rf.8fc57d8392347dce49b31dcd4f3b35d9.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0120_jpg.rf.8fc57d8392347dce49b31dcd4f3b35d9.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0120_jpg.rf.8fc57d8392347dce49b31dcd4f3b35d9.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0226_jpg.rf.25011ebfc9b12c0eedc1dce16f8556e7.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0226_jpg.rf.25011ebfc9b12c0eedc1dce16f8556e7.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0226_jpg.rf.25011ebfc9b12c0eedc1dce16f8556e7.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0383_jpg.rf.07ee4844d93268d2089fc89c4da9a9f3.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0383_jpg.rf.07ee4844d93268d2089fc89c4da9a9f3.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0383_jpg.rf.07ee4844d93268d2089fc89c4da9a9f3.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0303_jpg.rf.1811d297ebd43fb0d89a35e7d0d72161.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0303_jpg.rf.1811d297ebd43fb0d89a35e7d0d72161.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0303_jpg.rf.1811d297ebd43fb0d89a35e7d0d72161.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0195_jpg.rf.faea3adda15f72f7c2a7940333b08629.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0195_jpg.rf.faea3adda15f72f7c2a7940333b08629.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0195_jpg.rf.faea3adda15f72f7c2a7940333b08629.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0252_jpg.rf.805341ca3a2c4eac8344d9e1e4f132fb.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0252_jpg.rf.805341ca3a2c4eac8344d9e1e4f132fb.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0252_jpg.rf.805341ca3a2c4eac8344d9e1e4f132fb.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0431_jpg.rf.80861af28a75bf936451befa9c7b9031.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0431_jpg.rf.80861af28a75bf936451befa9c7b9031.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0431_jpg.rf.80861af28a75bf936451befa9c7b9031.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0366_jpg.rf.27b7bfc1c2195106e9c6e835b529d23e.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0366_jpg.rf.27b7bfc1c2195106e9c6e835b529d23e.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0366_jpg.rf.27b7bfc1c2195106e9c6e835b529d23e.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0356_jpg.rf.fd42134864c218a33bc5cd70b1465cb6.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0356_jpg.rf.fd42134864c218a33bc5cd70b1465cb6.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0356_jpg.rf.fd42134864c218a33bc5cd70b1465cb6.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0128_jpg.rf.167e3357bf53f322af0864dc088f1f43.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0128_jpg.rf.167e3357bf53f322af0864dc088f1f43.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0128_jpg.rf.167e3357bf53f322af0864dc088f1f43.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0308_jpg.rf.1f01eb95adb10e9793a8d65553119aeb.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0308_jpg.rf.1f01eb95adb10e9793a8d65553119aeb.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0308_jpg.rf.1f01eb95adb10e9793a8d65553119aeb.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0200_jpg.rf.bd54cdc3f9072d4b7e4f1be8aa836f32.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0200_jpg.rf.bd54cdc3f9072d4b7e4f1be8aa836f32.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0200_jpg.rf.bd54cdc3f9072d4b7e4f1be8aa836f32.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0440_jpg.rf.8af6804552678c3976c0cdb1589e9604.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0440_jpg.rf.8af6804552678c3976c0cdb1589e9604.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0440_jpg.rf.8af6804552678c3976c0cdb1589e9604.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0165_jpg.rf.e742e0d02aa763fe89b25aea4805c992.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0165_jpg.rf.e742e0d02aa763fe89b25aea4805c992.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0165_jpg.rf.e742e0d02aa763fe89b25aea4805c992.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0055_jpg.rf.857a20b49f6c5710b0d3c012b0c15a8e.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0055_jpg.rf.857a20b49f6c5710b0d3c012b0c15a8e.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0055_jpg.rf.857a20b49f6c5710b0d3c012b0c15a8e.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0442_jpg.rf.168c8cbc70a104c8a4bd4e93611dc64d.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0442_jpg.rf.168c8cbc70a104c8a4bd4e93611dc64d.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0442_jpg.rf.168c8cbc70a104c8a4bd4e93611dc64d.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0132_jpg.rf.7ecc8f9099eca3671adaf20c5777a066.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0132_jpg.rf.7ecc8f9099eca3671adaf20c5777a066.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0132_jpg.rf.7ecc8f9099eca3671adaf20c5777a066.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0030_jpg.rf.c5349cf3d88266b3da280b5a875bb3be.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0030_jpg.rf.c5349cf3d88266b3da280b5a875bb3be.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0030_jpg.rf.c5349cf3d88266b3da280b5a875bb3be.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0093_jpg.rf.e5925f6ce794d77ee03b58d4e5d28a7d.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0093_jpg.rf.e5925f6ce794d77ee03b58d4e5d28a7d.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0093_jpg.rf.e5925f6ce794d77ee03b58d4e5d28a7d.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0073_jpg.rf.e47cc5a2182f6b79895a91ae9b15de50.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0073_jpg.rf.e47cc5a2182f6b79895a91ae9b15de50.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0073_jpg.rf.e47cc5a2182f6b79895a91ae9b15de50.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0427_jpg.rf.014e199a639b6ef891f8645e7af07c2c.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0427_jpg.rf.014e199a639b6ef891f8645e7af07c2c.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0427_jpg.rf.014e199a639b6ef891f8645e7af07c2c.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0057_jpg.rf.645d96ad12e27ffb0616e6dc07a8ad11.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0057_jpg.rf.645d96ad12e27ffb0616e6dc07a8ad11.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0057_jpg.rf.645d96ad12e27ffb0616e6dc07a8ad11.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0424_jpg.rf.a656e344cb9fed7f40a2062513285475.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0424_jpg.rf.a656e344cb9fed7f40a2062513285475.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0424_jpg.rf.a656e344cb9fed7f40a2062513285475.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0255_jpg.rf.2a4377092789cf743f72c8502e35735f.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0255_jpg.rf.2a4377092789cf743f72c8502e35735f.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0255_jpg.rf.2a4377092789cf743f72c8502e35735f.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0045_jpg.rf.a700964f430e1baf048d1829709c4cb5.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0045_jpg.rf.a700964f430e1baf048d1829709c4cb5.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0045_jpg.rf.a700964f430e1baf048d1829709c4cb5.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0492_jpg.rf.8ae2cce8a63b54fd93d58b0720ed1938.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0492_jpg.rf.8ae2cce8a63b54fd93d58b0720ed1938.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0492_jpg.rf.8ae2cce8a63b54fd93d58b0720ed1938.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0496_jpg.rf.ec1382fe6282a9ad02f32ab7821aa514.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0496_jpg.rf.ec1382fe6282a9ad02f32ab7821aa514.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0496_jpg.rf.ec1382fe6282a9ad02f32ab7821aa514.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0182_jpg.rf.f13e5cec020a02d3c854b2ca66db1da7.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0182_jpg.rf.f13e5cec020a02d3c854b2ca66db1da7.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0182_jpg.rf.f13e5cec020a02d3c854b2ca66db1da7.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0417_jpg.rf.60167b17bcace97903d7770701093b3d.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0417_jpg.rf.60167b17bcace97903d7770701093b3d.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0417_jpg.rf.60167b17bcace97903d7770701093b3d.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0225_jpg.rf.ffaf23ab84537176958bd0d25d59749e.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0225_jpg.rf.ffaf23ab84537176958bd0d25d59749e.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0225_jpg.rf.ffaf23ab84537176958bd0d25d59749e.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0142_jpg.rf.695e682ad841643d2f543a5a17d9b1b9.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0142_jpg.rf.695e682ad841643d2f543a5a17d9b1b9.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0142_jpg.rf.695e682ad841643d2f543a5a17d9b1b9.jpg' are the same file\n",
            "‚ùå Error copying KakaoTalk_20250704_210829744_15_jpg.rf.19bda56a782b00be5446e8f111a10df9.jpg: './temp_data/train/images/KakaoTalk_20250704_210829744_15_jpg.rf.19bda56a782b00be5446e8f111a10df9.jpg' and './temp_data/train/images/KakaoTalk_20250704_210829744_15_jpg.rf.19bda56a782b00be5446e8f111a10df9.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0458_jpg.rf.b3688fd805001a5702c62a172d831da9.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0458_jpg.rf.b3688fd805001a5702c62a172d831da9.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0458_jpg.rf.b3688fd805001a5702c62a172d831da9.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0283_jpg.rf.7a305782863ce24e04ade1a6f4590b01.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0283_jpg.rf.7a305782863ce24e04ade1a6f4590b01.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0283_jpg.rf.7a305782863ce24e04ade1a6f4590b01.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0463_jpg.rf.f92b9a7862c4e284633cfcc8e4d1c263.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0463_jpg.rf.f92b9a7862c4e284633cfcc8e4d1c263.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0463_jpg.rf.f92b9a7862c4e284633cfcc8e4d1c263.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0380_jpg.rf.e97fb372b02dfc073d352abb5046e9c9.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0380_jpg.rf.e97fb372b02dfc073d352abb5046e9c9.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0380_jpg.rf.e97fb372b02dfc073d352abb5046e9c9.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0373_jpg.rf.11b86d51ca21d4e4a3484e6a527309cf.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0373_jpg.rf.11b86d51ca21d4e4a3484e6a527309cf.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0373_jpg.rf.11b86d51ca21d4e4a3484e6a527309cf.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0535_jpg.rf.b4e14144931828b76766f37eafc05418.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0535_jpg.rf.b4e14144931828b76766f37eafc05418.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0535_jpg.rf.b4e14144931828b76766f37eafc05418.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0411_jpg.rf.b11a3a8ee6c27e197a81583881a7affe.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0411_jpg.rf.b11a3a8ee6c27e197a81583881a7affe.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0411_jpg.rf.b11a3a8ee6c27e197a81583881a7affe.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0136_jpg.rf.938e131a557024ef8f9bb57d3d708cf1.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0136_jpg.rf.938e131a557024ef8f9bb57d3d708cf1.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0136_jpg.rf.938e131a557024ef8f9bb57d3d708cf1.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0305_jpg.rf.df74a22c8250cff463ccf50d12aa66c9.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0305_jpg.rf.df74a22c8250cff463ccf50d12aa66c9.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0305_jpg.rf.df74a22c8250cff463ccf50d12aa66c9.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0186_jpg.rf.57be85bc4a75fa98c511f91e30ba8752.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0186_jpg.rf.57be85bc4a75fa98c511f91e30ba8752.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0186_jpg.rf.57be85bc4a75fa98c511f91e30ba8752.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0382_jpg.rf.9a0f74c071cbf253dfdb6683b4f81bba.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0382_jpg.rf.9a0f74c071cbf253dfdb6683b4f81bba.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0382_jpg.rf.9a0f74c071cbf253dfdb6683b4f81bba.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0378_jpg.rf.1db9fd92ceb37b6622510185a2d13de3.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0378_jpg.rf.1db9fd92ceb37b6622510185a2d13de3.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0378_jpg.rf.1db9fd92ceb37b6622510185a2d13de3.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0307_jpg.rf.5d8e2c622624220bf5f5b933bcc7eaeb.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0307_jpg.rf.5d8e2c622624220bf5f5b933bcc7eaeb.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0307_jpg.rf.5d8e2c622624220bf5f5b933bcc7eaeb.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0389_jpg.rf.8f1387cab0913f54cc41363e2f886b29.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0389_jpg.rf.8f1387cab0913f54cc41363e2f886b29.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0389_jpg.rf.8f1387cab0913f54cc41363e2f886b29.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0409_jpg.rf.440f9b70e3fcd4eccdd65b42c69190fa.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0409_jpg.rf.440f9b70e3fcd4eccdd65b42c69190fa.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0409_jpg.rf.440f9b70e3fcd4eccdd65b42c69190fa.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0453_jpg.rf.1f4eaec82539d32a4a1d27c10e3a8215.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0453_jpg.rf.1f4eaec82539d32a4a1d27c10e3a8215.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0453_jpg.rf.1f4eaec82539d32a4a1d27c10e3a8215.jpg' are the same file\n",
            "‚ùå Error copying KakaoTalk_20250704_210829744_08_jpg.rf.f499d5f61131c29d3524bb6fab87ad15.jpg: './temp_data/train/images/KakaoTalk_20250704_210829744_08_jpg.rf.f499d5f61131c29d3524bb6fab87ad15.jpg' and './temp_data/train/images/KakaoTalk_20250704_210829744_08_jpg.rf.f499d5f61131c29d3524bb6fab87ad15.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0083_jpg.rf.4263d1904087d2668c781c4629b21937.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0083_jpg.rf.4263d1904087d2668c781c4629b21937.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0083_jpg.rf.4263d1904087d2668c781c4629b21937.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0085_jpg.rf.5f224870ab36452cf5248f6666330ab9.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0085_jpg.rf.5f224870ab36452cf5248f6666330ab9.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0085_jpg.rf.5f224870ab36452cf5248f6666330ab9.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0420_jpg.rf.6f1945794839ea7635a71cd46e77fc92.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0420_jpg.rf.6f1945794839ea7635a71cd46e77fc92.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0420_jpg.rf.6f1945794839ea7635a71cd46e77fc92.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0504_jpg.rf.bc91c61fbb2220582cbc0eacf3a5a659.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0504_jpg.rf.bc91c61fbb2220582cbc0eacf3a5a659.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0504_jpg.rf.bc91c61fbb2220582cbc0eacf3a5a659.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0408_jpg.rf.4b29824c14690f7a5e484ad4f9a3de5f.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0408_jpg.rf.4b29824c14690f7a5e484ad4f9a3de5f.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0408_jpg.rf.4b29824c14690f7a5e484ad4f9a3de5f.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0540_jpg.rf.23ff1b8705a558842c4f0b41e19a2e61.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0540_jpg.rf.23ff1b8705a558842c4f0b41e19a2e61.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0540_jpg.rf.23ff1b8705a558842c4f0b41e19a2e61.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0111_jpg.rf.9c26be75bfb569792fbacc638b8a5615.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0111_jpg.rf.9c26be75bfb569792fbacc638b8a5615.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0111_jpg.rf.9c26be75bfb569792fbacc638b8a5615.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0278_jpg.rf.9e8df8bb3222023fd6064a1fb47fb7c8.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0278_jpg.rf.9e8df8bb3222023fd6064a1fb47fb7c8.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0278_jpg.rf.9e8df8bb3222023fd6064a1fb47fb7c8.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0198_jpg.rf.3f940f7736dc1b965e6107accb3e4709.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0198_jpg.rf.3f940f7736dc1b965e6107accb3e4709.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0198_jpg.rf.3f940f7736dc1b965e6107accb3e4709.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0455_jpg.rf.37704dde351e74d5712178322a0fa909.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0455_jpg.rf.37704dde351e74d5712178322a0fa909.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0455_jpg.rf.37704dde351e74d5712178322a0fa909.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0498_jpg.rf.ed459d9996418f32ac3cdadd8b4c36ef.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0498_jpg.rf.ed459d9996418f32ac3cdadd8b4c36ef.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0498_jpg.rf.ed459d9996418f32ac3cdadd8b4c36ef.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0256_jpg.rf.98ecb349430a71c06273d40c09f93c3a.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0256_jpg.rf.98ecb349430a71c06273d40c09f93c3a.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0256_jpg.rf.98ecb349430a71c06273d40c09f93c3a.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0219_jpg.rf.b091d78f934379012ecc0c35baae1d8d.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0219_jpg.rf.b091d78f934379012ecc0c35baae1d8d.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0219_jpg.rf.b091d78f934379012ecc0c35baae1d8d.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0410_jpg.rf.50accada8ff5ee12c934f09142a224e1.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0410_jpg.rf.50accada8ff5ee12c934f09142a224e1.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0410_jpg.rf.50accada8ff5ee12c934f09142a224e1.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0353_jpg.rf.bd513ce1b8e81a181bf5bb834d9459e5.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0353_jpg.rf.bd513ce1b8e81a181bf5bb834d9459e5.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0353_jpg.rf.bd513ce1b8e81a181bf5bb834d9459e5.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0436_jpg.rf.617aaea09152df5ced94f0b77ef3d690.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0436_jpg.rf.617aaea09152df5ced94f0b77ef3d690.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0436_jpg.rf.617aaea09152df5ced94f0b77ef3d690.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0020_jpg.rf.97bfc3e29d14d16ef3d67fc93b0ddbbf.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0020_jpg.rf.97bfc3e29d14d16ef3d67fc93b0ddbbf.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0020_jpg.rf.97bfc3e29d14d16ef3d67fc93b0ddbbf.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0046_jpg.rf.7990a47298b6b53d9eb0bcc68d9de28c.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0046_jpg.rf.7990a47298b6b53d9eb0bcc68d9de28c.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0046_jpg.rf.7990a47298b6b53d9eb0bcc68d9de28c.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0146_jpg.rf.4a5a0c461a09b0fa2e1bd7169e81cfb1.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0146_jpg.rf.4a5a0c461a09b0fa2e1bd7169e81cfb1.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0146_jpg.rf.4a5a0c461a09b0fa2e1bd7169e81cfb1.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0466_jpg.rf.11e2ecdd8709da77f6e9f2759793f6fa.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0466_jpg.rf.11e2ecdd8709da77f6e9f2759793f6fa.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0466_jpg.rf.11e2ecdd8709da77f6e9f2759793f6fa.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0201_jpg.rf.5c7c54ddbfd8d627b6c36b672c43de13.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0201_jpg.rf.5c7c54ddbfd8d627b6c36b672c43de13.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0201_jpg.rf.5c7c54ddbfd8d627b6c36b672c43de13.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0448_jpg.rf.ef68f53f7adb3d15281ef66f69dd98fd.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0448_jpg.rf.ef68f53f7adb3d15281ef66f69dd98fd.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0448_jpg.rf.ef68f53f7adb3d15281ef66f69dd98fd.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0271_jpg.rf.b57080e04fd2839399af6bbe68013d1e.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0271_jpg.rf.b57080e04fd2839399af6bbe68013d1e.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0271_jpg.rf.b57080e04fd2839399af6bbe68013d1e.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0084_jpg.rf.b44d2166d8fc1b0dacd2056ae7449159.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0084_jpg.rf.b44d2166d8fc1b0dacd2056ae7449159.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0084_jpg.rf.b44d2166d8fc1b0dacd2056ae7449159.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0391_jpg.rf.38aadb0cf13e99fd694fbeb047640150.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0391_jpg.rf.38aadb0cf13e99fd694fbeb047640150.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0391_jpg.rf.38aadb0cf13e99fd694fbeb047640150.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0116_jpg.rf.b4276b0eab588e7561e46941cb4344a6.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0116_jpg.rf.b4276b0eab588e7561e46941cb4344a6.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0116_jpg.rf.b4276b0eab588e7561e46941cb4344a6.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0432_jpg.rf.1bb372af95a2dce4776d34d374d20558.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0432_jpg.rf.1bb372af95a2dce4776d34d374d20558.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0432_jpg.rf.1bb372af95a2dce4776d34d374d20558.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0042_jpg.rf.9e46224ecd893ae0ec24f38415890da6.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0042_jpg.rf.9e46224ecd893ae0ec24f38415890da6.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0042_jpg.rf.9e46224ecd893ae0ec24f38415890da6.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0494_jpg.rf.e0839b3651a6a99874242007bb09a9c4.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0494_jpg.rf.e0839b3651a6a99874242007bb09a9c4.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0494_jpg.rf.e0839b3651a6a99874242007bb09a9c4.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0295_jpg.rf.f378061061206b18e8b648be422a1c4e.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0295_jpg.rf.f378061061206b18e8b648be422a1c4e.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0295_jpg.rf.f378061061206b18e8b648be422a1c4e.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0499_jpg.rf.8e925e93469f7236686fa394f9eecf83.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0499_jpg.rf.8e925e93469f7236686fa394f9eecf83.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0499_jpg.rf.8e925e93469f7236686fa394f9eecf83.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0054_jpg.rf.a91e4ccd788bafc707a258e4b10f321c.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0054_jpg.rf.a91e4ccd788bafc707a258e4b10f321c.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0054_jpg.rf.a91e4ccd788bafc707a258e4b10f321c.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0071_jpg.rf.d5e66e7257926f11c510d1f37404f59d.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0071_jpg.rf.d5e66e7257926f11c510d1f37404f59d.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0071_jpg.rf.d5e66e7257926f11c510d1f37404f59d.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0170_jpg.rf.ee8c987a958dafb54b9a979b974fa4fc.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0170_jpg.rf.ee8c987a958dafb54b9a979b974fa4fc.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0170_jpg.rf.ee8c987a958dafb54b9a979b974fa4fc.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0317_jpg.rf.dd207d8dfbf07b7e73990e9fd6eb03aa.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0317_jpg.rf.dd207d8dfbf07b7e73990e9fd6eb03aa.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0317_jpg.rf.dd207d8dfbf07b7e73990e9fd6eb03aa.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0189_jpg.rf.80a6be580d0f23f53b45424a0f4b8d97.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0189_jpg.rf.80a6be580d0f23f53b45424a0f4b8d97.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0189_jpg.rf.80a6be580d0f23f53b45424a0f4b8d97.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0151_jpg.rf.588a4dba4cda8dfe10782322ae99064d.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0151_jpg.rf.588a4dba4cda8dfe10782322ae99064d.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0151_jpg.rf.588a4dba4cda8dfe10782322ae99064d.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0337_jpg.rf.609ef6588a7a32136b6aecaff6d41982.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0337_jpg.rf.609ef6588a7a32136b6aecaff6d41982.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0337_jpg.rf.609ef6588a7a32136b6aecaff6d41982.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0474_jpg.rf.3b7538c542787f1fbc40f7d37d4b48ce.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0474_jpg.rf.3b7538c542787f1fbc40f7d37d4b48ce.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0474_jpg.rf.3b7538c542787f1fbc40f7d37d4b48ce.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0187_jpg.rf.c96c06bd03e00f6adea57aac908725bf.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0187_jpg.rf.c96c06bd03e00f6adea57aac908725bf.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0187_jpg.rf.c96c06bd03e00f6adea57aac908725bf.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0511_jpg.rf.bc05119a1a30226b84f860b7541921e5.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0511_jpg.rf.bc05119a1a30226b84f860b7541921e5.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0511_jpg.rf.bc05119a1a30226b84f860b7541921e5.jpg' are the same file\n",
            "‚ùå Error copying KakaoTalk_20250717_091440196_05_jpg.rf.534db2b7a8827fc107af469a24740612.jpg: './temp_data/train/images/KakaoTalk_20250717_091440196_05_jpg.rf.534db2b7a8827fc107af469a24740612.jpg' and './temp_data/train/images/KakaoTalk_20250717_091440196_05_jpg.rf.534db2b7a8827fc107af469a24740612.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0147_jpg.rf.1c015953255011afeef81fda4670e3b9.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0147_jpg.rf.1c015953255011afeef81fda4670e3b9.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0147_jpg.rf.1c015953255011afeef81fda4670e3b9.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0493_jpg.rf.c3743c5cc3c02e57f117b7f46ec56d4a.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0493_jpg.rf.c3743c5cc3c02e57f117b7f46ec56d4a.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0493_jpg.rf.c3743c5cc3c02e57f117b7f46ec56d4a.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0130_jpg.rf.d4b7a7cae04b614d52d6aabd5192a566.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0130_jpg.rf.d4b7a7cae04b614d52d6aabd5192a566.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0130_jpg.rf.d4b7a7cae04b614d52d6aabd5192a566.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0126_jpg.rf.d2659d34b11018c91f8908a8f87a6050.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0126_jpg.rf.d2659d34b11018c91f8908a8f87a6050.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0126_jpg.rf.d2659d34b11018c91f8908a8f87a6050.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0096_jpg.rf.24288c07af3445a149dfe3204a1cf218.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0096_jpg.rf.24288c07af3445a149dfe3204a1cf218.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0096_jpg.rf.24288c07af3445a149dfe3204a1cf218.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0038_jpg.rf.52022417a9318bbc06c4c21a979870f6.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0038_jpg.rf.52022417a9318bbc06c4c21a979870f6.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0038_jpg.rf.52022417a9318bbc06c4c21a979870f6.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0472_jpg.rf.5d8a6d9a869e4c84b09e72cf0d4382dc.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0472_jpg.rf.5d8a6d9a869e4c84b09e72cf0d4382dc.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0472_jpg.rf.5d8a6d9a869e4c84b09e72cf0d4382dc.jpg' are the same file\n",
            "‚ùå Error copying KakaoTalk_20250704_210829744_11_jpg.rf.94179f05c2b1d1f2c69dd6ee9d6a6803.jpg: './temp_data/train/images/KakaoTalk_20250704_210829744_11_jpg.rf.94179f05c2b1d1f2c69dd6ee9d6a6803.jpg' and './temp_data/train/images/KakaoTalk_20250704_210829744_11_jpg.rf.94179f05c2b1d1f2c69dd6ee9d6a6803.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0279_jpg.rf.d1ab1a17b2d2d42a87894976c3fd7214.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0279_jpg.rf.d1ab1a17b2d2d42a87894976c3fd7214.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0279_jpg.rf.d1ab1a17b2d2d42a87894976c3fd7214.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0127_jpg.rf.188f7d6cbc2860bb6dd4bd77dcd8a5cc.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0127_jpg.rf.188f7d6cbc2860bb6dd4bd77dcd8a5cc.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0127_jpg.rf.188f7d6cbc2860bb6dd4bd77dcd8a5cc.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0229_jpg.rf.607599d49a7776dc735eb96b443f539b.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0229_jpg.rf.607599d49a7776dc735eb96b443f539b.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0229_jpg.rf.607599d49a7776dc735eb96b443f539b.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0502_jpg.rf.155f4e00ecbcc7440986b1a5906ef1d9.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0502_jpg.rf.155f4e00ecbcc7440986b1a5906ef1d9.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0502_jpg.rf.155f4e00ecbcc7440986b1a5906ef1d9.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0241_jpg.rf.cdd9f6ffb6a3bf57a95e537234101c92.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0241_jpg.rf.cdd9f6ffb6a3bf57a95e537234101c92.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0241_jpg.rf.cdd9f6ffb6a3bf57a95e537234101c92.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0049_jpg.rf.b26ac863bae84d5c1fdc10f32e738b22.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0049_jpg.rf.b26ac863bae84d5c1fdc10f32e738b22.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0049_jpg.rf.b26ac863bae84d5c1fdc10f32e738b22.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0393_jpg.rf.e26cd98981d408dcc328fcb511a53aa7.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0393_jpg.rf.e26cd98981d408dcc328fcb511a53aa7.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0393_jpg.rf.e26cd98981d408dcc328fcb511a53aa7.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0114_jpg.rf.094247b45a0120124679d768589aa546.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0114_jpg.rf.094247b45a0120124679d768589aa546.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0114_jpg.rf.094247b45a0120124679d768589aa546.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0274_jpg.rf.2f384815d137bd8038d2e454535e0f42.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0274_jpg.rf.2f384815d137bd8038d2e454535e0f42.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0274_jpg.rf.2f384815d137bd8038d2e454535e0f42.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0174_jpg.rf.e9567faf5cc0f2d1ffb67ab96e9a5608.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0174_jpg.rf.e9567faf5cc0f2d1ffb67ab96e9a5608.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0174_jpg.rf.e9567faf5cc0f2d1ffb67ab96e9a5608.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0161_jpg.rf.2f8dd7fed2ed4895cae5707c66c37dcc.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0161_jpg.rf.2f8dd7fed2ed4895cae5707c66c37dcc.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0161_jpg.rf.2f8dd7fed2ed4895cae5707c66c37dcc.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0526_jpg.rf.3558b424916c0b32c4f6371092657b34.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0526_jpg.rf.3558b424916c0b32c4f6371092657b34.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0526_jpg.rf.3558b424916c0b32c4f6371092657b34.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0449_jpg.rf.abc0fa92e4429d73521d9b06d7c3115f.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0449_jpg.rf.abc0fa92e4429d73521d9b06d7c3115f.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0449_jpg.rf.abc0fa92e4429d73521d9b06d7c3115f.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0425_jpg.rf.5f13400242c77d32aa70e2fb53282b03.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0425_jpg.rf.5f13400242c77d32aa70e2fb53282b03.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0425_jpg.rf.5f13400242c77d32aa70e2fb53282b03.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0385_jpg.rf.683c5e2dbcd60315a3d9f4b597c4b61c.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0385_jpg.rf.683c5e2dbcd60315a3d9f4b597c4b61c.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0385_jpg.rf.683c5e2dbcd60315a3d9f4b597c4b61c.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0251_jpg.rf.d85ed502dd139ecb2134053a9b2742a4.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0251_jpg.rf.d85ed502dd139ecb2134053a9b2742a4.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0251_jpg.rf.d85ed502dd139ecb2134053a9b2742a4.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0220_jpg.rf.33c0d89a9dfa224ecdc397867bfc581e.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0220_jpg.rf.33c0d89a9dfa224ecdc397867bfc581e.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0220_jpg.rf.33c0d89a9dfa224ecdc397867bfc581e.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0068_jpg.rf.34514f587466b410fb55887bb559eff9.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0068_jpg.rf.34514f587466b410fb55887bb559eff9.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0068_jpg.rf.34514f587466b410fb55887bb559eff9.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0230_jpg.rf.ccd43b5f395c540621619d6d394e6687.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0230_jpg.rf.ccd43b5f395c540621619d6d394e6687.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0230_jpg.rf.ccd43b5f395c540621619d6d394e6687.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0056_jpg.rf.579c0c4a96ea6511d45db05f85b45cfe.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0056_jpg.rf.579c0c4a96ea6511d45db05f85b45cfe.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0056_jpg.rf.579c0c4a96ea6511d45db05f85b45cfe.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0143_jpg.rf.6ae262c66565dcc8e2cf912a51083f21.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0143_jpg.rf.6ae262c66565dcc8e2cf912a51083f21.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0143_jpg.rf.6ae262c66565dcc8e2cf912a51083f21.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0397_jpg.rf.14d66d306cf938993c3f26f2a9d19941.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0397_jpg.rf.14d66d306cf938993c3f26f2a9d19941.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0397_jpg.rf.14d66d306cf938993c3f26f2a9d19941.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0008_jpg.rf.234420788d5f52bc799a6d933b438105.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0008_jpg.rf.234420788d5f52bc799a6d933b438105.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0008_jpg.rf.234420788d5f52bc799a6d933b438105.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0414_jpg.rf.73bd979609d03c80ea092eb20919de61.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0414_jpg.rf.73bd979609d03c80ea092eb20919de61.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0414_jpg.rf.73bd979609d03c80ea092eb20919de61.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0529_jpg.rf.c7f800b5d76d25433d0f8928ea30425e.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0529_jpg.rf.c7f800b5d76d25433d0f8928ea30425e.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0529_jpg.rf.c7f800b5d76d25433d0f8928ea30425e.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0288_jpg.rf.2e2bc290d52fbd8ce8fc8035dbbcaaff.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0288_jpg.rf.2e2bc290d52fbd8ce8fc8035dbbcaaff.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0288_jpg.rf.2e2bc290d52fbd8ce8fc8035dbbcaaff.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0365_jpg.rf.8dd5bb46fd1ce9a44968b9605fb91453.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0365_jpg.rf.8dd5bb46fd1ce9a44968b9605fb91453.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0365_jpg.rf.8dd5bb46fd1ce9a44968b9605fb91453.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0202_jpg.rf.7d3b7b9f9d4c91e0c0ecbcacecbaa562.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0202_jpg.rf.7d3b7b9f9d4c91e0c0ecbcacecbaa562.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0202_jpg.rf.7d3b7b9f9d4c91e0c0ecbcacecbaa562.jpg' are the same file\n",
            "‚ùå Error copying KakaoTalk_20250704_210829744_12_jpg.rf.7ddf1a53a3a70cece4ae5dbe06fa693e.jpg: './temp_data/train/images/KakaoTalk_20250704_210829744_12_jpg.rf.7ddf1a53a3a70cece4ae5dbe06fa693e.jpg' and './temp_data/train/images/KakaoTalk_20250704_210829744_12_jpg.rf.7ddf1a53a3a70cece4ae5dbe06fa693e.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0330_jpg.rf.cacccb5f2261806d740cb816e52f8223.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0330_jpg.rf.cacccb5f2261806d740cb816e52f8223.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0330_jpg.rf.cacccb5f2261806d740cb816e52f8223.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0041_jpg.rf.8690c1aeb685b9a4d8920862db037b6d.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0041_jpg.rf.8690c1aeb685b9a4d8920862db037b6d.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0041_jpg.rf.8690c1aeb685b9a4d8920862db037b6d.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0244_jpg.rf.c6569b6951c2a890becff56fd47cc541.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0244_jpg.rf.c6569b6951c2a890becff56fd47cc541.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0244_jpg.rf.c6569b6951c2a890becff56fd47cc541.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0530_jpg.rf.c536108fef41c7b36e6d172866ebae4a.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0530_jpg.rf.c536108fef41c7b36e6d172866ebae4a.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0530_jpg.rf.c536108fef41c7b36e6d172866ebae4a.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0098_jpg.rf.ca076ec2aab207d293decb88f72bfdee.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0098_jpg.rf.ca076ec2aab207d293decb88f72bfdee.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0098_jpg.rf.ca076ec2aab207d293decb88f72bfdee.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0024_jpg.rf.65348c2369d676bf8cdbcfe2e05f3b9f.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0024_jpg.rf.65348c2369d676bf8cdbcfe2e05f3b9f.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0024_jpg.rf.65348c2369d676bf8cdbcfe2e05f3b9f.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0501_jpg.rf.1aca3904e28a30d8482ecb145497aeca.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0501_jpg.rf.1aca3904e28a30d8482ecb145497aeca.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0501_jpg.rf.1aca3904e28a30d8482ecb145497aeca.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0010_jpg.rf.d922f6964d1924b78ae8d51bdaeaf5ac.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0010_jpg.rf.d922f6964d1924b78ae8d51bdaeaf5ac.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0010_jpg.rf.d922f6964d1924b78ae8d51bdaeaf5ac.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0327_jpg.rf.c61e8f3f57ccedd4749a6aaa72d83d6e.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0327_jpg.rf.c61e8f3f57ccedd4749a6aaa72d83d6e.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0327_jpg.rf.c61e8f3f57ccedd4749a6aaa72d83d6e.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0180_jpg.rf.c74eabae29912a546e15866dbb6eef6f.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0180_jpg.rf.c74eabae29912a546e15866dbb6eef6f.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0180_jpg.rf.c74eabae29912a546e15866dbb6eef6f.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0104_jpg.rf.1d4d2b52e56d44140d222def2446acfa.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0104_jpg.rf.1d4d2b52e56d44140d222def2446acfa.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0104_jpg.rf.1d4d2b52e56d44140d222def2446acfa.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0028_jpg.rf.06c491595f070c01c71b195b3ae59dc7.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0028_jpg.rf.06c491595f070c01c71b195b3ae59dc7.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0028_jpg.rf.06c491595f070c01c71b195b3ae59dc7.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0486_jpg.rf.9c5764acf97500d854c43393434cdec3.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0486_jpg.rf.9c5764acf97500d854c43393434cdec3.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0486_jpg.rf.9c5764acf97500d854c43393434cdec3.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0150_jpg.rf.d1e86e91d5279be693dff958825cb0ae.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0150_jpg.rf.d1e86e91d5279be693dff958825cb0ae.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0150_jpg.rf.d1e86e91d5279be693dff958825cb0ae.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0369_jpg.rf.5971ee56937a0afc8e4c9204c6af2105.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0369_jpg.rf.5971ee56937a0afc8e4c9204c6af2105.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0369_jpg.rf.5971ee56937a0afc8e4c9204c6af2105.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0263_jpg.rf.55809ab4d3835b7eb39ed6044959349d.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0263_jpg.rf.55809ab4d3835b7eb39ed6044959349d.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0263_jpg.rf.55809ab4d3835b7eb39ed6044959349d.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0533_jpg.rf.1ae08c10c43bd6023683f4c3efdbce8e.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0533_jpg.rf.1ae08c10c43bd6023683f4c3efdbce8e.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0533_jpg.rf.1ae08c10c43bd6023683f4c3efdbce8e.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0122_jpg.rf.71174891b402d7fb039e56139886e892.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0122_jpg.rf.71174891b402d7fb039e56139886e892.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0122_jpg.rf.71174891b402d7fb039e56139886e892.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0160_jpg.rf.d2a8e949fa8411b98d8704af7f435fb7.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0160_jpg.rf.d2a8e949fa8411b98d8704af7f435fb7.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0160_jpg.rf.d2a8e949fa8411b98d8704af7f435fb7.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0080_jpg.rf.a5c1f2ffbc2c41c79e14453c97d80c7b.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0080_jpg.rf.a5c1f2ffbc2c41c79e14453c97d80c7b.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0080_jpg.rf.a5c1f2ffbc2c41c79e14453c97d80c7b.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0048_jpg.rf.d002fdb2c41864dda80028535772ad06.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0048_jpg.rf.d002fdb2c41864dda80028535772ad06.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0048_jpg.rf.d002fdb2c41864dda80028535772ad06.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0209_jpg.rf.01299c024111c77197c6bdddce66ab97.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0209_jpg.rf.01299c024111c77197c6bdddce66ab97.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0209_jpg.rf.01299c024111c77197c6bdddce66ab97.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0348_jpg.rf.056cca653d9d75eff3815cf85e11dda2.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0348_jpg.rf.056cca653d9d75eff3815cf85e11dda2.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0348_jpg.rf.056cca653d9d75eff3815cf85e11dda2.jpg' are the same file\n",
            "‚ùå Error copying KakaoTalk_20250717_091440196_07_jpg.rf.b43ead12b1c94aef05e8c4feaa347dc0.jpg: './temp_data/train/images/KakaoTalk_20250717_091440196_07_jpg.rf.b43ead12b1c94aef05e8c4feaa347dc0.jpg' and './temp_data/train/images/KakaoTalk_20250717_091440196_07_jpg.rf.b43ead12b1c94aef05e8c4feaa347dc0.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0081_jpg.rf.872f56e3999be71bc0a9f9e25aa6978a.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0081_jpg.rf.872f56e3999be71bc0a9f9e25aa6978a.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0081_jpg.rf.872f56e3999be71bc0a9f9e25aa6978a.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0017_jpg.rf.e909d2579115380dd221364e618e532b.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0017_jpg.rf.e909d2579115380dd221364e618e532b.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0017_jpg.rf.e909d2579115380dd221364e618e532b.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0291_jpg.rf.518e70766d9c558ebf97f9535ed1f04c.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0291_jpg.rf.518e70766d9c558ebf97f9535ed1f04c.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0291_jpg.rf.518e70766d9c558ebf97f9535ed1f04c.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0134_jpg.rf.a7f9437cae473714597f5eb80d83cc45.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0134_jpg.rf.a7f9437cae473714597f5eb80d83cc45.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0134_jpg.rf.a7f9437cae473714597f5eb80d83cc45.jpg' are the same file\n",
            "‚ùå Error copying KakaoTalk_20250704_210829744_14_jpg.rf.e5f0009d2c2be73b44f774054aa8a998.jpg: './temp_data/train/images/KakaoTalk_20250704_210829744_14_jpg.rf.e5f0009d2c2be73b44f774054aa8a998.jpg' and './temp_data/train/images/KakaoTalk_20250704_210829744_14_jpg.rf.e5f0009d2c2be73b44f774054aa8a998.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0051_jpg.rf.89531d66b6146424f836fc9289fd1858.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0051_jpg.rf.89531d66b6146424f836fc9289fd1858.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0051_jpg.rf.89531d66b6146424f836fc9289fd1858.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0032_jpg.rf.cffb8911354148a04b38d27817ef3c14.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0032_jpg.rf.cffb8911354148a04b38d27817ef3c14.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0032_jpg.rf.cffb8911354148a04b38d27817ef3c14.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0302_jpg.rf.924e7d24e8cea7e710567c2a81c0cc24.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0302_jpg.rf.924e7d24e8cea7e710567c2a81c0cc24.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0302_jpg.rf.924e7d24e8cea7e710567c2a81c0cc24.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0390_jpg.rf.833385c6542b4add58496a91311722dd.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0390_jpg.rf.833385c6542b4add58496a91311722dd.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0390_jpg.rf.833385c6542b4add58496a91311722dd.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0216_jpg.rf.91d7b2cf4f04e7c606dbbeaf65fb2c5a.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0216_jpg.rf.91d7b2cf4f04e7c606dbbeaf65fb2c5a.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0216_jpg.rf.91d7b2cf4f04e7c606dbbeaf65fb2c5a.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0401_jpg.rf.69a95b766a7ee9ee031a2028b9b3bb26.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0401_jpg.rf.69a95b766a7ee9ee031a2028b9b3bb26.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0401_jpg.rf.69a95b766a7ee9ee031a2028b9b3bb26.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0156_jpg.rf.af525e55d8b80b30bdc3aa03a9200beb.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0156_jpg.rf.af525e55d8b80b30bdc3aa03a9200beb.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0156_jpg.rf.af525e55d8b80b30bdc3aa03a9200beb.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0299_jpg.rf.403fc5e28b1991b94887ef7e103ffda3.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0299_jpg.rf.403fc5e28b1991b94887ef7e103ffda3.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0299_jpg.rf.403fc5e28b1991b94887ef7e103ffda3.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0434_jpg.rf.0802fdbd64f1f8b3e653e7e37288f499.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0434_jpg.rf.0802fdbd64f1f8b3e653e7e37288f499.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0434_jpg.rf.0802fdbd64f1f8b3e653e7e37288f499.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0531_jpg.rf.055c8b3c40403c1675e90dcfb1abc92f.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0531_jpg.rf.055c8b3c40403c1675e90dcfb1abc92f.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0531_jpg.rf.055c8b3c40403c1675e90dcfb1abc92f.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0407_jpg.rf.c425457e4183f38d6f8565297a50ca0c.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0407_jpg.rf.c425457e4183f38d6f8565297a50ca0c.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0407_jpg.rf.c425457e4183f38d6f8565297a50ca0c.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0363_jpg.rf.fbad77cf2d8843b414ac9993a72332fb.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0363_jpg.rf.fbad77cf2d8843b414ac9993a72332fb.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0363_jpg.rf.fbad77cf2d8843b414ac9993a72332fb.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0227_jpg.rf.72eb939d4b0657cb52c659a3a31230a4.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0227_jpg.rf.72eb939d4b0657cb52c659a3a31230a4.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0227_jpg.rf.72eb939d4b0657cb52c659a3a31230a4.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0167_jpg.rf.3f8c226d5f476ede45a38a87e51353fe.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0167_jpg.rf.3f8c226d5f476ede45a38a87e51353fe.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0167_jpg.rf.3f8c226d5f476ede45a38a87e51353fe.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0238_jpg.rf.97fd0ed0f4f7e3c2de0b02c3b5d5b932.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0238_jpg.rf.97fd0ed0f4f7e3c2de0b02c3b5d5b932.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0238_jpg.rf.97fd0ed0f4f7e3c2de0b02c3b5d5b932.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0194_jpg.rf.b332646bce54301f8c6be76ed39424d9.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0194_jpg.rf.b332646bce54301f8c6be76ed39424d9.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0194_jpg.rf.b332646bce54301f8c6be76ed39424d9.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0205_jpg.rf.211dd98e6c1b35aaf5da308d582672b9.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0205_jpg.rf.211dd98e6c1b35aaf5da308d582672b9.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0205_jpg.rf.211dd98e6c1b35aaf5da308d582672b9.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0379_jpg.rf.4374bb950b32eeb61ba8a26ce213f30e.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0379_jpg.rf.4374bb950b32eeb61ba8a26ce213f30e.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0379_jpg.rf.4374bb950b32eeb61ba8a26ce213f30e.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0108_jpg.rf.da228830068d0ca443dab3ec53e9b323.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0108_jpg.rf.da228830068d0ca443dab3ec53e9b323.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0108_jpg.rf.da228830068d0ca443dab3ec53e9b323.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0482_jpg.rf.ba1dd6d4c123a521ad69fbee2480ae5e.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0482_jpg.rf.ba1dd6d4c123a521ad69fbee2480ae5e.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0482_jpg.rf.ba1dd6d4c123a521ad69fbee2480ae5e.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0404_jpg.rf.99bb5e2f1d395416fa0709366ebc8b29.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0404_jpg.rf.99bb5e2f1d395416fa0709366ebc8b29.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0404_jpg.rf.99bb5e2f1d395416fa0709366ebc8b29.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0011_jpg.rf.52187df7f519ee5b64f0653798e48e7a.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0011_jpg.rf.52187df7f519ee5b64f0653798e48e7a.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0011_jpg.rf.52187df7f519ee5b64f0653798e48e7a.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0102_jpg.rf.6485605ede6ed04f7e32bf2ef9b10333.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0102_jpg.rf.6485605ede6ed04f7e32bf2ef9b10333.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0102_jpg.rf.6485605ede6ed04f7e32bf2ef9b10333.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0019_jpg.rf.7690b6a47a4bf68e21554ac51dd7d6fa.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0019_jpg.rf.7690b6a47a4bf68e21554ac51dd7d6fa.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0019_jpg.rf.7690b6a47a4bf68e21554ac51dd7d6fa.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0211_jpg.rf.82f3ebafab66dd8cd8f9fae47a0a280d.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0211_jpg.rf.82f3ebafab66dd8cd8f9fae47a0a280d.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0211_jpg.rf.82f3ebafab66dd8cd8f9fae47a0a280d.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0357_jpg.rf.d3215a73c9fd5657dd9daaed44b17143.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0357_jpg.rf.d3215a73c9fd5657dd9daaed44b17143.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0357_jpg.rf.d3215a73c9fd5657dd9daaed44b17143.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0223_jpg.rf.b0dfa5a29f274779fb61478620c275ff.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0223_jpg.rf.b0dfa5a29f274779fb61478620c275ff.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0223_jpg.rf.b0dfa5a29f274779fb61478620c275ff.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0003_jpg.rf.fbfa81f70e91d7e45e9d5d0b2d877f94.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0003_jpg.rf.fbfa81f70e91d7e45e9d5d0b2d877f94.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0003_jpg.rf.fbfa81f70e91d7e45e9d5d0b2d877f94.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0228_jpg.rf.3fe184280f9b8568bc3865477aa79e80.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0228_jpg.rf.3fe184280f9b8568bc3865477aa79e80.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0228_jpg.rf.3fe184280f9b8568bc3865477aa79e80.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0272_jpg.rf.b8eeae9aaff02685f8e62ebaa364a528.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0272_jpg.rf.b8eeae9aaff02685f8e62ebaa364a528.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0272_jpg.rf.b8eeae9aaff02685f8e62ebaa364a528.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0313_jpg.rf.40c225bfdc08bea10fbd9cf7c221495c.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0313_jpg.rf.40c225bfdc08bea10fbd9cf7c221495c.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0313_jpg.rf.40c225bfdc08bea10fbd9cf7c221495c.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0361_jpg.rf.ab1387d5b3e8d84daed43fe81cea1309.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0361_jpg.rf.ab1387d5b3e8d84daed43fe81cea1309.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0361_jpg.rf.ab1387d5b3e8d84daed43fe81cea1309.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0110_jpg.rf.d1e5803cf55a17b12107aab6f7b1d356.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0110_jpg.rf.d1e5803cf55a17b12107aab6f7b1d356.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0110_jpg.rf.d1e5803cf55a17b12107aab6f7b1d356.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0144_jpg.rf.ef4e4c6912995b3fecb1d21245e7653d.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0144_jpg.rf.ef4e4c6912995b3fecb1d21245e7653d.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0144_jpg.rf.ef4e4c6912995b3fecb1d21245e7653d.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0497_jpg.rf.458cf6fa25631d740a28de0d80169929.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0497_jpg.rf.458cf6fa25631d740a28de0d80169929.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0497_jpg.rf.458cf6fa25631d740a28de0d80169929.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0233_jpg.rf.0a11450eeb02a3245fc2be2072c4afd9.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0233_jpg.rf.0a11450eeb02a3245fc2be2072c4afd9.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0233_jpg.rf.0a11450eeb02a3245fc2be2072c4afd9.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0262_jpg.rf.d5ea953a065c3a6dfbb65e7a471455b7.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0262_jpg.rf.d5ea953a065c3a6dfbb65e7a471455b7.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0262_jpg.rf.d5ea953a065c3a6dfbb65e7a471455b7.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0367_jpg.rf.c3ca959390cc2dfdaf570cee3ba56519.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0367_jpg.rf.c3ca959390cc2dfdaf570cee3ba56519.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0367_jpg.rf.c3ca959390cc2dfdaf570cee3ba56519.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0495_jpg.rf.556fc887091fa8194cc10b1725645278.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0495_jpg.rf.556fc887091fa8194cc10b1725645278.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0495_jpg.rf.556fc887091fa8194cc10b1725645278.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0162_jpg.rf.ef8e602fe5623411af9597675dbb67fd.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0162_jpg.rf.ef8e602fe5623411af9597675dbb67fd.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0162_jpg.rf.ef8e602fe5623411af9597675dbb67fd.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0331_jpg.rf.a855cc7b0feb978bea1bc87ec215efa3.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0331_jpg.rf.a855cc7b0feb978bea1bc87ec215efa3.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0331_jpg.rf.a855cc7b0feb978bea1bc87ec215efa3.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0324_jpg.rf.ccb3ca1d795c231857e72e60e20b56bb.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0324_jpg.rf.ccb3ca1d795c231857e72e60e20b56bb.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0324_jpg.rf.ccb3ca1d795c231857e72e60e20b56bb.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0315_jpg.rf.57f32f3b527dedbebdbe9d1e3818f4e6.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0315_jpg.rf.57f32f3b527dedbebdbe9d1e3818f4e6.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0315_jpg.rf.57f32f3b527dedbebdbe9d1e3818f4e6.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0332_jpg.rf.0d2daf9cae41e9d35f476fbc23bd67a8.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0332_jpg.rf.0d2daf9cae41e9d35f476fbc23bd67a8.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0332_jpg.rf.0d2daf9cae41e9d35f476fbc23bd67a8.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0539_jpg.rf.76491f230777f2f19fee84e47f3a1a13.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0539_jpg.rf.76491f230777f2f19fee84e47f3a1a13.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0539_jpg.rf.76491f230777f2f19fee84e47f3a1a13.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0231_jpg.rf.812fcff5b139592e749d3df4f771fa1a.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0231_jpg.rf.812fcff5b139592e749d3df4f771fa1a.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0231_jpg.rf.812fcff5b139592e749d3df4f771fa1a.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0412_jpg.rf.f98dc9beaadf9102bdfbd7fba35a7228.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0412_jpg.rf.f98dc9beaadf9102bdfbd7fba35a7228.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0412_jpg.rf.f98dc9beaadf9102bdfbd7fba35a7228.jpg' are the same file\n",
            "‚ùå Error copying KakaoTalk_20250717_091440196_09_jpg.rf.3ae9d1ba834d0e7bcbbaaff738bdba82.jpg: './temp_data/train/images/KakaoTalk_20250717_091440196_09_jpg.rf.3ae9d1ba834d0e7bcbbaaff738bdba82.jpg' and './temp_data/train/images/KakaoTalk_20250717_091440196_09_jpg.rf.3ae9d1ba834d0e7bcbbaaff738bdba82.jpg' are the same file\n",
            "‚ùå Error copying KakaoTalk_20250704_210829744_jpg.rf.83d7e31c89903be445d2c61d8eb95508.jpg: './temp_data/train/images/KakaoTalk_20250704_210829744_jpg.rf.83d7e31c89903be445d2c61d8eb95508.jpg' and './temp_data/train/images/KakaoTalk_20250704_210829744_jpg.rf.83d7e31c89903be445d2c61d8eb95508.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0386_jpg.rf.ca750af1ba917c8ac6ef7e00214a323f.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0386_jpg.rf.ca750af1ba917c8ac6ef7e00214a323f.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0386_jpg.rf.ca750af1ba917c8ac6ef7e00214a323f.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0513_jpg.rf.56be1b391f1cac777560fd1c49416fa6.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0513_jpg.rf.56be1b391f1cac777560fd1c49416fa6.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0513_jpg.rf.56be1b391f1cac777560fd1c49416fa6.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0064_jpg.rf.17b75a85c97950ced797899fe2b12693.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0064_jpg.rf.17b75a85c97950ced797899fe2b12693.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0064_jpg.rf.17b75a85c97950ced797899fe2b12693.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0022_jpg.rf.eb4247369573358ec2cf3c682f91d24c.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0022_jpg.rf.eb4247369573358ec2cf3c682f91d24c.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0022_jpg.rf.eb4247369573358ec2cf3c682f91d24c.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0441_jpg.rf.7e838d0554bdbb1ffb97d54444925689.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0441_jpg.rf.7e838d0554bdbb1ffb97d54444925689.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0441_jpg.rf.7e838d0554bdbb1ffb97d54444925689.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0289_jpg.rf.4e5bd705efd0ce1513864b9dbf85df8f.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0289_jpg.rf.4e5bd705efd0ce1513864b9dbf85df8f.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0289_jpg.rf.4e5bd705efd0ce1513864b9dbf85df8f.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0360_jpg.rf.0e459a2c16470f2147616e7e70467add.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0360_jpg.rf.0e459a2c16470f2147616e7e70467add.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0360_jpg.rf.0e459a2c16470f2147616e7e70467add.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0508_jpg.rf.841d4274a69d286f03ea8efd76c9b1e7.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0508_jpg.rf.841d4274a69d286f03ea8efd76c9b1e7.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0508_jpg.rf.841d4274a69d286f03ea8efd76c9b1e7.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0318_jpg.rf.068aa794a0c2471d28f8da8ed3404707.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0318_jpg.rf.068aa794a0c2471d28f8da8ed3404707.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0318_jpg.rf.068aa794a0c2471d28f8da8ed3404707.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0208_jpg.rf.1024d2dbcceb2f9e29dd6e0bc60159e1.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0208_jpg.rf.1024d2dbcceb2f9e29dd6e0bc60159e1.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0208_jpg.rf.1024d2dbcceb2f9e29dd6e0bc60159e1.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0477_jpg.rf.3eb4038c6a4ff4a054936d233cb5de47.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0477_jpg.rf.3eb4038c6a4ff4a054936d233cb5de47.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0477_jpg.rf.3eb4038c6a4ff4a054936d233cb5de47.jpg' are the same file\n",
            "‚ùå Error copying KakaoTalk_20250717_091440196_08_jpg.rf.51a952aea5e9560abaf67fab831a9582.jpg: './temp_data/train/images/KakaoTalk_20250717_091440196_08_jpg.rf.51a952aea5e9560abaf67fab831a9582.jpg' and './temp_data/train/images/KakaoTalk_20250717_091440196_08_jpg.rf.51a952aea5e9560abaf67fab831a9582.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0484_jpg.rf.e222a2ed3cdc9d1646ee378504e64b2d.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0484_jpg.rf.e222a2ed3cdc9d1646ee378504e64b2d.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0484_jpg.rf.e222a2ed3cdc9d1646ee378504e64b2d.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0175_jpg.rf.b972f8e00667229bd6dd5f83c2997166.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0175_jpg.rf.b972f8e00667229bd6dd5f83c2997166.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0175_jpg.rf.b972f8e00667229bd6dd5f83c2997166.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0326_jpg.rf.cdef6bbf87e484d5347daebef5c2b367.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0326_jpg.rf.cdef6bbf87e484d5347daebef5c2b367.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0326_jpg.rf.cdef6bbf87e484d5347daebef5c2b367.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0258_jpg.rf.bb3f5cfa8d218e367cb920452384b172.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0258_jpg.rf.bb3f5cfa8d218e367cb920452384b172.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0258_jpg.rf.bb3f5cfa8d218e367cb920452384b172.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0133_jpg.rf.fff83adef2b86109ce6cbc5c2bae1de4.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0133_jpg.rf.fff83adef2b86109ce6cbc5c2bae1de4.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0133_jpg.rf.fff83adef2b86109ce6cbc5c2bae1de4.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0107_jpg.rf.36f5ce0fb9555c4d533278dfe9371bd9.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0107_jpg.rf.36f5ce0fb9555c4d533278dfe9371bd9.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0107_jpg.rf.36f5ce0fb9555c4d533278dfe9371bd9.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0082_jpg.rf.d5576727321351082bbc4f5dc95d6d33.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0082_jpg.rf.d5576727321351082bbc4f5dc95d6d33.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0082_jpg.rf.d5576727321351082bbc4f5dc95d6d33.jpg' are the same file\n",
            "‚ùå Error copying KakaoTalk_20250704_210829744_06_jpg.rf.835d0f98d3640446b525a5558c0c106b.jpg: './temp_data/train/images/KakaoTalk_20250704_210829744_06_jpg.rf.835d0f98d3640446b525a5558c0c106b.jpg' and './temp_data/train/images/KakaoTalk_20250704_210829744_06_jpg.rf.835d0f98d3640446b525a5558c0c106b.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0430_jpg.rf.78fadd9665998b93d054e36334d714e6.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0430_jpg.rf.78fadd9665998b93d054e36334d714e6.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0430_jpg.rf.78fadd9665998b93d054e36334d714e6.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0419_jpg.rf.c3f38bb0b4b9695dfe2b128e201ad5cb.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0419_jpg.rf.c3f38bb0b4b9695dfe2b128e201ad5cb.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0419_jpg.rf.c3f38bb0b4b9695dfe2b128e201ad5cb.jpg' are the same file\n",
            "‚ùå Error copying KakaoTalk_20250704_210829744_02_jpg.rf.84fc0a466477ff7911adaf70de54b8a2.jpg: './temp_data/train/images/KakaoTalk_20250704_210829744_02_jpg.rf.84fc0a466477ff7911adaf70de54b8a2.jpg' and './temp_data/train/images/KakaoTalk_20250704_210829744_02_jpg.rf.84fc0a466477ff7911adaf70de54b8a2.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0074_jpg.rf.024f01993c9af52d1054230f9adb8ffb.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0074_jpg.rf.024f01993c9af52d1054230f9adb8ffb.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0074_jpg.rf.024f01993c9af52d1054230f9adb8ffb.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0070_jpg.rf.3e5261da84e4e71599aeb9ebc986072d.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0070_jpg.rf.3e5261da84e4e71599aeb9ebc986072d.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0070_jpg.rf.3e5261da84e4e71599aeb9ebc986072d.jpg' are the same file\n",
            "‚ùå Error copying KakaoTalk_20250717_091440196_02_jpg.rf.08fcecd1dbf289597cb4c1b1e1a6dfdf.jpg: './temp_data/train/images/KakaoTalk_20250717_091440196_02_jpg.rf.08fcecd1dbf289597cb4c1b1e1a6dfdf.jpg' and './temp_data/train/images/KakaoTalk_20250717_091440196_02_jpg.rf.08fcecd1dbf289597cb4c1b1e1a6dfdf.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0301_jpg.rf.6a462d29e07ac8c40f9fea0266b32cc0.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0301_jpg.rf.6a462d29e07ac8c40f9fea0266b32cc0.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0301_jpg.rf.6a462d29e07ac8c40f9fea0266b32cc0.jpg' are the same file\n",
            "‚ùå Error copying KakaoTalk_20250704_210829744_04_jpg.rf.82dfcc6b607ea07d1529525da215e502.jpg: './temp_data/train/images/KakaoTalk_20250704_210829744_04_jpg.rf.82dfcc6b607ea07d1529525da215e502.jpg' and './temp_data/train/images/KakaoTalk_20250704_210829744_04_jpg.rf.82dfcc6b607ea07d1529525da215e502.jpg' are the same file\n",
            "‚ùå Error copying KakaoTalk_20250704_210829744_10_jpg.rf.f49d946fa0f5b3de650ee503b473bcc8.jpg: './temp_data/train/images/KakaoTalk_20250704_210829744_10_jpg.rf.f49d946fa0f5b3de650ee503b473bcc8.jpg' and './temp_data/train/images/KakaoTalk_20250704_210829744_10_jpg.rf.f49d946fa0f5b3de650ee503b473bcc8.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0311_jpg.rf.9d92d032c6e73ac53498308f825432ca.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0311_jpg.rf.9d92d032c6e73ac53498308f825432ca.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0311_jpg.rf.9d92d032c6e73ac53498308f825432ca.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0293_jpg.rf.5029a3c4b04ab9a1127946c529992d8c.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0293_jpg.rf.5029a3c4b04ab9a1127946c529992d8c.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0293_jpg.rf.5029a3c4b04ab9a1127946c529992d8c.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0169_jpg.rf.b1985dcf6159637e2501c6ae803f6648.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0169_jpg.rf.b1985dcf6159637e2501c6ae803f6648.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0169_jpg.rf.b1985dcf6159637e2501c6ae803f6648.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0100_jpg.rf.d0ef0a793a2115a009408a5fb6251d8d.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0100_jpg.rf.d0ef0a793a2115a009408a5fb6251d8d.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0100_jpg.rf.d0ef0a793a2115a009408a5fb6251d8d.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0509_jpg.rf.942fc82754beb6342a51d6f3b56188f3.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0509_jpg.rf.942fc82754beb6342a51d6f3b56188f3.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0509_jpg.rf.942fc82754beb6342a51d6f3b56188f3.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0037_jpg.rf.b820caea447b13b9c46595bfe69cbc51.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0037_jpg.rf.b820caea447b13b9c46595bfe69cbc51.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0037_jpg.rf.b820caea447b13b9c46595bfe69cbc51.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0123_jpg.rf.603d239b219b551a8792f50fe6439d52.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0123_jpg.rf.603d239b219b551a8792f50fe6439d52.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0123_jpg.rf.603d239b219b551a8792f50fe6439d52.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0335_jpg.rf.574617da75f9d6aeb0a3ad6196275ecf.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0335_jpg.rf.574617da75f9d6aeb0a3ad6196275ecf.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0335_jpg.rf.574617da75f9d6aeb0a3ad6196275ecf.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0078_jpg.rf.79af45dd9b4679ac6a9f760769ee3e77.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0078_jpg.rf.79af45dd9b4679ac6a9f760769ee3e77.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0078_jpg.rf.79af45dd9b4679ac6a9f760769ee3e77.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0304_jpg.rf.242654fa0dd80d601f5afc4f289b15b6.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0304_jpg.rf.242654fa0dd80d601f5afc4f289b15b6.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0304_jpg.rf.242654fa0dd80d601f5afc4f289b15b6.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0347_jpg.rf.9dec2e1ee65c54fa4e7adcff0f07a854.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0347_jpg.rf.9dec2e1ee65c54fa4e7adcff0f07a854.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0347_jpg.rf.9dec2e1ee65c54fa4e7adcff0f07a854.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0460_jpg.rf.6be825a7191842a743aa4f7914d85596.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0460_jpg.rf.6be825a7191842a743aa4f7914d85596.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0460_jpg.rf.6be825a7191842a743aa4f7914d85596.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0319_jpg.rf.244f6f23ce65c4384d1d687a8bed9f7c.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0319_jpg.rf.244f6f23ce65c4384d1d687a8bed9f7c.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0319_jpg.rf.244f6f23ce65c4384d1d687a8bed9f7c.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0340_jpg.rf.45b7a0f769064e8232e04e0a04eb4a4b.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0340_jpg.rf.45b7a0f769064e8232e04e0a04eb4a4b.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0340_jpg.rf.45b7a0f769064e8232e04e0a04eb4a4b.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0052_jpg.rf.7bfa55923665649eb375d91b3eed7d68.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0052_jpg.rf.7bfa55923665649eb375d91b3eed7d68.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0052_jpg.rf.7bfa55923665649eb375d91b3eed7d68.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0264_jpg.rf.2164eed96f85dd3d034e0ea1170545f8.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0264_jpg.rf.2164eed96f85dd3d034e0ea1170545f8.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0264_jpg.rf.2164eed96f85dd3d034e0ea1170545f8.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0062_jpg.rf.f24a56093caec4262fa97be6055c59f2.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0062_jpg.rf.f24a56093caec4262fa97be6055c59f2.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0062_jpg.rf.f24a56093caec4262fa97be6055c59f2.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0101_jpg.rf.e0adaea72b8a57be19418df6f5ba4fd0.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0101_jpg.rf.e0adaea72b8a57be19418df6f5ba4fd0.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0101_jpg.rf.e0adaea72b8a57be19418df6f5ba4fd0.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0218_jpg.rf.60a814b18941c40f56c900ae9b60fe04.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0218_jpg.rf.60a814b18941c40f56c900ae9b60fe04.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0218_jpg.rf.60a814b18941c40f56c900ae9b60fe04.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0007_jpg.rf.96ff625aed41638b19a3434254272917.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0007_jpg.rf.96ff625aed41638b19a3434254272917.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0007_jpg.rf.96ff625aed41638b19a3434254272917.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0152_jpg.rf.b642c40508c99be17706c22af8801483.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0152_jpg.rf.b642c40508c99be17706c22af8801483.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0152_jpg.rf.b642c40508c99be17706c22af8801483.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0402_jpg.rf.3d8ef5de93a1145477e609dc013f3314.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0402_jpg.rf.3d8ef5de93a1145477e609dc013f3314.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0402_jpg.rf.3d8ef5de93a1145477e609dc013f3314.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0487_jpg.rf.28bd0de5b21a818626e6c59aab09aa8e.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0487_jpg.rf.28bd0de5b21a818626e6c59aab09aa8e.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0487_jpg.rf.28bd0de5b21a818626e6c59aab09aa8e.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0387_jpg.rf.aa61f70a080cdcf3eb73295f5ae289e5.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0387_jpg.rf.aa61f70a080cdcf3eb73295f5ae289e5.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0387_jpg.rf.aa61f70a080cdcf3eb73295f5ae289e5.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0418_jpg.rf.569238c35e2a4ef35ac01dc7c3b72a96.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0418_jpg.rf.569238c35e2a4ef35ac01dc7c3b72a96.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0418_jpg.rf.569238c35e2a4ef35ac01dc7c3b72a96.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0121_jpg.rf.22e7a6153042587ddeb2cf79d57e4c6e.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0121_jpg.rf.22e7a6153042587ddeb2cf79d57e4c6e.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0121_jpg.rf.22e7a6153042587ddeb2cf79d57e4c6e.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0009_jpg.rf.6102bc4b5ee591035eaf91b48eb2c3e2.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0009_jpg.rf.6102bc4b5ee591035eaf91b48eb2c3e2.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0009_jpg.rf.6102bc4b5ee591035eaf91b48eb2c3e2.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0158_jpg.rf.9017e1e6317c94e5cf5ad6f831fc3566.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0158_jpg.rf.9017e1e6317c94e5cf5ad6f831fc3566.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0158_jpg.rf.9017e1e6317c94e5cf5ad6f831fc3566.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0036_jpg.rf.4ad368edfc67f93ce054c7a518e8082d.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0036_jpg.rf.4ad368edfc67f93ce054c7a518e8082d.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0036_jpg.rf.4ad368edfc67f93ce054c7a518e8082d.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0097_jpg.rf.9beab89cbe2204b0622eca4195a3e540.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0097_jpg.rf.9beab89cbe2204b0622eca4195a3e540.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0097_jpg.rf.9beab89cbe2204b0622eca4195a3e540.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0443_jpg.rf.69b3f5494896439a6f5ed9c5a911590a.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0443_jpg.rf.69b3f5494896439a6f5ed9c5a911590a.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0443_jpg.rf.69b3f5494896439a6f5ed9c5a911590a.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0478_jpg.rf.fc4d9d03760c34c30a0300b61bc5e718.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0478_jpg.rf.fc4d9d03760c34c30a0300b61bc5e718.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0478_jpg.rf.fc4d9d03760c34c30a0300b61bc5e718.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0154_jpg.rf.e0aaecfab20b268af16bdf08b63029f5.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0154_jpg.rf.e0aaecfab20b268af16bdf08b63029f5.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0154_jpg.rf.e0aaecfab20b268af16bdf08b63029f5.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0328_jpg.rf.66a2d987ef68940dd8addcbdfbda40db.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0328_jpg.rf.66a2d987ef68940dd8addcbdfbda40db.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0328_jpg.rf.66a2d987ef68940dd8addcbdfbda40db.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0015_jpg.rf.59d71a9d43d9dd3b202e097a06e2f003.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0015_jpg.rf.59d71a9d43d9dd3b202e097a06e2f003.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0015_jpg.rf.59d71a9d43d9dd3b202e097a06e2f003.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0018_jpg.rf.85cfca7a61b9373271f285957b553b98.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0018_jpg.rf.85cfca7a61b9373271f285957b553b98.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0018_jpg.rf.85cfca7a61b9373271f285957b553b98.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0012_jpg.rf.3e3bcf1286d39752e7e2378959d46901.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0012_jpg.rf.3e3bcf1286d39752e7e2378959d46901.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0012_jpg.rf.3e3bcf1286d39752e7e2378959d46901.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0184_jpg.rf.69d3ebdda22bde7e1d7b5a8d659dfe8f.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0184_jpg.rf.69d3ebdda22bde7e1d7b5a8d659dfe8f.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0184_jpg.rf.69d3ebdda22bde7e1d7b5a8d659dfe8f.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0476_jpg.rf.adbf9a5cc80edc357b2c19835ea27bc1.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0476_jpg.rf.adbf9a5cc80edc357b2c19835ea27bc1.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0476_jpg.rf.adbf9a5cc80edc357b2c19835ea27bc1.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0245_jpg.rf.9b42e320d0be00176ba333b5346444b1.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0245_jpg.rf.9b42e320d0be00176ba333b5346444b1.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0245_jpg.rf.9b42e320d0be00176ba333b5346444b1.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0183_jpg.rf.8d3f0cdab4070a1355c07ef782c184c3.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0183_jpg.rf.8d3f0cdab4070a1355c07ef782c184c3.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0183_jpg.rf.8d3f0cdab4070a1355c07ef782c184c3.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0438_jpg.rf.c52e3c2136cd229733b43d918398c686.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0438_jpg.rf.c52e3c2136cd229733b43d918398c686.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0438_jpg.rf.c52e3c2136cd229733b43d918398c686.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0350_jpg.rf.8aff929d830d941e5a16763bbfd6778b.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0350_jpg.rf.8aff929d830d941e5a16763bbfd6778b.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0350_jpg.rf.8aff929d830d941e5a16763bbfd6778b.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0282_jpg.rf.9fc64f17ff07a6120492080b6e0627c2.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0282_jpg.rf.9fc64f17ff07a6120492080b6e0627c2.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0282_jpg.rf.9fc64f17ff07a6120492080b6e0627c2.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0376_jpg.rf.9f22d1ee556f2a4cbdfda8b98e585557.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0376_jpg.rf.9f22d1ee556f2a4cbdfda8b98e585557.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0376_jpg.rf.9f22d1ee556f2a4cbdfda8b98e585557.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0514_jpg.rf.da258a7174b95f6ec874e3c67cdb97e8.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0514_jpg.rf.da258a7174b95f6ec874e3c67cdb97e8.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0514_jpg.rf.da258a7174b95f6ec874e3c67cdb97e8.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0087_jpg.rf.b9e70b3288dc5dbab278224132bb091e.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0087_jpg.rf.b9e70b3288dc5dbab278224132bb091e.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0087_jpg.rf.b9e70b3288dc5dbab278224132bb091e.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0521_jpg.rf.7b419912c03b09ac4f0968363b457602.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0521_jpg.rf.7b419912c03b09ac4f0968363b457602.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0521_jpg.rf.7b419912c03b09ac4f0968363b457602.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0166_jpg.rf.defa3d5f05fe2e34880828fe9601d913.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0166_jpg.rf.defa3d5f05fe2e34880828fe9601d913.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0166_jpg.rf.defa3d5f05fe2e34880828fe9601d913.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0321_jpg.rf.293a2d2b09b072add668f258492b6493.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0321_jpg.rf.293a2d2b09b072add668f258492b6493.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0321_jpg.rf.293a2d2b09b072add668f258492b6493.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0115_jpg.rf.90d5c0a246502397d4288bc53bea75f1.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0115_jpg.rf.90d5c0a246502397d4288bc53bea75f1.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0115_jpg.rf.90d5c0a246502397d4288bc53bea75f1.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0171_jpg.rf.dd3350278256e594f919d56fb5c55fa0.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0171_jpg.rf.dd3350278256e594f919d56fb5c55fa0.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0171_jpg.rf.dd3350278256e594f919d56fb5c55fa0.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0338_jpg.rf.ac30dd42fbbf6548fcb3459a91327cf8.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0338_jpg.rf.ac30dd42fbbf6548fcb3459a91327cf8.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0338_jpg.rf.ac30dd42fbbf6548fcb3459a91327cf8.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0320_jpg.rf.609b6ac88c73878f97b7c9c116d23818.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0320_jpg.rf.609b6ac88c73878f97b7c9c116d23818.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0320_jpg.rf.609b6ac88c73878f97b7c9c116d23818.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0232_jpg.rf.a16e841e393f47bcf6ab47c49f8e9d27.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0232_jpg.rf.a16e841e393f47bcf6ab47c49f8e9d27.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0232_jpg.rf.a16e841e393f47bcf6ab47c49f8e9d27.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0351_jpg.rf.5700b4c7e386d4aaba432f5723582798.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0351_jpg.rf.5700b4c7e386d4aaba432f5723582798.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0351_jpg.rf.5700b4c7e386d4aaba432f5723582798.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0031_jpg.rf.e08c25fcf17a370979c8e17c101fcb81.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0031_jpg.rf.e08c25fcf17a370979c8e17c101fcb81.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0031_jpg.rf.e08c25fcf17a370979c8e17c101fcb81.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0416_jpg.rf.39987a95e94aa09f0f5b4e9ab1bd7914.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0416_jpg.rf.39987a95e94aa09f0f5b4e9ab1bd7914.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0416_jpg.rf.39987a95e94aa09f0f5b4e9ab1bd7914.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0429_jpg.rf.6b93727a2264796aa75ecb2a4ba44fde.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0429_jpg.rf.6b93727a2264796aa75ecb2a4ba44fde.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0429_jpg.rf.6b93727a2264796aa75ecb2a4ba44fde.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0456_jpg.rf.7c99bf1841bea565325c9388fd8c513a.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0456_jpg.rf.7c99bf1841bea565325c9388fd8c513a.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0456_jpg.rf.7c99bf1841bea565325c9388fd8c513a.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0002_jpg.rf.003f8617f31530425fec9438d0afe4b6.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0002_jpg.rf.003f8617f31530425fec9438d0afe4b6.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0002_jpg.rf.003f8617f31530425fec9438d0afe4b6.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0090_jpg.rf.1e2ede71edf25ac70c4a11e4bc6c43b6.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0090_jpg.rf.1e2ede71edf25ac70c4a11e4bc6c43b6.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0090_jpg.rf.1e2ede71edf25ac70c4a11e4bc6c43b6.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0086_jpg.rf.a9b706fb4502ae74e96598549a82eae8.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0086_jpg.rf.a9b706fb4502ae74e96598549a82eae8.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0086_jpg.rf.a9b706fb4502ae74e96598549a82eae8.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0370_jpg.rf.22eb31609154534d6dfb4bb99ec7098c.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0370_jpg.rf.22eb31609154534d6dfb4bb99ec7098c.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0370_jpg.rf.22eb31609154534d6dfb4bb99ec7098c.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0422_jpg.rf.04f02586902ee5f8a4053fa55cf791e5.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0422_jpg.rf.04f02586902ee5f8a4053fa55cf791e5.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0422_jpg.rf.04f02586902ee5f8a4053fa55cf791e5.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0465_jpg.rf.af7f80e4c520b17617199504d988e26d.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0465_jpg.rf.af7f80e4c520b17617199504d988e26d.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0465_jpg.rf.af7f80e4c520b17617199504d988e26d.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0105_jpg.rf.634e5f415dad0e572d5a0346eb5bc231.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0105_jpg.rf.634e5f415dad0e572d5a0346eb5bc231.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0105_jpg.rf.634e5f415dad0e572d5a0346eb5bc231.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0069_jpg.rf.119226f5ae831aca5ca649cc6d0bf846.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0069_jpg.rf.119226f5ae831aca5ca649cc6d0bf846.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0069_jpg.rf.119226f5ae831aca5ca649cc6d0bf846.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0445_jpg.rf.09b0d37a4acc004e56f952c0ee9bcedc.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0445_jpg.rf.09b0d37a4acc004e56f952c0ee9bcedc.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0445_jpg.rf.09b0d37a4acc004e56f952c0ee9bcedc.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0239_jpg.rf.e098808325cf8da7828621966fa1c3a4.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0239_jpg.rf.e098808325cf8da7828621966fa1c3a4.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0239_jpg.rf.e098808325cf8da7828621966fa1c3a4.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0310_jpg.rf.5a09be37bf33fbb38876a9fa1f5887d0.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0310_jpg.rf.5a09be37bf33fbb38876a9fa1f5887d0.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0310_jpg.rf.5a09be37bf33fbb38876a9fa1f5887d0.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0236_jpg.rf.8d233d5af8ab28fd8dbef033ca1ff15b.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0236_jpg.rf.8d233d5af8ab28fd8dbef033ca1ff15b.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0236_jpg.rf.8d233d5af8ab28fd8dbef033ca1ff15b.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0451_jpg.rf.8688572ad07e9d6fc4fe9c51e8a63583.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0451_jpg.rf.8688572ad07e9d6fc4fe9c51e8a63583.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0451_jpg.rf.8688572ad07e9d6fc4fe9c51e8a63583.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0240_jpg.rf.726cc9502a4c536525496f2df1ed5753.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0240_jpg.rf.726cc9502a4c536525496f2df1ed5753.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0240_jpg.rf.726cc9502a4c536525496f2df1ed5753.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0285_jpg.rf.941d48dd5682ad81c231609599f376c5.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0285_jpg.rf.941d48dd5682ad81c231609599f376c5.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0285_jpg.rf.941d48dd5682ad81c231609599f376c5.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0541_jpg.rf.73a0214929d8b2c072c5aec9de5628ad.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0541_jpg.rf.73a0214929d8b2c072c5aec9de5628ad.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0541_jpg.rf.73a0214929d8b2c072c5aec9de5628ad.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0267_jpg.rf.bf2b9846863a1343821228975b239269.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0267_jpg.rf.bf2b9846863a1343821228975b239269.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0267_jpg.rf.bf2b9846863a1343821228975b239269.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0322_jpg.rf.36a0b3dc05e4ca61614637c60cdda572.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0322_jpg.rf.36a0b3dc05e4ca61614637c60cdda572.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0322_jpg.rf.36a0b3dc05e4ca61614637c60cdda572.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0510_jpg.rf.b3e993242bf9bfcfc0fae26a79b9d898.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0510_jpg.rf.b3e993242bf9bfcfc0fae26a79b9d898.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0510_jpg.rf.b3e993242bf9bfcfc0fae26a79b9d898.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0140_jpg.rf.d17f6a139e669c6533537643b5b65a3e.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0140_jpg.rf.d17f6a139e669c6533537643b5b65a3e.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0140_jpg.rf.d17f6a139e669c6533537643b5b65a3e.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0217_jpg.rf.54000fcc339793e30f3e024d6be5bd93.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0217_jpg.rf.54000fcc339793e30f3e024d6be5bd93.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0217_jpg.rf.54000fcc339793e30f3e024d6be5bd93.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0500_jpg.rf.372b25d3f0160b0375ef545ab9d1bdba.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0500_jpg.rf.372b25d3f0160b0375ef545ab9d1bdba.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0500_jpg.rf.372b25d3f0160b0375ef545ab9d1bdba.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0077_jpg.rf.ea67269e925c4b429c21dce98867b615.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0077_jpg.rf.ea67269e925c4b429c21dce98867b615.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0077_jpg.rf.ea67269e925c4b429c21dce98867b615.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0099_jpg.rf.9461c677071e3d9c223cad0252f49455.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0099_jpg.rf.9461c677071e3d9c223cad0252f49455.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0099_jpg.rf.9461c677071e3d9c223cad0252f49455.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0450_jpg.rf.e622e7c420c5baffbcc508ab77d314fb.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0450_jpg.rf.e622e7c420c5baffbcc508ab77d314fb.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0450_jpg.rf.e622e7c420c5baffbcc508ab77d314fb.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0266_jpg.rf.ac6b77adbc22d6b0e00b2b92bc6d8234.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0266_jpg.rf.ac6b77adbc22d6b0e00b2b92bc6d8234.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0266_jpg.rf.ac6b77adbc22d6b0e00b2b92bc6d8234.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0520_jpg.rf.e53fbf7cd3501281045c66a161f89ea2.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0520_jpg.rf.e53fbf7cd3501281045c66a161f89ea2.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0520_jpg.rf.e53fbf7cd3501281045c66a161f89ea2.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0034_jpg.rf.7e6490556406ea06b2a29e262d9e1980.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0034_jpg.rf.7e6490556406ea06b2a29e262d9e1980.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0034_jpg.rf.7e6490556406ea06b2a29e262d9e1980.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0023_jpg.rf.040ed46f4867af9143989e72baa9c72d.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0023_jpg.rf.040ed46f4867af9143989e72baa9c72d.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0023_jpg.rf.040ed46f4867af9143989e72baa9c72d.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0423_jpg.rf.9101d12642391d136a3345640fae73cf.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0423_jpg.rf.9101d12642391d136a3345640fae73cf.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0423_jpg.rf.9101d12642391d136a3345640fae73cf.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0214_jpg.rf.29f4b9993c18cdbef54fc6f31bdc1c10.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0214_jpg.rf.29f4b9993c18cdbef54fc6f31bdc1c10.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0214_jpg.rf.29f4b9993c18cdbef54fc6f31bdc1c10.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0137_jpg.rf.c18373f1361c08545d3a9c38941863c5.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0137_jpg.rf.c18373f1361c08545d3a9c38941863c5.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0137_jpg.rf.c18373f1361c08545d3a9c38941863c5.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0329_jpg.rf.0ea781927240fdda1b51008cc17e7552.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0329_jpg.rf.0ea781927240fdda1b51008cc17e7552.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0329_jpg.rf.0ea781927240fdda1b51008cc17e7552.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0507_jpg.rf.2972a014ae3e28a9118c01ba85dcb069.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0507_jpg.rf.2972a014ae3e28a9118c01ba85dcb069.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0507_jpg.rf.2972a014ae3e28a9118c01ba85dcb069.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0314_jpg.rf.542e74863878c90cb1974dfa3414936b.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0314_jpg.rf.542e74863878c90cb1974dfa3414936b.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0314_jpg.rf.542e74863878c90cb1974dfa3414936b.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0257_jpg.rf.e1fe3ce647abbbab31bf14d80bba52ac.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0257_jpg.rf.e1fe3ce647abbbab31bf14d80bba52ac.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0257_jpg.rf.e1fe3ce647abbbab31bf14d80bba52ac.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0344_jpg.rf.f917035bcbe739eb0505c247d992b9b9.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0344_jpg.rf.f917035bcbe739eb0505c247d992b9b9.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0344_jpg.rf.f917035bcbe739eb0505c247d992b9b9.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0261_jpg.rf.cf96ac40504e3c7f9a046e84fdd6a620.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0261_jpg.rf.cf96ac40504e3c7f9a046e84fdd6a620.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0261_jpg.rf.cf96ac40504e3c7f9a046e84fdd6a620.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0138_jpg.rf.9c848db827d5efef394814bfee312c51.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0138_jpg.rf.9c848db827d5efef394814bfee312c51.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0138_jpg.rf.9c848db827d5efef394814bfee312c51.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0221_jpg.rf.578528d9a79d7621a25c55c346754079.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0221_jpg.rf.578528d9a79d7621a25c55c346754079.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0221_jpg.rf.578528d9a79d7621a25c55c346754079.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0248_jpg.rf.79f34c4f7cecc4929949d7015bf49e2a.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0248_jpg.rf.79f34c4f7cecc4929949d7015bf49e2a.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0248_jpg.rf.79f34c4f7cecc4929949d7015bf49e2a.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0538_jpg.rf.996f9d9c14de1fd890b994d701b598cb.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0538_jpg.rf.996f9d9c14de1fd890b994d701b598cb.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0538_jpg.rf.996f9d9c14de1fd890b994d701b598cb.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0193_jpg.rf.70e9e9bb5286b641668f4095ce459bfb.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0193_jpg.rf.70e9e9bb5286b641668f4095ce459bfb.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0193_jpg.rf.70e9e9bb5286b641668f4095ce459bfb.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0044_jpg.rf.3a55e3b3fe90a603d68050c71266217c.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0044_jpg.rf.3a55e3b3fe90a603d68050c71266217c.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0044_jpg.rf.3a55e3b3fe90a603d68050c71266217c.jpg' are the same file\n",
            "‚ùå Error copying combined_video-YB-Jung-_mp4-0403_jpg.rf.9e24bdab320520f8e63691d33a30f863.jpg: './temp_data/train/images/combined_video-YB-Jung-_mp4-0403_jpg.rf.9e24bdab320520f8e63691d33a30f863.jpg' and './temp_data/train/images/combined_video-YB-Jung-_mp4-0403_jpg.rf.9e24bdab320520f8e63691d33a30f863.jpg' are the same file\n",
            "   train: 0 files copied\n",
            "   val: 112 files copied\n",
            "   test: 56 files copied\n",
            "üîç Verifying dataset structure...\n",
            "   ‚úÖ train_images: 564 files\n",
            "   ‚úÖ train_labels: 564 files\n",
            "   ‚úÖ val_images: 112 files\n",
            "   ‚úÖ val_labels: 112 files\n",
            "‚úÖ Dataset structure verification passed\n",
            "üìù Loaded class names from data.yaml\n",
            "‚úÖ Successfully loaded dataset with 16 classes:\n",
            "    0: Autobike\n",
            "    1: Car\n",
            "    2: Central line\n",
            "    3: Crosswalk\n",
            "    4: Human\n",
            "    5: Lane\n",
            "    6: Load Information\n",
            "    7: Load direction\n",
            "    8: Pedestrian traffic light\n",
            "    9: Separation\n",
            "   10: Speed limit\n",
            "   11: Streetlight\n",
            "   12: Traffic light\n",
            "   13: Traffic sign\n",
            "   14: Truck\n",
            "   15: Velocity limit\n",
            "\n",
            "üìã Available Classes (16 total):\n",
            "    0: Autobike\n",
            "    1: Car\n",
            "    2: Central line\n",
            "    3: Crosswalk\n",
            "    4: Human\n",
            "    5: Lane\n",
            "    6: Load Information\n",
            "    7: Load direction\n",
            "    8: Pedestrian traffic light\n",
            "    9: Separation\n",
            "   10: Speed limit\n",
            "   11: Streetlight\n",
            "   12: Traffic light\n",
            "   13: Traffic sign\n",
            "   14: Truck\n",
            "   15: Velocity limit\n",
            "\n",
            "üéØ Select classes to train:\n",
            "   ‚Ä¢ Type 'all' for all classes\n",
            "   ‚Ä¢ Type numbers separated by commas (e.g., 0,2,5)\n",
            "   ‚Ä¢ Type ranges with dashes (e.g., 0-5,8,10-12)\n",
            "   ‚Ä¢ Press Ctrl+C to cancel\n",
            "\n",
            "‚û§ Enter your selection: 2,3,5,9,12,13\n",
            "\n",
            "‚úÖ Selected 6 classes:\n",
            "    2: Central line\n",
            "    3: Crosswalk\n",
            "    5: Lane\n",
            "    9: Separation\n",
            "   12: Traffic light\n",
            "   13: Traffic sign\n",
            "\n",
            "‚öôÔ∏è Training Configuration:\n",
            "Press Enter to use default values shown in parentheses\n",
            "\n",
            "ü§ñ Select YOLO Version:\n",
            "   0: YOLOv8 (5 models)\n",
            "   1: YOLOv9 (5 models)\n",
            "   2: YOLOv10 (6 models)\n",
            "   3: YOLO11 (5 models)\n",
            "Select YOLO version (3 for YOLO11): 3\n",
            "\n",
            "üì¶ Selected: YOLO11\n",
            "Available YOLO11 models:\n",
            "   0: yolo11n.pt - Nano (fastest, least accurate)\n",
            "   1: yolo11s.pt - Small (fast, good accuracy)\n",
            "   2: yolo11m.pt - Medium (balanced speed/accuracy)\n",
            "   3: yolo11l.pt - Large (slow, high accuracy)\n",
            "   4: yolo11x.pt - Extra Large (slowest, highest accuracy)\n",
            "Select model (0 for yolo11n.pt): 2\n",
            "\n",
            "Epochs (100): 400\n",
            "Image size (640): \n",
            "Batch size (16): \n",
            "\n",
            "üìã Training Summary:\n",
            "   üìä Dataset: Auto Driving.v1i.yolov8.zip\n",
            "   üéØ Classes: 6 selected\n",
            "   ü§ñ YOLO Version: YOLO11\n",
            "   üì¶ Model: yolo11m.pt\n",
            "   üìà Epochs: 400\n",
            "   üñºÔ∏è Image size: 640\n",
            "   üì¶ Batch size: 16\n",
            "\n",
            "‚ö° Ready to start training!\n",
            "Continue? (y/N): y\n",
            "üöÄ Starting YOLO11 training with 6 classes...\n",
            "üìÑ Created dataset.yaml with 6 classes\n",
            "üîÑ Filtering labels...\n",
            "üîç Final dataset verification...\n",
            "üìä Dataset summary:\n",
            "   üèãÔ∏è Training: 564 images, 564 labels\n",
            "   ‚úÖ Validation: 112 images, 112 labels\n",
            "‚úÖ Final verification passed - ready for training!\n",
            "ü§ñ Loading yolo11m.pt model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m.pt to 'yolo11m.pt': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38.8M/38.8M [00:00<00:00, 139MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ Training started...\n",
            "Parameters: YOLO11 yolo11m.pt, epochs=400, imgsz=640, batch=16\n",
            "üìÑ Using dataset config: /content/dataset.yaml\n",
            "Ultralytics 8.3.179 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/dataset.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=400, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo11_custom, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=./runs/train, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/train/yolo11_custom, save_frames=False, save_json=False, save_period=40, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 36.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  1    111872  ultralytics.nn.modules.block.C3k2            [128, 256, 1, True, 0.25]     \n",
            "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  4                  -1  1    444928  ultralytics.nn.modules.block.C3k2            [256, 512, 1, True, 0.25]     \n",
            "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  6                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 13                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1    542720  ultralytics.nn.modules.block.C3k2            [1024, 256, 1, True]          \n",
            " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
            " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
            " 23        [16, 19, 22]  1   1415650  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "YOLO11m summary: 231 layers, 20,057,634 parameters, 20,057,618 gradients, 68.2 GFLOPs\n",
            "\n",
            "Transferred 643/649 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.35M/5.35M [00:00<00:00, 114MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ENHANCED SEGFORMER FINE-TUNING SYSTEM"
      ],
      "metadata": {
        "id": "viA2_s3BBIwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# COMPLETE SEGMENTATION PROCESS - FULLY EXPLAINED WITH PERFORMANCE TUNING\n",
        "# ===============================================================================\n",
        "# Every command explained + Performance optimization annotations\n",
        "# Learn exactly how segmentation works and how to improve it\n",
        "# ===============================================================================\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')  # Hide unnecessary warnings\n",
        "\n",
        "# Core libraries with explanations\n",
        "import torch  # PyTorch: Main deep learning framework\n",
        "import torch.nn as nn  # Neural network components (layers, loss functions)\n",
        "import torch.nn.functional as F  # Functional operations (interpolation, etc.)\n",
        "from torch.utils.data import Dataset, DataLoader  # Data handling for training\n",
        "from transformers import (\n",
        "    SegformerImageProcessor,  # Preprocesses images for Segformer\n",
        "    SegformerForSemanticSegmentation,  # The segmentation model itself\n",
        "    TrainingArguments,  # Training configuration\n",
        "    Trainer  # Handles training loop\n",
        ")\n",
        "import numpy as np  # Numerical array operations\n",
        "from PIL import Image  # Image loading and basic operations\n",
        "import os  # File system operations\n",
        "import cv2  # Computer vision operations (boundaries, contours)\n",
        "from tqdm import tqdm  # Progress bars\n",
        "import matplotlib.pyplot as plt  # Plotting and visualization\n",
        "import json  # JSON file handling\n",
        "from datetime import datetime  # Timestamps\n",
        "import time  # Performance timing\n",
        "from sklearn.metrics import accuracy_score, jaccard_score  # Evaluation metrics\n",
        "import albumentations as A  # Data augmentation library\n",
        "\n",
        "# Check environment\n",
        "try:\n",
        "    from google.colab import files\n",
        "    COLAB_ENV = True\n",
        "except ImportError:\n",
        "    COLAB_ENV = False\n",
        "\n",
        "# ===============================================================================\n",
        "# üéØ SEGMENTATION PROCESS EXPLAINED - COMPLETE PIPELINE\n",
        "# ===============================================================================\n",
        "\"\"\"\n",
        "üìö HOW SEMANTIC SEGMENTATION WORKS - COMPLETE EXPLANATION:\n",
        "\n",
        "üîç INPUT PROCESSING:\n",
        "1. Take RGB image (Height √ó Width √ó 3)\n",
        "2. Resize to model input size (typically 512√ó512 or 1024√ó1024)\n",
        "3. Normalize pixel values (0-255 ‚Üí 0-1 range)\n",
        "4. Convert to tensor format for neural network\n",
        "\n",
        "üß† NEURAL NETWORK PROCESSING:\n",
        "1. Encoder: Extract features at multiple scales\n",
        "   - Early layers: detect edges, textures\n",
        "   - Middle layers: detect shapes, objects\n",
        "   - Deep layers: detect complex patterns\n",
        "2. Decoder: Combine features to make pixel predictions\n",
        "   - Upsampling: restore original image size\n",
        "   - Feature fusion: combine different scale information\n",
        "3. Output: Probability map (Height √ó Width √ó NumClasses)\n",
        "\n",
        "üéØ PREDICTION GENERATION:\n",
        "1. For each pixel, get probability for each class\n",
        "2. Take argmax (highest probability) = final class\n",
        "3. Create segmentation map (Height √ó Width)\n",
        "\n",
        "üé® VISUALIZATION:\n",
        "1. Map class IDs to colors\n",
        "2. Create colored mask\n",
        "3. Add boundaries for clarity\n",
        "4. Blend with original image\n",
        "\n",
        "‚ö° PERFORMANCE FACTORS:\n",
        "- Model architecture (larger = more accurate but slower)\n",
        "- Input resolution (higher = more detail but slower)\n",
        "- Preprocessing quality\n",
        "- Post-processing techniques\n",
        "\"\"\"\n",
        "\n",
        "class CompleteSegmentationExplained:\n",
        "    \"\"\"\n",
        "    üî¨ COMPLETE SEGMENTATION SYSTEM WITH DETAILED EXPLANATIONS\n",
        "\n",
        "    This class demonstrates every step of the segmentation process\n",
        "    with detailed explanations and performance tuning options.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        üèóÔ∏è SYSTEM INITIALIZATION - DETAILED SETUP\n",
        "\n",
        "        Sets up the complete segmentation pipeline with all components\n",
        "        needed for high-performance semantic segmentation.\n",
        "        \"\"\"\n",
        "        print(\"üöÄ INITIALIZING COMPLETE SEGMENTATION SYSTEM\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # üîß PERFORMANCE TUNING PARAMETER #1: Device Selection\n",
        "        # GPU vs CPU dramatically affects speed (10-100x difference)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"üíª Computing device: {self.device}\")\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            # Display GPU information for performance reference\n",
        "            gpu_name = torch.cuda.get_device_name(0)\n",
        "            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "            print(f\"üî• GPU: {gpu_name}\")\n",
        "            print(f\"üíæ GPU Memory: {gpu_memory:.1f} GB\")\n",
        "\n",
        "            # üîß PERFORMANCE TUNING PARAMETER #2: Memory Optimization\n",
        "            # Enable memory efficient attention if available\n",
        "            torch.backends.cuda.enable_flash_sdp(True)\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è  Using CPU - expect slower performance\")\n",
        "\n",
        "        # Initialize model components\n",
        "        self.pretrained_model = None\n",
        "        self.processor = None\n",
        "        self.model_info = {}\n",
        "\n",
        "        # üîß PERFORMANCE TUNING PARAMETER #3: Processing Settings\n",
        "        # These settings significantly affect quality vs speed trade-off\n",
        "        self.processing_config = {\n",
        "            'input_size': 512,          # üéØ CRITICAL: Higher = better quality, slower speed\n",
        "            'batch_size': 1,            # üéØ CRITICAL: Higher = faster, more memory usage\n",
        "            'interpolation_mode': 'bilinear',  # üéØ CRITICAL: bilinear vs nearest\n",
        "            'align_corners': False,     # üéØ CRITICAL: Affects upsampling quality\n",
        "            'confidence_threshold': 0.5,  # üéØ CRITICAL: Filter low-confidence predictions\n",
        "            'boundary_thickness': 2,    # Visual: Boundary line thickness\n",
        "            'blend_alpha': 0.6         # Visual: Original image opacity in overlay\n",
        "        }\n",
        "\n",
        "        # üîß PERFORMANCE TUNING PARAMETER #4: Color Mapping\n",
        "        # High-contrast colors improve visual clarity\n",
        "        self.performance_colors = self._create_performance_colors()\n",
        "\n",
        "        # Setup directories\n",
        "        self.setup_directories()\n",
        "\n",
        "        print(\"‚úÖ System initialized with performance optimizations!\")\n",
        "        self._print_performance_tips()\n",
        "\n",
        "    def _print_performance_tips(self):\n",
        "        \"\"\"Print performance optimization tips\"\"\"\n",
        "        print(\"\\nüöÄ PERFORMANCE OPTIMIZATION TIPS:\")\n",
        "        print(\"  üéØ For SPEED: Reduce input_size to 256-512\")\n",
        "        print(\"  üéØ For QUALITY: Increase input_size to 1024+\")\n",
        "        print(\"  üéØ For MEMORY: Reduce batch_size\")\n",
        "        print(\"  üéØ For GPU: Enable mixed precision (fp16)\")\n",
        "        print(\"  üéØ For CPU: Use smaller models (segformer-b0)\")\n",
        "\n",
        "    def setup_directories(self):\n",
        "        \"\"\"Create organized directory structure\"\"\"\n",
        "        self.dirs = {\n",
        "            'models': './segmentation_models',\n",
        "            'outputs': './video_outputs',\n",
        "            'results': './image_results',\n",
        "            'temp': './temp_processing'\n",
        "        }\n",
        "\n",
        "        for path in self.dirs.values():\n",
        "            os.makedirs(path, exist_ok=True)\n",
        "\n",
        "# ===============================================================================\n",
        "# üîß PERFORMANCE-CRITICAL MODEL LOADING\n",
        "# ===============================================================================\n",
        "    def load_model_with_performance_optimization(self, model_path=None):\n",
        "        \"\"\"\n",
        "        üì§ LOAD MODEL WITH PERFORMANCE OPTIMIZATION\n",
        "\n",
        "        üîß PERFORMANCE ANNOTATIONS:\n",
        "        - Model loading affects all subsequent processing speed\n",
        "        - Larger models (b1-b5) = better accuracy, slower inference\n",
        "        - Smaller models (b0) = faster inference, lower accuracy\n",
        "        - Memory optimization critical for large models\n",
        "        \"\"\"\n",
        "        print(\"\\nüì§ LOADING MODEL WITH PERFORMANCE OPTIMIZATION\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Get model path\n",
        "        if model_path is None:\n",
        "            if COLAB_ENV:\n",
        "                uploaded = files.upload()\n",
        "                if not uploaded:\n",
        "                    return False\n",
        "                model_path = list(uploaded.keys())[0]\n",
        "            else:\n",
        "                model_path = input(\"üìÅ Enter model path: \").strip()\n",
        "\n",
        "        try:\n",
        "            # üîß PERFORMANCE TUNING: Model Architecture Selection\n",
        "            print(\"üîß PERFORMANCE OPTIMIZATION: Selecting base architecture...\")\n",
        "\n",
        "            # Different base models with performance characteristics\n",
        "            base_models = {\n",
        "                'b0': \"nvidia/segformer-b0-finetuned-cityscapes-1024-1024\",  # Fastest\n",
        "                'b1': \"nvidia/segformer-b1-finetuned-cityscapes-1024-1024\",  # Balanced\n",
        "                'b2': \"nvidia/segformer-b2-finetuned-cityscapes-1024-1024\",  # Better quality\n",
        "                'b3': \"nvidia/segformer-b3-finetuned-cityscapes-1024-1024\",  # High quality\n",
        "                'b4': \"nvidia/segformer-b4-finetuned-cityscapes-1024-1024\",  # Very high quality\n",
        "                'b5': \"nvidia/segformer-b5-finetuned-cityscapes-1024-1024\"   # Best quality, slowest\n",
        "            }\n",
        "\n",
        "            print(\"üìä Available architectures (performance vs quality):\")\n",
        "            print(\"  üèÉ b0: Fastest (4x speed, 85% accuracy)\")\n",
        "            print(\"  ‚öñÔ∏è  b1: Balanced (3x speed, 87% accuracy)\")\n",
        "            print(\"  üéØ b2: Good (2x speed, 89% accuracy)\")\n",
        "            print(\"  üî• b3: Better (1.5x speed, 91% accuracy)\")\n",
        "            print(\"  üåü b4: Excellent (1x speed, 93% accuracy)\")\n",
        "            print(\"  üèÜ b5: Best (0.7x speed, 95% accuracy)\")\n",
        "\n",
        "            # üîß PERFORMANCE CHOICE: Let user select or auto-detect\n",
        "            architecture = 'b0'  # Default to fastest for demonstration\n",
        "            base_model_name = base_models[architecture]\n",
        "            print(f\"üöÄ Using {architecture} architecture for optimal performance\")\n",
        "\n",
        "            # Load checkpoint if provided\n",
        "            if model_path.endswith(('.pth', '.pt')):\n",
        "                checkpoint = torch.load(model_path, map_location='cpu')\n",
        "\n",
        "                # Extract state dict\n",
        "                if 'model_state_dict' in checkpoint:\n",
        "                    state_dict = checkpoint['model_state_dict']\n",
        "                elif 'state_dict' in checkpoint:\n",
        "                    state_dict = checkpoint['state_dict']\n",
        "                else:\n",
        "                    state_dict = checkpoint\n",
        "\n",
        "                # Detect classes\n",
        "                num_classes = self._detect_classes_optimized(state_dict)\n",
        "                print(f\"üéØ Detected {num_classes} classes\")\n",
        "\n",
        "                # üîß PERFORMANCE OPTIMIZATION: Load with memory efficiency\n",
        "                print(\"üîß Loading model with memory optimization...\")\n",
        "                self.pretrained_model = SegformerForSemanticSegmentation.from_pretrained(\n",
        "                    base_model_name,\n",
        "                    num_labels=num_classes,\n",
        "                    ignore_mismatched_sizes=True,\n",
        "                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32  # üîß CRITICAL: Half precision for speed\n",
        "                )\n",
        "\n",
        "                # Load weights\n",
        "                missing, unexpected = self.pretrained_model.load_state_dict(state_dict, strict=False)\n",
        "                print(f\"‚úÖ Weights loaded: {len(state_dict)-len(missing)}/{len(state_dict)} parameters\")\n",
        "\n",
        "            else:\n",
        "                # Load HuggingFace model\n",
        "                self.pretrained_model = SegformerForSemanticSegmentation.from_pretrained(model_path)\n",
        "                num_classes = self.pretrained_model.config.num_labels\n",
        "\n",
        "            # üîß PERFORMANCE OPTIMIZATION: Setup processor with optimal settings\n",
        "            self.processor = SegformerImageProcessor.from_pretrained(\n",
        "                base_model_name,\n",
        "                size=self.processing_config['input_size'],  # üîß CRITICAL: Controls quality vs speed\n",
        "                do_resize=True,\n",
        "                do_normalize=True\n",
        "            )\n",
        "\n",
        "            # üîß PERFORMANCE OPTIMIZATION: Model optimizations\n",
        "            self.pretrained_model.to(self.device)\n",
        "            self.pretrained_model.eval()  # Set to evaluation mode\n",
        "\n",
        "            # Enable optimizations\n",
        "            if torch.cuda.is_available():\n",
        "                # üîß PERFORMANCE BOOST: Compile model for faster inference (PyTorch 2.0+)\n",
        "                try:\n",
        "                    self.pretrained_model = torch.compile(self.pretrained_model, mode='max-autotune')\n",
        "                    print(\"üöÄ Model compiled for maximum performance\")\n",
        "                except:\n",
        "                    print(\"‚ö†Ô∏è  Model compilation not available\")\n",
        "\n",
        "            # Store model info\n",
        "            self.model_info = {\n",
        "                'num_classes': num_classes,\n",
        "                'architecture': architecture,\n",
        "                'input_size': self.processing_config['input_size'],\n",
        "                'device': str(self.device)\n",
        "            }\n",
        "\n",
        "            print(\"‚úÖ Model loaded with performance optimizations!\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading model: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def _detect_classes_optimized(self, state_dict):\n",
        "        \"\"\"Optimized class detection\"\"\"\n",
        "        for key, tensor in state_dict.items():\n",
        "            if any(x in key.lower() for x in ['classifier', 'decode_head', 'head']):\n",
        "                if 'weight' in key and len(tensor.shape) >= 2:\n",
        "                    return tensor.shape[0]\n",
        "        return 19  # Default cityscapes classes\n",
        "\n",
        "# ===============================================================================\n",
        "# üéØ CORE SEGMENTATION PROCESS - STEP BY STEP EXPLANATION\n",
        "# ===============================================================================\n",
        "    def process_image_complete_explanation(self, image_path, save_results=True):\n",
        "        \"\"\"\n",
        "        üñºÔ∏è COMPLETE IMAGE SEGMENTATION PROCESS - EVERY STEP EXPLAINED\n",
        "\n",
        "        This function demonstrates the COMPLETE segmentation pipeline:\n",
        "        1. Image Loading & Preprocessing\n",
        "        2. Neural Network Inference\n",
        "        3. Post-processing & Optimization\n",
        "        4. Visualization & Analysis\n",
        "        5. Performance Measurement\n",
        "\n",
        "        üîß PERFORMANCE CRITICAL SECTIONS ARE MARKED WITH ANNOTATIONS\n",
        "        \"\"\"\n",
        "        print(f\"\\nüñºÔ∏è COMPLETE SEGMENTATION PROCESS - STEP BY STEP\")\n",
        "        print(\"=\" * 70)\n",
        "        print(f\"üìÅ Processing: {os.path.basename(image_path)}\")\n",
        "\n",
        "        if not self.pretrained_model:\n",
        "            print(\"‚ùå No model loaded! Load a model first.\")\n",
        "            return None\n",
        "\n",
        "        start_total = time.time()\n",
        "\n",
        "        try:\n",
        "            # ================================================================\n",
        "            # STEP 1: IMAGE LOADING & PREPROCESSING\n",
        "            # ================================================================\n",
        "            print(\"\\n1Ô∏è‚É£ IMAGE LOADING & PREPROCESSING\")\n",
        "            print(\"   üîç This step prepares the image for the neural network\")\n",
        "            print(\"   üìä Performance impact: ~5% of total time\")\n",
        "\n",
        "            step1_start = time.time()\n",
        "\n",
        "            # Load image\n",
        "            print(\"   üìÅ Loading image file...\")\n",
        "            original_image = Image.open(image_path).convert(\"RGB\")\n",
        "            original_np = np.array(original_image)\n",
        "            print(f\"      ‚úÖ Loaded: {original_image.size} pixels\")\n",
        "\n",
        "            # üîß PERFORMANCE CRITICAL: Image preprocessing\n",
        "            print(\"   ‚öôÔ∏è  Preprocessing for neural network...\")\n",
        "            print(\"      üîß PERFORMANCE FACTOR: Input size affects quality vs speed\")\n",
        "            print(f\"      üìè Target size: {self.processing_config['input_size']}√ó{self.processing_config['input_size']}\")\n",
        "\n",
        "            # Preprocess with optimized settings\n",
        "            inputs = self.processor(\n",
        "                original_image,\n",
        "                return_tensors=\"pt\",\n",
        "                do_resize=True,\n",
        "                size=self.processing_config['input_size']  # üîß CRITICAL: Size vs quality trade-off\n",
        "            )\n",
        "\n",
        "            # Move to device (GPU/CPU)\n",
        "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "\n",
        "            step1_time = time.time() - step1_start\n",
        "            print(f\"   ‚è±Ô∏è  Preprocessing completed: {step1_time:.3f}s\")\n",
        "\n",
        "            # ================================================================\n",
        "            # STEP 2: NEURAL NETWORK INFERENCE\n",
        "            # ================================================================\n",
        "            print(\"\\n2Ô∏è‚É£ NEURAL NETWORK INFERENCE\")\n",
        "            print(\"   üîç The neural network analyzes every pixel\")\n",
        "            print(\"   üìä Performance impact: ~80% of total time\")\n",
        "            print(\"   üß† Process: Input ‚Üí Encoder ‚Üí Decoder ‚Üí Predictions\")\n",
        "\n",
        "            step2_start = time.time()\n",
        "\n",
        "            # üîß PERFORMANCE CRITICAL: Neural network inference\n",
        "            print(\"   üß† Running neural network inference...\")\n",
        "            print(\"      üîß PERFORMANCE FACTORS:\")\n",
        "            print(\"         ‚Ä¢ Model size (b0-b5)\")\n",
        "            print(\"         ‚Ä¢ Input resolution\")\n",
        "            print(\"         ‚Ä¢ Device (GPU vs CPU)\")\n",
        "            print(\"         ‚Ä¢ Batch size\")\n",
        "            print(\"         ‚Ä¢ Mixed precision\")\n",
        "\n",
        "            with torch.no_grad():  # üîß CRITICAL: Disable gradients for inference\n",
        "                # Enable autocast for mixed precision (speed boost)\n",
        "                if torch.cuda.is_available():\n",
        "                    with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
        "                        outputs = self.pretrained_model(**inputs)\n",
        "                else:\n",
        "                    outputs = self.pretrained_model(**inputs)\n",
        "\n",
        "            step2_time = time.time() - step2_start\n",
        "            print(f\"   ‚è±Ô∏è  Inference completed: {step2_time:.3f}s\")\n",
        "            print(f\"   üìä Output shape: {outputs.logits.shape}\")\n",
        "\n",
        "            # ================================================================\n",
        "            # STEP 3: PREDICTION POST-PROCESSING\n",
        "            # ================================================================\n",
        "            print(\"\\n3Ô∏è‚É£ PREDICTION POST-PROCESSING\")\n",
        "            print(\"   üîç Convert neural network output to final segmentation\")\n",
        "            print(\"   üìä Performance impact: ~10% of total time\")\n",
        "\n",
        "            step3_start = time.time()\n",
        "\n",
        "            # üîß PERFORMANCE CRITICAL: Upsampling to original size\n",
        "            print(\"   üìè Upsampling predictions to original image size...\")\n",
        "            print(\"      üîß PERFORMANCE FACTORS:\")\n",
        "            print(\"         ‚Ä¢ Interpolation method (bilinear vs nearest)\")\n",
        "            print(\"         ‚Ä¢ Align corners setting\")\n",
        "            print(\"         ‚Ä¢ Output resolution\")\n",
        "\n",
        "            predictions = F.interpolate(\n",
        "                outputs.logits,\n",
        "                size=original_image.size[::-1],  # (height, width)\n",
        "                mode=self.processing_config['interpolation_mode'],  # üîß CRITICAL: Quality vs speed\n",
        "                align_corners=self.processing_config['align_corners']  # üîß CRITICAL: Alignment quality\n",
        "            )\n",
        "\n",
        "            # Convert to class map\n",
        "            print(\"   üéØ Converting probabilities to class predictions...\")\n",
        "            print(\"      üîß Process: For each pixel, select class with highest probability\")\n",
        "\n",
        "            # Get raw probabilities for analysis\n",
        "            probabilities = F.softmax(predictions, dim=1)\n",
        "            confidence_map = torch.max(probabilities, dim=1)[0].cpu().numpy()\n",
        "\n",
        "            # Get final predictions\n",
        "            predicted_map = predictions.squeeze().cpu().numpy().argmax(axis=0)\n",
        "\n",
        "            # üîß PERFORMANCE OPTIMIZATION: Confidence filtering\n",
        "            if self.processing_config['confidence_threshold'] > 0:\n",
        "                print(f\"   üîß Applying confidence threshold: {self.processing_config['confidence_threshold']}\")\n",
        "                low_confidence = confidence_map < self.processing_config['confidence_threshold']\n",
        "                predicted_map[low_confidence] = 0  # Set low confidence to background\n",
        "\n",
        "            step3_time = time.time() - step3_start\n",
        "            print(f\"   ‚è±Ô∏è  Post-processing completed: {step3_time:.3f}s\")\n",
        "\n",
        "            # ================================================================\n",
        "            # STEP 4: RESULT ANALYSIS\n",
        "            # ================================================================\n",
        "            print(\"\\n4Ô∏è‚É£ SEGMENTATION RESULT ANALYSIS\")\n",
        "            print(\"   üîç Analyzing what the model detected\")\n",
        "\n",
        "            # Analyze detected classes\n",
        "            unique_classes = np.unique(predicted_map)\n",
        "            class_stats = {}\n",
        "\n",
        "            print(f\"   üìä Classes detected: {len(unique_classes)}\")\n",
        "            total_pixels = predicted_map.size\n",
        "\n",
        "            for class_id in unique_classes:\n",
        "                count = np.sum(predicted_map == class_id)\n",
        "                percentage = (count / total_pixels) * 100\n",
        "                avg_confidence = np.mean(confidence_map[predicted_map == class_id])\n",
        "\n",
        "                class_stats[class_id] = {\n",
        "                    'pixels': count,\n",
        "                    'percentage': percentage,\n",
        "                    'confidence': avg_confidence\n",
        "                }\n",
        "\n",
        "                class_name = f\"Class_{class_id}\"  # You can customize this\n",
        "                print(f\"      üéØ {class_name}: {percentage:.1f}% (conf: {avg_confidence:.2f})\")\n",
        "\n",
        "            # ================================================================\n",
        "            # STEP 5: VISUALIZATION CREATION\n",
        "            # ================================================================\n",
        "            print(\"\\n5Ô∏è‚É£ CREATING ENHANCED VISUALIZATIONS\")\n",
        "            print(\"   üîç Creating clear, professional visualizations\")\n",
        "            print(\"   üìä Performance impact: ~5% of total time\")\n",
        "\n",
        "            step5_start = time.time()\n",
        "\n",
        "            # Create visualizations\n",
        "            visualizations = self._create_enhanced_visualizations_explained(\n",
        "                original_np, predicted_map, confidence_map, unique_classes\n",
        "            )\n",
        "\n",
        "            step5_time = time.time() - step5_start\n",
        "            print(f\"   ‚è±Ô∏è  Visualization creation: {step5_time:.3f}s\")\n",
        "\n",
        "            # ================================================================\n",
        "            # STEP 6: PERFORMANCE SUMMARY\n",
        "            # ================================================================\n",
        "            total_time = time.time() - start_total\n",
        "\n",
        "            print(f\"\\n6Ô∏è‚É£ PERFORMANCE SUMMARY\")\n",
        "            print(\"=\" * 40)\n",
        "            print(f\"   ‚è±Ô∏è  Total processing time: {total_time:.3f}s\")\n",
        "            print(f\"   üìä Time breakdown:\")\n",
        "            print(f\"      ‚Ä¢ Preprocessing: {step1_time:.3f}s ({step1_time/total_time*100:.1f}%)\")\n",
        "            print(f\"      ‚Ä¢ Neural network: {step2_time:.3f}s ({step2_time/total_time*100:.1f}%)\")\n",
        "            print(f\"      ‚Ä¢ Post-processing: {step3_time:.3f}s ({step3_time/total_time*100:.1f}%)\")\n",
        "            print(f\"      ‚Ä¢ Visualization: {step5_time:.3f}s ({step5_time/total_time*100:.1f}%)\")\n",
        "\n",
        "            # Calculate throughput\n",
        "            throughput = (original_image.size[0] * original_image.size[1]) / total_time\n",
        "            print(f\"   üöÄ Throughput: {throughput/1000000:.1f} megapixels/second\")\n",
        "\n",
        "            # ================================================================\n",
        "            # STEP 7: DISPLAY AND SAVE RESULTS\n",
        "            # ================================================================\n",
        "            if save_results:\n",
        "                print(f\"\\n7Ô∏è‚É£ SAVING RESULTS\")\n",
        "                save_dir = self._save_complete_results(\n",
        "                    image_path, original_np, visualizations, class_stats, total_time\n",
        "                )\n",
        "                print(f\"   üíæ Results saved to: {save_dir}\")\n",
        "\n",
        "            # Display results\n",
        "            self._display_complete_results(original_np, visualizations)\n",
        "\n",
        "            print(f\"\\nüéâ COMPLETE SEGMENTATION FINISHED!\")\n",
        "            print(f\"‚úÖ Successfully processed {os.path.basename(image_path)}\")\n",
        "\n",
        "            return {\n",
        "                'original': original_np,\n",
        "                'prediction_map': predicted_map,\n",
        "                'confidence_map': confidence_map,\n",
        "                'visualizations': visualizations,\n",
        "                'class_stats': class_stats,\n",
        "                'performance': {\n",
        "                    'total_time': total_time,\n",
        "                    'inference_time': step2_time,\n",
        "                    'throughput_mpps': throughput/1000000\n",
        "                }\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error during processing: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return None\n",
        "\n",
        "# ===============================================================================\n",
        "# üé® ADVANCED VISUALIZATION WITH PERFORMANCE OPTIMIZATION\n",
        "# ===============================================================================\n",
        "    def _create_enhanced_visualizations_explained(self, original, prediction_map, confidence_map, unique_classes):\n",
        "        \"\"\"\n",
        "        üé® CREATE ENHANCED VISUALIZATIONS - COMPLETE PROCESS\n",
        "\n",
        "        üîß PERFORMANCE ANNOTATIONS:\n",
        "        - Visualization quality vs processing speed trade-offs\n",
        "        - Memory usage optimization for large images\n",
        "        - Efficient boundary detection algorithms\n",
        "        \"\"\"\n",
        "        print(\"   üé® Creating enhanced visualizations...\")\n",
        "\n",
        "        h, w = prediction_map.shape\n",
        "\n",
        "        # üîß PERFORMANCE OPTIMIZATION: Efficient color mapping\n",
        "        print(\"      üîß PERFORMANCE: Using optimized color mapping...\")\n",
        "        colors = self.performance_colors\n",
        "\n",
        "        # Create base colored mask\n",
        "        colored_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
        "        for class_id in unique_classes:\n",
        "            if class_id < len(colors):\n",
        "                mask = prediction_map == class_id\n",
        "                colored_mask[mask] = colors[class_id]\n",
        "\n",
        "        # üîß PERFORMANCE CRITICAL: Boundary detection\n",
        "        print(\"      üîß PERFORMANCE: Efficient boundary detection...\")\n",
        "        boundary_mask = self._create_optimized_boundaries(prediction_map)\n",
        "\n",
        "        # Create enhanced mask with boundaries\n",
        "        enhanced_mask = colored_mask.copy()\n",
        "        enhanced_mask[boundary_mask > 0] = [255, 255, 255]  # White boundaries\n",
        "\n",
        "        # üîß PERFORMANCE OPTIMIZATION: Confidence visualization\n",
        "        print(\"      üîß PERFORMANCE: Creating confidence overlay...\")\n",
        "        confidence_overlay = self._create_confidence_overlay(original, confidence_map)\n",
        "\n",
        "        # Create different blend modes\n",
        "        blend_standard = cv2.addWeighted(\n",
        "            original,\n",
        "            self.processing_config['blend_alpha'],\n",
        "            colored_mask,\n",
        "            1 - self.processing_config['blend_alpha'],\n",
        "            0\n",
        "        )\n",
        "\n",
        "        blend_enhanced = cv2.addWeighted(\n",
        "            original,\n",
        "            self.processing_config['blend_alpha'],\n",
        "            enhanced_mask,\n",
        "            1 - self.processing_config['blend_alpha'],\n",
        "            0\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'colored_mask': colored_mask,\n",
        "            'enhanced_mask': enhanced_mask,\n",
        "            'boundary_mask': boundary_mask,\n",
        "            'confidence_overlay': confidence_overlay,\n",
        "            'blend_standard': blend_standard,\n",
        "            'blend_enhanced': blend_enhanced\n",
        "        }\n",
        "\n",
        "    def _create_optimized_boundaries(self, prediction_map):\n",
        "        \"\"\"\n",
        "        üîß OPTIMIZED BOUNDARY DETECTION\n",
        "\n",
        "        Uses efficient algorithms for boundary detection:\n",
        "        - Morphological gradient for speed\n",
        "        - Sobel edge detection for quality\n",
        "        - Optimized kernel operations\n",
        "        \"\"\"\n",
        "        # üîß PERFORMANCE: Use morphological operations (faster than Sobel)\n",
        "        kernel = cv2.getStructuringElement(\n",
        "            cv2.MORPH_RECT,\n",
        "            (self.processing_config['boundary_thickness'], self.processing_config['boundary_thickness'])\n",
        "        )\n",
        "\n",
        "        # Create boundaries\n",
        "        boundaries = cv2.morphologyEx(\n",
        "            prediction_map.astype(np.uint8),\n",
        "            cv2.MORPH_GRADIENT,\n",
        "            kernel\n",
        "        )\n",
        "\n",
        "        return (boundaries > 0).astype(np.uint8) * 255\n",
        "\n",
        "    def _create_confidence_overlay(self, original, confidence_map):\n",
        "        \"\"\"Create confidence-based overlay\"\"\"\n",
        "        # Normalize confidence to 0-255\n",
        "        conf_norm = (confidence_map * 255).astype(np.uint8)\n",
        "\n",
        "        # Create color map (red = low confidence, green = high confidence)\n",
        "        confidence_colored = cv2.applyColorMap(conf_norm, cv2.COLORMAP_RdYlGn)\n",
        "        confidence_colored = cv2.cvtColor(confidence_colored, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Blend with original\n",
        "        confidence_overlay = cv2.addWeighted(original, 0.7, confidence_colored, 0.3, 0)\n",
        "\n",
        "        return confidence_overlay\n",
        "\n",
        "    def _create_performance_colors(self):\n",
        "        \"\"\"\n",
        "        üé® CREATE HIGH-PERFORMANCE COLOR MAPPING\n",
        "\n",
        "        üîß PERFORMANCE CONSIDERATIONS:\n",
        "        - High contrast colors for visibility\n",
        "        - Distinct hues for easy differentiation\n",
        "        - Optimized color space for display\n",
        "        \"\"\"\n",
        "        return [\n",
        "            [64, 64, 64],       # Background - Dark gray\n",
        "            [255, 0, 0],        # Class 1 - Bright red\n",
        "            [0, 255, 0],        # Class 2 - Bright green\n",
        "            [0, 0, 255],        # Class 3 - Bright blue\n",
        "            [255, 255, 0],      # Class 4 - Yellow\n",
        "            [255, 0, 255],      # Class 5 - Magenta\n",
        "            [0, 255, 255],      # Class 6 - Cyan\n",
        "            [255, 128, 0],      # Class 7 - Orange\n",
        "            [128, 0, 255],      # Class 8 - Purple\n",
        "            [255, 192, 203],    # Class 9 - Pink\n",
        "            [50, 205, 50],      # Class 10 - Lime green\n",
        "            [255, 69, 0],       # Class 11 - Red orange\n",
        "            [138, 43, 226],     # Class 12 - Blue violet\n",
        "            [255, 20, 147],     # Class 13 - Deep pink\n",
        "            [0, 191, 255],      # Class 14 - Deep sky blue\n",
        "            [255, 215, 0],      # Class 15 - Gold\n",
        "            [220, 20, 60],      # Class 16 - Crimson\n",
        "            [0, 128, 128],      # Class 17 - Teal\n",
        "            [128, 128, 0],      # Class 18 - Olive\n",
        "            [128, 0, 128],      # Class 19 - Purple\n",
        "        ]\n",
        "\n",
        "# ===============================================================================\n",
        "# üé¨ VIDEO PROCESSING WITH PERFORMANCE OPTIMIZATION\n",
        "# ===============================================================================\n",
        "    def process_video_with_performance_optimization(self, video_path, output_path=None):\n",
        "        \"\"\"\n",
        "        üé¨ VIDEO PROCESSING WITH COMPLETE PERFORMANCE OPTIMIZATION\n",
        "\n",
        "        üîß PERFORMANCE CRITICAL FEATURES:\n",
        "        - Frame batching for efficiency\n",
        "        - Memory management for long videos\n",
        "        - Progress tracking and ETA calculation\n",
        "        - Optimized video encoding\n",
        "        - Real-time performance monitoring\n",
        "        \"\"\"\n",
        "        print(f\"\\nüé¨ PROCESSING VIDEO WITH PERFORMANCE OPTIMIZATION\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        if not self.pretrained_model:\n",
        "            print(\"‚ùå No model loaded!\")\n",
        "            return None\n",
        "\n",
        "        # Video setup\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        if not cap.isOpened():\n",
        "            print(f\"‚ùå Cannot open video: {video_path}\")\n",
        "            return None\n",
        "\n",
        "        # Get video properties\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        print(f\"üìπ Video properties:\")\n",
        "        print(f\"   üìè Resolution: {width}√ó{height}\")\n",
        "        print(f\"   üé¨ FPS: {fps}\")\n",
        "        print(f\"   üìä Total frames: {total_frames}\")\n",
        "        print(f\"   ‚è±Ô∏è  Duration: {total_frames/fps:.1f} seconds\")\n",
        "\n",
        "        # Setup output\n",
        "        if output_path is None:\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            output_path = os.path.join(self.dirs['outputs'], f\"segmented_{timestamp}.mp4\")\n",
        "\n",
        "        # üîß PERFORMANCE OPTIMIZATION: Video encoding settings\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Efficient codec\n",
        "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "        print(f\"üíæ Output: {output_path}\")\n",
        "\n",
        "        # üîß PERFORMANCE OPTIMIZATION: Processing settings\n",
        "        batch_size = self.processing_config['batch_size']\n",
        "\n",
        "        print(f\"\\nüîß PERFORMANCE SETTINGS:\")\n",
        "        print(f\"   üì¶ Batch size: {batch_size}\")\n",
        "        print(f\"   üìè Processing size: {self.processing_config['input_size']}\")\n",
        "        print(f\"   üíª Device: {self.device}\")\n",
        "\n",
        "        # Process video with performance monitoring\n",
        "        frame_count = 0\n",
        "        start_time = time.time()\n",
        "        fps_history = []\n",
        "\n",
        "        with tqdm(total=total_frames, desc=\"üé¨ Processing\", unit=\"frames\") as pbar:\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "\n",
        "                frame_start = time.time()\n",
        "\n",
        "                # Process frame\n",
        "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                # Run segmentation\n",
        "                result = self._process_single_frame_optimized(frame_rgb)\n",
        "                if result is None:\n",
        "                    continue\n",
        "\n",
        "                # Convert back and write\n",
        "                output_frame = cv2.cvtColor(result, cv2.COLOR_RGB2BGR)\n",
        "                out.write(output_frame)\n",
        "\n",
        "                # Performance tracking\n",
        "                frame_time = time.time() - frame_start\n",
        "                frame_fps = 1.0 / frame_time if frame_time > 0 else 0\n",
        "                fps_history.append(frame_fps)\n",
        "\n",
        "                # Keep only recent FPS measurements\n",
        "                if len(fps_history) > 30:\n",
        "                    fps_history.pop(0)\n",
        "\n",
        "                frame_count += 1\n",
        "\n",
        "                # Update progress with performance info\n",
        "                if frame_count % 10 == 0:\n",
        "                    elapsed = time.time() - start_time\n",
        "                    avg_fps = np.mean(fps_history)\n",
        "                    remaining_frames = total_frames - frame_count\n",
        "                    eta = remaining_frames / avg_fps if avg_fps > 0 else 0\n",
        "\n",
        "                    pbar.set_postfix({\n",
        "                        'FPS': f'{avg_fps:.1f}',\n",
        "                        'ETA': f'{eta/60:.1f}m'\n",
        "                    })\n",
        "\n",
        "                pbar.update(1)\n",
        "\n",
        "        # Cleanup and summary\n",
        "        cap.release()\n",
        "        out.release()\n",
        "\n",
        "        total_time = time.time() - start_time\n",
        "        avg_fps = frame_count / total_time\n",
        "        file_size = os.path.getsize(output_path) / 1024 / 1024\n",
        "\n",
        "        print(f\"\\nüéâ VIDEO PROCESSING COMPLETED!\")\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"‚è±Ô∏è  Total time: {total_time/60:.1f} minutes\")\n",
        "        print(f\"üìä Average FPS: {avg_fps:.1f}\")\n",
        "        print(f\"üìÅ Output file: {output_path}\")\n",
        "        print(f\"üíæ File size: {file_size:.1f} MB\")\n",
        "        print(f\"üöÄ Throughput: {(width*height*frame_count)/(total_time*1000000):.1f} MP/s\")\n",
        "\n",
        "        return output_path\n",
        "\n",
        "    def _process_single_frame_optimized(self, frame_rgb):\n",
        "        \"\"\"Process single frame with optimization\"\"\"\n",
        "        try:\n",
        "            # Convert to PIL\n",
        "            image_pil = Image.fromarray(frame_rgb)\n",
        "\n",
        "            # Preprocess\n",
        "            inputs = self.processor(image_pil, return_tensors=\"pt\")\n",
        "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "\n",
        "            # Inference with optimization\n",
        "            with torch.no_grad():\n",
        "                if torch.cuda.is_available():\n",
        "                    with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
        "                        outputs = self.pretrained_model(**inputs)\n",
        "                else:\n",
        "                    outputs = self.pretrained_model(**inputs)\n",
        "\n",
        "            # Post-process\n",
        "            predictions = F.interpolate(\n",
        "                outputs.logits,\n",
        "                size=image_pil.size[::-1],\n",
        "                mode=self.processing_config['interpolation_mode'],\n",
        "                align_corners=self.processing_config['align_corners']\n",
        "            )\n",
        "\n",
        "            predicted_map = predictions.squeeze().cpu().numpy().argmax(axis=0)\n",
        "\n",
        "            # Create visualization\n",
        "            colored_mask = self._create_quick_visualization(predicted_map)\n",
        "\n",
        "            # Blend\n",
        "            result = cv2.addWeighted(\n",
        "                frame_rgb,\n",
        "                self.processing_config['blend_alpha'],\n",
        "                colored_mask,\n",
        "                1 - self.processing_config['blend_alpha'],\n",
        "                0\n",
        "            )\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Frame processing error: {e}\")\n",
        "            return None\n",
        "\n",
        "    def _create_quick_visualization(self, prediction_map):\n",
        "        \"\"\"Create quick visualization for video processing\"\"\"\n",
        "        h, w = prediction_map.shape\n",
        "        colored_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
        "\n",
        "        for class_id in np.unique(prediction_map):\n",
        "            if class_id < len(self.performance_colors):\n",
        "                mask = prediction_map == class_id\n",
        "                colored_mask[mask] = self.performance_colors[class_id]\n",
        "\n",
        "        return colored_mask\n",
        "\n",
        "# ===============================================================================\n",
        "# üñ•Ô∏è DISPLAY AND SAVING FUNCTIONS\n",
        "# ===============================================================================\n",
        "    def _display_complete_results(self, original, visualizations):\n",
        "        \"\"\"Display comprehensive results\"\"\"\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "        fig.suptitle('Complete Segmentation Results - Performance Optimized', fontsize=16, fontweight='bold')\n",
        "\n",
        "        axes[0, 0].imshow(original)\n",
        "        axes[0, 0].set_title('Original Image', fontweight='bold')\n",
        "        axes[0, 0].axis('off')\n",
        "\n",
        "        axes[0, 1].imshow(visualizations['colored_mask'])\n",
        "        axes[0, 1].set_title('Class Segmentation', fontweight='bold')\n",
        "        axes[0, 1].axis('off')\n",
        "\n",
        "        axes[0, 2].imshow(visualizations['enhanced_mask'])\n",
        "        axes[0, 2].set_title('Enhanced with Boundaries', fontweight='bold')\n",
        "        axes[0, 2].axis('off')\n",
        "\n",
        "        axes[1, 0].imshow(visualizations['blend_standard'])\n",
        "        axes[1, 0].set_title('Standard Overlay', fontweight='bold')\n",
        "        axes[1, 0].axis('off')\n",
        "\n",
        "        axes[1, 1].imshow(visualizations['blend_enhanced'])\n",
        "        axes[1, 1].set_title('Enhanced Overlay', fontweight='bold')\n",
        "        axes[1, 1].axis('off')\n",
        "\n",
        "        axes[1, 2].imshow(visualizations['confidence_overlay'])\n",
        "        axes[1, 2].set_title('Confidence Map', fontweight='bold')\n",
        "        axes[1, 2].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def _save_complete_results(self, image_path, original, visualizations, class_stats, processing_time):\n",
        "        \"\"\"Save complete results with performance analysis\"\"\"\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        save_dir = os.path.join(self.dirs['results'], f\"segmentation_{timestamp}\")\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "        # Save visualizations\n",
        "        cv2.imwrite(os.path.join(save_dir, \"01_original.jpg\"),\n",
        "                   cv2.cvtColor(original, cv2.COLOR_RGB2BGR))\n",
        "        cv2.imwrite(os.path.join(save_dir, \"02_segmentation.jpg\"),\n",
        "                   cv2.cvtColor(visualizations['colored_mask'], cv2.COLOR_RGB2BGR))\n",
        "        cv2.imwrite(os.path.join(save_dir, \"03_enhanced.jpg\"),\n",
        "                   cv2.cvtColor(visualizations['enhanced_mask'], cv2.COLOR_RGB2BGR))\n",
        "        cv2.imwrite(os.path.join(save_dir, \"04_overlay.jpg\"),\n",
        "                   cv2.cvtColor(visualizations['blend_enhanced'], cv2.COLOR_RGB2BGR))\n",
        "        cv2.imwrite(os.path.join(save_dir, \"05_confidence.jpg\"),\n",
        "                   cv2.cvtColor(visualizations['confidence_overlay'], cv2.COLOR_RGB2BGR))\n",
        "\n",
        "        # Save performance report\n",
        "        report = {\n",
        "            'image_path': image_path,\n",
        "            'processing_time': processing_time,\n",
        "            'model_info': self.model_info,\n",
        "            'processing_config': self.processing_config,\n",
        "            'class_statistics': class_stats,\n",
        "            'timestamp': timestamp\n",
        "        }\n",
        "\n",
        "        with open(os.path.join(save_dir, \"performance_report.json\"), 'w') as f:\n",
        "            json.dump(report, f, indent=2)\n",
        "\n",
        "        return save_dir\n",
        "\n",
        "# ===============================================================================\n",
        "# üöÄ MAIN INTERFACE WITH PERFORMANCE OPTIMIZATION\n",
        "# ===============================================================================\n",
        "def main_interface_with_performance():\n",
        "    \"\"\"\n",
        "    üöÄ MAIN INTERFACE WITH COMPLETE PERFORMANCE OPTIMIZATION\n",
        "\n",
        "    This interface provides access to all segmentation features with\n",
        "    detailed explanations and performance optimization options.\n",
        "    \"\"\"\n",
        "    print(\"üî• COMPLETE SEGMENTATION SYSTEM - PERFORMANCE OPTIMIZED\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"‚úÖ Every process step explained in detail\")\n",
        "    print(\"‚úÖ Performance optimization annotations\")\n",
        "    print(\"‚úÖ Real-time performance monitoring\")\n",
        "    print(\"‚úÖ Professional quality results\")\n",
        "\n",
        "    # Initialize system\n",
        "    system = CompleteSegmentationExplained()\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            print(f\"\\nüéØ PERFORMANCE-OPTIMIZED SEGMENTATION MENU\")\n",
        "            print(\"=\" * 50)\n",
        "            print(\"1. üì§ Load model with performance optimization\")\n",
        "            print(\"2. üñºÔ∏è  Process single image (complete explanation)\")\n",
        "            print(\"3. üé¨ Process video (performance optimized)\")\n",
        "            print(\"4. ‚öôÔ∏è  Configure performance settings\")\n",
        "            print(\"5. üìä Performance benchmark test\")\n",
        "            print(\"6. üí° Show performance optimization tips\")\n",
        "            print(\"0. üö™ Exit\")\n",
        "\n",
        "            choice = input(\"\\nüëâ Choose option (0-6): \").strip()\n",
        "\n",
        "            if choice == '0':\n",
        "                print(\"üëã Segmentation system closed!\")\n",
        "                break\n",
        "\n",
        "            elif choice == '1':\n",
        "                print(\"\\nüì§ LOADING MODEL WITH PERFORMANCE OPTIMIZATION\")\n",
        "                success = system.load_model_with_performance_optimization()\n",
        "                if success:\n",
        "                    print(\"‚úÖ Model loaded with performance optimizations!\")\n",
        "\n",
        "            elif choice == '2':\n",
        "                if not system.pretrained_model:\n",
        "                    print(\"‚ùå Load a model first (option 1)\")\n",
        "                    continue\n",
        "\n",
        "                print(\"\\nüñºÔ∏è SINGLE IMAGE PROCESSING - COMPLETE EXPLANATION\")\n",
        "                image_path = input(\"üìÅ Enter image path: \").strip()\n",
        "                if not os.path.exists(image_path):\n",
        "                    print(\"‚ùå Image file not found!\")\n",
        "                    continue\n",
        "\n",
        "                save_results = input(\"üíæ Save results? (y/n): \").strip().lower() == 'y'\n",
        "\n",
        "                result = system.process_image_complete_explanation(image_path, save_results)\n",
        "\n",
        "                if result:\n",
        "                    print(f\"\\nüéâ PROCESSING COMPLETED!\")\n",
        "                    print(f\"‚è±Ô∏è  Time: {result['performance']['total_time']:.2f}s\")\n",
        "                    print(f\"üöÄ Throughput: {result['performance']['throughput_mpps']:.1f} MP/s\")\n",
        "\n",
        "            elif choice == '3':\n",
        "                if not system.pretrained_model:\n",
        "                    print(\"‚ùå Load a model first (option 1)\")\n",
        "                    continue\n",
        "\n",
        "                print(\"\\nüé¨ VIDEO PROCESSING - PERFORMANCE OPTIMIZED\")\n",
        "                video_path = input(\"üìπ Enter video path: \").strip()\n",
        "                if not os.path.exists(video_path):\n",
        "                    print(\"‚ùå Video file not found!\")\n",
        "                    continue\n",
        "\n",
        "                output_path = input(\"üíæ Output path (Enter for auto): \").strip()\n",
        "                if not output_path:\n",
        "                    output_path = None\n",
        "\n",
        "                result = system.process_video_with_performance_optimization(video_path, output_path)\n",
        "\n",
        "                if result:\n",
        "                    print(f\"\\nüéâ VIDEO PROCESSING COMPLETED!\")\n",
        "                    print(f\"üìÅ Output: {result}\")\n",
        "\n",
        "            elif choice == '4':\n",
        "                print(\"\\n‚öôÔ∏è PERFORMANCE CONFIGURATION\")\n",
        "                print(\"Current settings:\")\n",
        "                for key, value in system.processing_config.items():\n",
        "                    print(f\"  {key}: {value}\")\n",
        "\n",
        "                print(\"\\nüîß CRITICAL PERFORMANCE PARAMETERS:\")\n",
        "                print(\"  ‚Ä¢ input_size: Higher = better quality, slower\")\n",
        "                print(\"  ‚Ä¢ confidence_threshold: Higher = cleaner results\")\n",
        "                print(\"  ‚Ä¢ interpolation_mode: bilinear vs nearest\")\n",
        "\n",
        "                # Allow configuration changes\n",
        "                new_size = input(f\"New input size ({system.processing_config['input_size']}): \").strip()\n",
        "                if new_size:\n",
        "                    system.processing_config['input_size'] = int(new_size)\n",
        "\n",
        "                new_threshold = input(f\"Confidence threshold ({system.processing_config['confidence_threshold']}): \").strip()\n",
        "                if new_threshold:\n",
        "                    system.processing_config['confidence_threshold'] = float(new_threshold)\n",
        "\n",
        "                print(\"‚úÖ Configuration updated!\")\n",
        "\n",
        "            elif choice == '5':\n",
        "                if not system.pretrained_model:\n",
        "                    print(\"‚ùå Load a model first (option 1)\")\n",
        "                    continue\n",
        "\n",
        "                print(\"\\nüìä PERFORMANCE BENCHMARK TEST\")\n",
        "                print(\"This will test processing speed on different image sizes\")\n",
        "\n",
        "                test_sizes = [256, 512, 1024]\n",
        "\n",
        "                for size in test_sizes:\n",
        "                    print(f\"\\nüß™ Testing {size}√ó{size} images...\")\n",
        "\n",
        "                    # Create test image\n",
        "                    test_image = np.random.randint(0, 255, (size, size, 3), dtype=np.uint8)\n",
        "                    test_pil = Image.fromarray(test_image)\n",
        "\n",
        "                    # Time processing\n",
        "                    start_time = time.time()\n",
        "                    inputs = system.processor(test_pil, return_tensors=\"pt\")\n",
        "                    inputs = {k: v.to(system.device) for k, v in inputs.items()}\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        outputs = system.pretrained_model(**inputs)\n",
        "\n",
        "                    processing_time = time.time() - start_time\n",
        "                    throughput = (size * size) / processing_time / 1000000\n",
        "\n",
        "                    print(f\"   ‚è±Ô∏è  Time: {processing_time:.3f}s\")\n",
        "                    print(f\"   üöÄ Throughput: {throughput:.1f} MP/s\")\n",
        "\n",
        "            elif choice == '6':\n",
        "                print(\"\\nüí° PERFORMANCE OPTIMIZATION TIPS\")\n",
        "                print(\"=\" * 50)\n",
        "                print(\"üöÄ SPEED OPTIMIZATION:\")\n",
        "                print(\"  ‚Ä¢ Use smaller input sizes (256-512)\")\n",
        "                print(\"  ‚Ä¢ Enable GPU processing\")\n",
        "                print(\"  ‚Ä¢ Use model compilation (PyTorch 2.0+)\")\n",
        "                print(\"  ‚Ä¢ Enable mixed precision (fp16)\")\n",
        "                print(\"  ‚Ä¢ Use smaller model variants (b0, b1)\")\n",
        "\n",
        "                print(\"\\nüéØ QUALITY OPTIMIZATION:\")\n",
        "                print(\"  ‚Ä¢ Use larger input sizes (1024+)\")\n",
        "                print(\"  ‚Ä¢ Higher confidence thresholds\")\n",
        "                print(\"  ‚Ä¢ Better interpolation (bilinear)\")\n",
        "                print(\"  ‚Ä¢ Larger model variants (b3, b4, b5)\")\n",
        "\n",
        "                print(\"\\nüíæ MEMORY OPTIMIZATION:\")\n",
        "                print(\"  ‚Ä¢ Reduce batch size\")\n",
        "                print(\"  ‚Ä¢ Use gradient checkpointing\")\n",
        "                print(\"  ‚Ä¢ Clear cache between operations\")\n",
        "                print(\"  ‚Ä¢ Process videos in chunks\")\n",
        "\n",
        "            else:\n",
        "                print(\"‚ùå Invalid choice!\")\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n‚èπÔ∏è Interrupted by user\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error: {str(e)}\")\n",
        "\n",
        "# ===============================================================================\n",
        "# üèÉ EXECUTION\n",
        "# ===============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    main_interface_with_performance()\n",
        "\n",
        "# ===============================================================================\n",
        "# üìö COMPLETE USAGE GUIDE\n",
        "# ===============================================================================\n",
        "\"\"\"\n",
        "üî• COMPLETE SEGMENTATION SYSTEM - USAGE GUIDE\n",
        "\n",
        "üéØ WHAT THIS SYSTEM DOES:\n",
        "‚úÖ Loads your pre-trained segmentation model\n",
        "‚úÖ Explains every processing step in detail\n",
        "‚úÖ Optimizes performance for speed and quality\n",
        "‚úÖ Processes images and videos with professional results\n",
        "‚úÖ Provides detailed performance analysis\n",
        "‚úÖ Creates multiple visualization types\n",
        "\n",
        "üöÄ PERFORMANCE CRITICAL PARAMETERS:\n",
        "\n",
        "1. INPUT SIZE (Most Important)\n",
        "   ‚Ä¢ 256√ó256: Very fast, lower quality\n",
        "   ‚Ä¢ 512√ó512: Balanced speed/quality (RECOMMENDED)\n",
        "   ‚Ä¢ 1024√ó1024: High quality, slower\n",
        "   ‚Ä¢ 2048√ó2048: Best quality, very slow\n",
        "\n",
        "2. MODEL ARCHITECTURE\n",
        "   ‚Ä¢ segformer-b0: Fastest (4x speed)\n",
        "   ‚Ä¢ segformer-b1: Balanced (3x speed)\n",
        "   ‚Ä¢ segformer-b2: Good quality (2x speed)\n",
        "   ‚Ä¢ segformer-b3: Better quality (1.5x speed)\n",
        "   ‚Ä¢ segformer-b4: Excellent (1x speed)\n",
        "   ‚Ä¢ segformer-b5: Best quality (0.7x speed)\n",
        "\n",
        "3. DEVICE OPTIMIZATION\n",
        "   ‚Ä¢ GPU: 10-100x faster than CPU\n",
        "   ‚Ä¢ Mixed precision (fp16): 2x speed boost\n",
        "   ‚Ä¢ Model compilation: 20-30% speed boost\n",
        "\n",
        "4. POST-PROCESSING\n",
        "   ‚Ä¢ Confidence threshold: Filter weak predictions\n",
        "   ‚Ä¢ Interpolation mode: bilinear vs nearest\n",
        "   ‚Ä¢ Boundary thickness: Visual clarity\n",
        "\n",
        "üé¨ VIDEO PROCESSING TIPS:\n",
        "‚Ä¢ Use input_size=512 for good balance\n",
        "‚Ä¢ Enable GPU for real-time processing\n",
        "‚Ä¢ Monitor memory usage for long videos\n",
        "‚Ä¢ Use batch processing for efficiency\n",
        "\n",
        "üìä EXPECTED PERFORMANCE:\n",
        "‚Ä¢ GPU (RTX 3080): ~50-100 FPS at 512√ó512\n",
        "‚Ä¢ GPU (RTX 4090): ~100-200 FPS at 512√ó512\n",
        "‚Ä¢ CPU (Modern): ~2-5 FPS at 512√ó512\n",
        "\n",
        "üéØ QUALITY IMPROVEMENTS:\n",
        "‚Ä¢ Higher input resolution\n",
        "‚Ä¢ Better model architecture\n",
        "‚Ä¢ Confidence filtering\n",
        "‚Ä¢ Boundary enhancement\n",
        "‚Ä¢ Multi-scale processing\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "DtHsXp9-BIK9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}